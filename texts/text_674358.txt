

Multilingual Text-to-Speech Models for Indic Languages / Habr


              30  June   at 15:39  Multilingual Text-to-Speech Models for Indic Languages Machine learning *Natural Language Processing *Voice user interfaces *      In this article, we shall provide some background on how multilingual multi-speaker models work and test an Indic TTS model that supports 9 languages and 17 speakers (Hindi, Malayalam, Manipuri, Bengali, Rajasthani, Tamil, Telugu, Gujarati, Kannada).It seems a bit counter-intuitive at first that one model can support so many languages and speakers provided that each Indic language has its own alphabet, but we shall see how it was implemented.Also, we shall list the specs of these models like supported sampling rates and try something cool – making speakers of different Indic languages speak Hindi. Please, if you are a native speaker of any of these languages, share your opinion on how these voices sound, both in their respective language and in Hindi.Basic Background on Text-to-SpeechText-to-speech (TTS) is a broad subject, but we need to get a basic understanding of how it works in general or what are the main components.Unlike more traditional TTS models that relied on specific linguistic information as inputs, modern TTS models usually work with text or phoneme inputs. The main components of most modern TTS systems are (even newer fully end-to-end models still have similar components inside):Text preprocessing module and cleaning plus some form of text to phoneme transcription, transcription, or transliteration;An acoustic model;A vocoder;Modern TTS models typically rely on curated graphemes or phonemes as input. This input is then passed into an embedding layer that maps this alphabet to a set of tensors.Usually, Mel Spectrograms are chosen as a modelling unit for the acoustic model and the vocoder. In simple terms, the acoustic model transfers input text embeddings into a Mel Spectrogram, which the vocoder turns into the actual audio.There is a whole plethora of different approaches and architectures for vocoders and acoustic models (please see the paper below for a comprehensive review), but this is out of scope for this article.Source: http://arxiv.org/abs/2106.15561Each Indic language has its own alphabet and basically, there are only 2 ways we can combine them into one unified model (of course we also can train several distinct models):Use some transliteration or transcription scheme;Combine the alphabets together and increase the number of embeddings;The second approach is a bit problematic because the phonemes are very similar in closely related languages using such an approach may hurt the model’s generalization and convergence.Also, each speaker should get his or her own embedding. As for the languages – it does not make sense to include language embeddings in case the number of speakers is not much larger than the number of languages.How does it Work?The secret sauce is that the model uses ISO romanization techniques supported by a widely used aksharamukha tool and its python package. This process is a transliteration (not a transcription) and some language’s letters have a bit different sounds, but this works well enough as you will see.To use this tool for all of these languages, for example using python, we need to:LanguageRomanization functionhinditransliterate.process(‘Devanagari’, ‘ISO’, orig_text)malayalamtransliterate.process(‘Malayalam’, ‘ISO’, orig_text)manipuritransliterate.process(‘Bengali’, ‘ISO’, orig_text)bengalitransliterate.process(‘Bengali’, ‘ISO’, orig_text)rajasthanitransliterate.process(‘Devanagari’, ‘ISO’, orig_text)tamiltransliterate.process(‘Tamil’, ‘ISO’, orig_text, pre_options=[‘TamilTranscribe’])telugutransliterate.process(‘Telugu’, ‘ISO’, orig_text)gujaratitransliterate.process(‘Gujarati’, ‘ISO’, orig_text)kannadatransliterate.process(‘Kannada’, ‘ISO’, orig_text)After converting the input text to ISO, now we can try the model:import torch
from aksharamukha import transliterate
model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',
 																		 model='silero_tts',
                                     language='indic',
                                     speaker='v3_indic')
orig_text = "