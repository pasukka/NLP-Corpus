

Создайте свой клон с помощью Fine-tuned LLM / Habr


               Создайте свой клон с помощью Fine-tuned LLM Level of difficulty  
    Medium
   Reading time  
    10 min
   Views  5.1K Programming *Machine learning *Artificial Intelligence   
    From sandbox
  
    Translation
     
                Original author:
                
                  Sergei Savvov
                   Обретите цифрового двойника  Image generated by Stable Diffusion.  Перевод статьи Сергея Саввова.Цель этой статьи - показать, как эффективно и с минимальными затратами настроить LLM на пользовательском датасет. Мы рассмотрим использование модели Falcon-7B с адаптерами LoRa, с использованием библиотеки Lit-GPT.  Вы задумывались, каково это - иметь цифрового двойника? Виртуальную копию себя, которая может вести беседы, учиться и даже выражать мысли? Последние достижения в области искусственного интеллекта (ИИ) сделали эту некогда фантастическую идею достижимой.  Усилия сообщества искусственного интеллекта привели к разработке многих высококачественных open-source LLMs, включая LLaMA, Falcon, StableLM и Pythia. Вы можете настроить эти модели, чтобы адаптировать их к вашей конкретной задаче, например, обучить чат-бота отвечать на финансовые вопросы. В дополнение, это также может гарантировать защиту конфиденциальности данных, когда они не могут быть переданы или обработаны с помощью Cloud APIs.  В данном исследовании я хотел, чтобы модель научилась говорить в моем стиле, подражая, используя шутки, фразочки и слова.Сбор и подготовка данных  Перед тем, как углубиться в детали, хочу отметить, что дообучение GPT-подобных моделей может быть довольно сложной задачей. Тем не менее, я решил сделать еще один шаг вперед и обучить модель русскому языку.Это представляет дополнительную проблему, поскольку модели в основном обучаются на английских текстах.Учитывая, что русский - мой родной язык, у меня есть хорошая база, включающая личные переписки.Сбор данных  Я выбрал Telegram, потому что он предоставляет удобный API для сбора данных. Кроме того, он служит основной платформой для моего общения с друзьями. Этот выбор позволяет модели глубже понять уникальный стиль общения и лучше имитировать меня.Следуя документации, я написал небольшой скрипт, который загружает всю переписку из приватных чатов и сохраняет их в файл.Сначала создаём клиент Телеграмма:from telethon.sync import TelegramClient
client = TelegramClient(PHONE_NUMBER, TELEGRAM_APP_ID, TELEGRAM_APP_HASH)
client.start()Затем получаем список диалогов:def get_dialogs(limit: int | None = 100) -> list[Dialog]:
    """Get all dialogs from the Telegram."""
    dialogs: list[Dialog] = client.get_dialogs(limit=limit)
    dialogs = [dialog for dialog in dialogs if dialog.is_user]  # remove groups or channels
    logger.info(f"Found {len(dialogs)} dialogs")
    return dialogsИ под конец загружаем историю переписок:def parse_messages(dialog: Dialog, limit: int = 1000) -> list[dict]:
    """Get all messages from the dialog."""
    all_messages_list = []
    offset_id = 0
    while True:
        messages: list[Message] = client(
            GetHistoryRequest(
                peer=dialog,
                offset_id=offset_id,
                offset_date=None,
                add_offset=0,
                limit=limit,
                max_id=0,
                min_id=0,
                hash=0,
            )
        ).messages
        if not messages:
            break
        all_messages_list.extend(
            {
                "date": message.date.isoformat(),
                "message": message.message,
                "out": message.out,
            }
            for message in messages
            # Filter audio or video content
            if message.message and not message.is_bot
        )
        offset_id = offset_id = messages[-1].id
    return all_messages_listВы можете найти полный скрипт здесь.  Стоит упомянуть, что я намеренно исключил аудио- и видеосообщения из набора данных и сосредоточился исключительно на текстовом контенте. В результате некоторая информация в диалоге могла быть утеряна. Извлечение текста из таких данных - объемная тема, которая лучше подойдет для отдельной статьи.   Подготовка данных  На этом этапе вы должны трансформировать данные в инструкции для дообучения модели. Fine-tune обычно включает себя дообучение модели следовать инструкциям или выполнять другую целевую задачу (например, анализ тональности текста). ChatGPT (который начинался как fine-tuned версия базовой модели GPT-3) является типичным примером модели, которая была создана для следования инструкциям. Наборы инструкций обычно содержат три ключа: instruction, input (необязательный контекст для данной инструкции) и response от LLM. Ниже приведен пример данных инструкции:   [
    {
        "instruction": "Can cats communicate?",
        "context": "Cats need to communicate with each other for bonding, and relating with each other; they need to collaborate, play, and share resources...",
        "response": "Cat vocalizations have been categorized according to a range of characteristics...",
    }
]Схематично процесс точной настройки можно представить следующим образом:  Fine-tuning a pretrained LLM to follow instructions. Важно помнить, что вы можете изменять формат данных в соответствии со своими потребностями. Например, можете ввести функцию и попросить модель сгенерировать документацию в качестве ответа. Однако, исходя из моего опыта, модели меньшего размера (такие как 7B) могут испытывать трудности со сложными запросами.Чтобы это избежать, попробуйте упростить запросы или разбить их на ряд последовательных инструкций. Так вы сможете добиться лучших результатов и повысить производительность модели.Чтобы создать инструкции на основе моего чата, я использовал несколько подходов:Разбиение беседы на батчи, когда перерыв между двумя сообщениями превышает один день. Тогда мы рассматриваем это как начало нового диалога, следовательно, контекста из предыдущего разговора не будет.Объединение нескольких сообщений, идущих подряд от одного пользователя, в одно.Установка максимальной длины контекста для ускорения процесса обучения.Добавление меток к своим ответам и ответам собеседника, чтобы помочь модели лучше понимать контекст.Preprocessing chat messages.  Я также очистил историю чатов от конфиденциальной информации, такой как личные пароли или электронные письма.По итогу у меня получилось 51к инструкций, что вполне сопоставимо с Dolly 2.0 instruction dataset от Databricks (~15к инструкций) и Alpaca dataset (~52К инструкций).Модель  Я решил выбрать open-source large LLM Falcon от Technology Innovation Institute. Эта модель авторегрессионного декодера с двумя вариантами: моделью с 7 миллиардами параметров и моделью с 40 миллиардами параметров. Вариант модели 40B обучался на 384 графических процессорах AWS в течение 2 месяцев.Open LLM Leaderboard. Исходя из того, что известно об этой модели, архитектура Falcon очень похожа на GPT-3 и LLaMA, за исключением использования multi-query attention (Shazeer 2019) и  RefinedWeb corpus в качестве обучающего набора данных (что может быть ключом к успеху).  Точная настройка LLM с помощью LoRa  Если мы рассматриваем способы дообучения LLM (Large Language Model), одним из ценных ресурсов является статья OpenAI PALMS: Pre-training an Autoencoder Latent Model for Sequence Generation. В статье обсуждается использование fine-tuning, которая включает в себя обучение модели с использованием тех же методов, что и при первоначальном обучении, но с более низкой скоростью обучения ~ 0,1. Этот процесс позволяет обучать модель на конкретных данных, тем самым улучшая качество ее ответов в желаемой области.Помимо fine-tune существуют и другие подходы, такие как использование адаптеров. Они предполагают добавление дополнительных слоев меньшего размера к существующим слоям исходной модели, обучая только добавленные слои. Такой подход позволяет ускорить обучение, поскольку задействованные веса относительно невелики.Architecture of adapter-based knowledge injection into LLMs. Концепция LoRa черпает вдохновение из наблюдений за тем, как меняются веса матриц во время обучения, как в работе Aghajanyan et al. (2020). Эти наблюдения показывают, что матрицы могут быть приближены с использованием пространства меньшей размерности при сохранении большей части их существенной информации и структуры.Каждая матрица W представлена в виде суммы W + A * B во время обучения. Исходная матрица W заморожена, и обучаются только матрицы A и B. Следовательно, обновленные веса получаются как 