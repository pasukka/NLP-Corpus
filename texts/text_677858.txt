

Как мы обучали категоризатор фискальных чеков DataCheckEngine / Habr


              20  July   at 12:03  Как мы обучали категоризатор фискальных чеков DataCheckEngine Datanomica corporate blog System Analysis and Design *Big Data *Development for e-commerce *Machine learning *      Задача актуальна для фин. организаций и ретейла. Как мы подошли к ней и почему выбрали для обучения уменьшенную версию модели DistilBert, рассказывают наш data scientist Бондарь Андрей и владелец продукта Гриднев Владислав.Банки и интерес к чекамПредприниматели обязаны передавать информацию по чекам в ФНС — это требование 54-ФЗ. Посредниками в этом процессе выступают операторы фискальных данных (ОФД). Они же перепродают информацию о покупках банкам, которые собирают статистику об интересах клиентов и на её основе делают персональные предложения. Но есть нюанс — данные по чекам приходят в сыром текстовом виде. Каждый магазин описывает товары в произвольном формате (с сокращениями и собственными аббревиатурами), поскольку эта процедура не регламентирована 54-ФЗ. В итоге перед банками стоит нетривиальная задача по выделению и структурированию категорий товаров и брендов.Именно с таким кейсом к нам обратилась крупная финансовая организация. Проблема показалась нам интересной, плюс мы увидели в этом возможность прокачать NLP-экспертизу и поработать с новыми подходами в машинном обучении. Сегодня хотим разобрать задачу подробнее и рассказать, как мы подошли к разработке системы категоризации чеков DataCheckEngine.Последовательность действийМы разбили проблему на три подзадачи. Во-первых, по каждой позиции в чеке необходимо определить наименование продукта, однозначно отражающее его содержание — например, не «палочки», а «кукурузные палочки». Во-вторых, нужно определить категорию товара. В-третьих, вычленить объем (вес), единицы измерения и бренд. Например, вот так может выглядеть схема категорий для литровой бутылки кефира:Категории товаров. Первый справочник категорий решили собрать, опираясь на интернет-каталоги магазинов, но столкнулись с проблемами. Блоки в них зачастую пересекались друг с другом и имели различное количество уровней вложенности, что в перспективе снизило бы эффективность модели машинного обучения.Тогда мы взяли случайную выборку позиций чеков и разметили её вручную, придерживаясь двух принципов — категории должны быть уникальны и иметь всего два уровня вложенности. Разметку проводили внутренними ресурсами команды — по нашему опыту так она получается качественнее, по сравнению с результатами использования сторонних сервисов. Вообще, такой практики придерживаются многие известные компании — например, Tesla. Автопроизводитель перенес разметку данных для беспилотников в in-house формат, когда специалисты по системам ИИ работают плечом к плечу с «разметчиками».Далее, мы начали обогащать тренировочную выборку. Возник вопрос — как добавить в неё данные по недостающим категориям, если мы еще не знаем категории позиций чеков. Проблему решили двумя способами: а) вручную искали необходимые позиции по ключевым словам, б) передавали ML-модели новые порции данных и самостоятельно категоризировали ответы с низким уровнем уверенности.Расширяя выборку, важно не допустить переобучения модели. Иначе она просто запомнит конкретный список чеков и начнет ошибаться. Баланс точности и полноты алгоритма отражает F1-мера. Оптимальное значение метрики зависит от конкретной задачи — в нашем случае она составила 0,95.В итоге финальная версия справочника содержит двадцать две категории первого уровня: АвтоОдежда, обувь, аксессуарыТовары для животных   АлкогольПодарки и сувенирыТовары для здоровья   Бытовая техникаПродуктыТовары для красоты   Дача, сад и огородПрочееУслуги   Детские товарыСпорт и отдыхХобби и творчество   Досуг и развлеченияСтроительство и ремонтЭлектроника   КанцтоварыТабачная продукцияКафе, ресторан, доставкаТовары для домаНа практике они покрывают значительную часть потребительской корзины среднестатистического россиянина. Каждая категория имеет детализацию второго уровня. Она менялась по мере понимания содержимого чеков. Например, в них стали попадаться снэки, джемы и варенья — отнести эти продукты в существующие категории было проблематично. В итоге мы добавили отдельные подкатегории — «Снэки» и «Джем, мёд, варенье, сиропы и топпинги».Похожая история произошла с чаем и кофе. Напитки можно взять навынос в кафе, найти на полке или купить в бутылке — все это разные категории. Так, чай в чайничке попадет в категорию «Кафе, рестораны, доставка», чай в бутылке — «Холодный чай и кофе», а кофе навынос — «Чай, кофе с собой». Последняя категория может быть интересна банкам с точки зрения удобства клиентов, если есть планы разместить точку кофе в отделении.Вот так выглядит итоговая детализация самой многочисленной категории «Продукты» — тридцать пять подкатегорий:Безалкогольное пиво и виноМясная гастрономияБиойогурты и кисломолочные продуктыПолуфабрикатыБлюда быстрого приготовленияРыбная гастрономияВсё для выпечкиСнэкиДетское питаниеСоки и нектарыДжем, мёд, варенье, сиропы и топпингиСоль, специи, сахарДиетическое и спортивное питаниеСоусы, растительные маслаЗамороженные продуктыСухофрукты, семечки, орехиЙогурты и молочные напиткиСырная продукцияКондитерские изделияТорты, пирожные, суфле, десертыКонсервацияФрукты, овощи и грибыКрупы, бобовые, макаронные изделияХлеб и выпечкаЛимонады и газированные напиткиХлопья, мюсли, сухие завтракиМинеральная и питьевая водаХолодный чай и кофеЯйцаЧай, кофе, какаоМолоко и молочные продуктыЧай, кофе с собойМороженоеЭнергетические напиткиМорсы, кисели, компотыНаименования продуктов и бренды. Первым делом внутри позиции чека необходимо было разобраться, с каким продуктом мы имеем дело. Например, бумага может быть офисной и туалетной, а перчатки — медицинскими или кожаными. Также чеки содержали словосочетания вида «бумага для …» или «салат с …». Можно было разметить продукты в виде словосочетаний, но это трудоемкая задача. Мы применили метод n-грамм с отбросом ненужных слов.Смысл в том, чтобы настроить множество n-грамм (мы использовали до семи слов в словосочетании), а затем отфильтровать их по окончаниям, союзам и частоте. Так мы получали почти идеальные продукты для конкретной позиции чека, которые можно было передавать моделям для обучения.Например, для слова “батончик” мы получили вот такие n-граммы:'шоколадный батончик', 'батончик злаковый', 'батончик протеиновый', 
'мороженое батончик', 'батончик с арахисом', 'батончик молочный', 
'батончик фруктово-ореховый'Для слова “сливки”:'сливки питьевые', 'сливки для кофе', 'сливки для взбивания'Для слова “бальзам”:'бальзам для волос', 'бальзам для губ', 'гель-бальзам', 'крем-бальзам', 
'бальзам-ополаскиватель', 'бальзам для тела', 'оттеночный бальзам', 
'бальзам для всех типов волос', 'бальзам для окрашенных волос'Помимо развернутого описания продукта в виде n-грамм, мы возвращаем и ключевое слово, образующее название продукта. Так, для «шоколадного батончика» мы возвратим слово «батончик». Оно может служить тегом для поиска товаров в банковском приложении. Что касается брендов, то в плане разметки мы поступили похожим образом. Написали функцию на regex, которая ищет бренды в списке из 200 тыс. наименований — так мы получили почти идеально размеченные данные. Далее, после некоторой предобработки, передали в модель для обучения. Через regex также определяем меры и объемы.В то же время наш категоризатор товарных чеков умеет нормализовать текст — очищать от «мусора» и править некорректные написания компаний-производителей. Например, вот такой вот «крякозябр»:Нап с/а RED DEVIL ИнаяСила7,2% ж/б0.45LСистема восстановит как:НАПИТОК СЛАБОАЛКОГОЛЬНЫЙ RED DEVIL ИНАЯ СИЛА 7.2% ЖЕСТЯНАЯ БАНКА 0,45 ЛИТРОВЕсли говорить о точности моделей, то:F1-мера по категориям — 95.0817 % (кол-во обучение — 225415, тест — 50357)F1-мера по продуктам — 96.1165 % (кол-во обучение — 763348, тест — 84817)F1-мера по брендам — 96.4335 % (кол-во обучение — 841214, тест — 93469)Код для обучения языковой модели на выборке из 10 тыс. чеков мы выложили в открытый доступ в виде Jupyter Notebook. Там же можно найти семпл из 3 тыс. размеченных брендов для дообучения текстового категоризатора чеков в Pytorch.Железо и алгоритмыПредобучение модели проходило на 7,3 млн чеков. Для обучения применили уменьшенную версию DistilBert и библиотеку Transformers.Мы пробовали использовать CNN-модели c эмбеддингами GloVe. Да, они работают очень быстро — на один запрос уходит порядка 10 мс — но проигрывают по точности, что нас не устраивало. В свою очередь, Bi-LSTM дают сопоставимый результат по точности, но уступают по скорости — 40 мс на запрос. Измерения мы проводили на CPU в Pytorch. Библиотека зарекомендовала себя как более быстрая, по сравнению с TensorFlow.Сфера NLP уходит от классических моделей LSTM и CNN в сторону attention based models. Дистилляцией и уменьшением числа параметров модели можно добиться внушительных скоростей при приемлемой точности. Также существует тренд на экстремальную дистилляцию архитектур больших моделей.Уже есть решения вроде MiniLM и XtremeDistil-l6-h256, которые в пять-девять раз быстрее обычного BERT. К сожалению, кода для предобучения этих моделей нет в открытом доступе. Тюнинговать нашу модель на английской или мультиязычной версиях не очень хотелось, так как страдает точность. Поэтому мы и остановились на классическом, но надежном DistilBert.Что в итогеDataCheckEngine преобразует наименования позиций чеков в понятный формат. Получили достойные значения метрик категоризации на примере чеков среднестатистического потребителя с фиксированным списком категорий. В зависимости от задачи и вводных наше решение можно адаптировать для иного заказчика. В идеальном случае достаточно подставить в модель новый справочник категорий, и она заработает без переобучения. Для реализации более глубокой аналитики вроде анализа спроса на товар в конкретный момент времени потребуются дополнительные работы.Возможно, у вас возник вопрос, откуда для этого брать «живые чеки»? И как финансовые организации связывают с ними покупки клиентов? У нас есть опыт реализации таких проектов, и мы поделимся им в следующих материалах.     Tags: Датаномикамашинное обучениеDataCheckEngineкатегоризацияретейлфинансовые организациичекитоварыnlpdata science Hubs: Datanomica corporate blogSystem Analysis and DesignBig DataDevelopment for e-commerceMachine learning          


