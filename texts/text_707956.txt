

Автоматическое исправление ошибок ASR с помощью sequence-to-sequence моделей / Habr


               Автоматическое исправление ошибок ASR с помощью sequence-to-sequence моделей  Reading time  
    11 min
   Views  1.7K MTS AI corporate blog Machine learning *Reading room Artificial Intelligence Natural Language Processing * 
    Review
        Всем привет, я Алсу Вахитова — NLP-разработчица в MTS AI. Вместе с коллегами мы создаем различные алгоритмы обработки текста и извлечения информации из него. Большое количество проектов включает в себя взаимодействие с командами из “соседних” доменов, например, automatic speech recognition (ASR). Одна из таких задач - исправление ошибок в результате работы ASR методов (ASR error correction). В этой статье я приведу теоретический обзор некоторых статей, решающих данную проблему.Описание проблемыАвтоматическое распознавание речи играет важную роль в современных многоуровневых системах, построенных на основе глубокого обучения. К ним относятся, например, голосовые ассистенты или машинный перевод аудиоданных. К сожалению, довольно часто ASR методы работают с ошибками. Это происходит как из-за внешних факторов (шум, манера речи или акцент говорящего), так и из-за внутренних (недостаток доменного знания у модели). Типичные недочеты в работе ASR:Грамматические ошибки из-за плохого качества аудиосигнала:И этот час дремоты настиг  -> И этот час дано династийНекорректное распознавание фонетически схожих слов:На картине изображен зеленый луг -> На картине изображен зеленый лукНедостаток доменного знания:Ему прописали кумадин  -> Ему прописали куминДобавление или наоборот “проглатывание” слов: Опасное задание -> А опасное заданиеМы поедем в Орел  -> Мы поедем  ОрелНаличие таких ошибок в тексте может препятствовать последующим манипуляциям над распознанным текстом, например, извлечению сущностей. Постановка задачиСуществуют разные подходы к исправлению ошибок в распознавании речи. Самый очевидный, но далеко не самый простой —  улучшить ASR-модель. Также есть различные методы постобработки, они предполагают использование правил и словарей или применение машинного обучения. В этой статье я сосредоточусь на последних.На выходе из ASR-модели получается последовательность слов Х, потенциально содержащая ошибки. При наличии ground truth (оригинального текстового представления произнесенной фразы) T, необходимо найти трансформацию X->T.Эта постановка очень напоминает задачу машинного перевода с небольшим изменением: вместо языков разных стран есть входной “язык ошибок” и выходной “грамматический правильный язык”. Соответственно, в такой постановке к решению задачи можно применить классические методы машинного перевода (machine translation, MT), а именно sequence-to-sequence модели (seq2seq). Они принимают на вход последовательность элементов (слов, букв, признаков изображения и т.д.) и возвращают другую последовательность элементов.Таким образом, базовая схема работы методов выглядит состоит из следующих этапов:ASR-модель получает на вход аудиоданные, распознает их и выводит текст;Полученный текст передается на вход seq2seq-модели, которая вновь выводит тот же текст, но с исправленными ошибками, если такие находятся.В следующих блоках я представлю несколько подходов к созданию подобных моделей, которые использую в своей работе. Все эти методы были почерпнуты мной из статей в зарубежных научных изданиях.Automatic Correction of ASR Outputs by Using Machine TranslationАвторы этой статьи, вышедшей в 2016 году, одни из первых предложили решать задачу исправления ASR ошибок методом машинного перевода. Они используют два датасета: HuRIC (озвученные людьми команды для домашних роботов) и TourSG (вручную расшифрованные диалоги путешественников с турагенствами). Ниже приведена иллюстрация предложенной системы. Пройдемся по всем этапам.Архитектура предложенной системы (D’Haro and Banchs, 2016)Сперва обратимся к процессу тренировки. Авторы берут аудиофайл и распознают его с помощью Google ASR. На выходе получается список из N лучших гипотез распознанного текста. Далее ко всему списку, а также к референсной транскрипции применяются такие техники обработки текста, как приведение к нижнему регистру и токенизация. На полученных парах тренируется статистическая модель машинного перевода (напоминаю, что это все еще 2016 год).На инференсе обработанный список из N лучших ASR-гипотез отправляется в уже натренированную модель, которая в свою очередь переводит каждый элемент списка на “грамматически правильный” язык. Переведенный список проходит через статистическое ре-ранжирование (Minimum Bayes Risk Decoding). Лучший кандидат из списка считается финальной откорректированной фразой.В качестве надстройки над основным алгоритмом авторы также предлагают на этапе обработки текста переводить в его в фонетическое представление с помощью алгоритма Dual Metaphone. Таким образом модель машинного перевода обучается не просто на неправильном-правильном языках, а на неправильном-правильном фонетических языках.Результаты работы алгоритма были подсчитаны с помощью метрики CER (character error rate, процент неправильно предсказанных символов). Ниже приведена таблица с результатами на разных частях двух датасетов.Результаты работы системы (D’Haro and Banchs, 2016)Видно, что комбинация двух моделей, совместно с ре-ранжированием, дает уменьшение CER везде, кроме тест-части датасета HuRIC. Я включила эту статью в обзор, потому что бывает полезно вспомнить, какими методами задачи решались в донейронные времена. И как мы видим, проблема исправления ошибок ASR была и остается актуальной.ASR Error Correction and Domain Adaptation Using Machine TranslationАвторы этой статьи предлагают одно из самых простых решений проблемы: использование рекуррентной сети (кодера-декодера) в комбинации с механизмом внимания для перевода последовательности с ошибками в правильную последовательность. Как и раньше, модели тренируются переводить из “ошибочного” языка ASR модели в “правильный”.Важно заметить, что в этой статье используются медицинские данные. Это одно из самых сложных направлений в сфере ASR error correction, поскольку именно транскрибация разговоров с/между медиками приводит к наибольшему количеству ошибок из-за большого количества доменной лексики. Авторы не указывают, какой конкретно датасет используется, но описывают его как 288,475 реплик из разговоров пациентов с докторами. Пример того, какой текст произносился, и как его распознал Google ASR (Mani et al., 2020)Здесь в качестве базовой ASR-модели снова используется Google ASR, а также модель с открытым кодом ASPIRE. Для оценки результатов авторы используют метрику WER (word error rate, процент неправильно предсказанных слов) и стандартную метрику машинного перевода BLEU (грубо говоря, доля правильно предсказанных последовательностей 1-4 слов). Ниже приведена таблица с результатами работы алгоритма.Результаты распознавания ASR до/после исправления ошибок (Mani et al., 2020)Видно заметное улучшение обеих метрик. Таким образом, данная статья иллюстрирует, как с помощью простой нейронной сети можно адаптировать готовую ASR-модель к доменной лексике.Remember the Context! ASR Slot Error Correction Through MemorizationЭта статья одна из самых интересных и сложных для понимания, но однозначно стоит потраченного на разбор времени. Авторы предлагают в одной архитектуре объединить текстовые и фонетические репрезентации, а также поиск по хранилищу методом k-ближайших соседей (k-NN, k-nearest neighbors algorithm). Ниже приведена иллюстрация архитектуры, схема создания хранилища и логика инференса.Предложенная авторами PAT модель с k-NN аугментацией из хранилища данных. Левая часть фигуры - архитектура модели, правая нижняя иллюстрирует процесс создания k-NN хранилища данных. Правая верхняя часть демонстрирует логику инференса (Bekal et al., 2021)Начнем с архитектуры модели. Авторы используют Phone Augmented Transformer (PAT, фонетически аугментированный трансформер). Он состоит из двух стандартных трансформерных кодеров — текстового и фонетического. Кодеры принимают на вход соответствующие последовательности и выдают скрытые представления, которые по очереди встраиваются в декодер, последовательно декодирующий выходную последовательность.На иллюстрации видно, что есть два пути из декодера. Первый — стандартная комбинация линейного слоя и софтмакс функции, позволяющая выбрать наиболее вероятный токен для продолжения выходной последовательности. Второй же путь ведет в еще один механизм внимания с софтмаксом. Это так называемый шаг запоминания, а именно создания вектора-ключа для хранилища. Во время тренировки модели все тренировочные слова проходят через этот шаг запоминания и пара  вектор-ключ - слово сохраняется в хранилище.На этапе инференса входная последовательность снова проходит через два пути в декодере. Первый дает вероятности следующих слов. Второй вновь дает вектор, который на этот раз используется для поиска по хранилищу как вектор-запрос (query). Среди всех векторов-ключей при помощи алгоритма k-NN находятся ближайшие ключи, а их значения становятся потенциальными кандидатами. Далее вероятности, полученные из двух путей, складываются, и лучший токен продолжает декодируемую выходную последовательность.Таким образом хранилище — еще один способ запомнить соответствие ввода (комбинации текста и фонем) выводу (ground truth тексту). Такая техника дает значительное улучшение метрик, что мы и увидим далее.Авторы не используют готовый датасет, а синтетически генерируют свой. Для этого названия городов, аэропортов, штатов, улиц и т.д. комбинируются с различными фразовыми паттернами (например, “я лечу из X в Y”), а далее озвучиваются алгоритмом синтеза речи (text-to-speech, TTS) AWS Polly. Авторы не указывают, какая конкретно ASR модель была использована, но называют ее “стандартной”. Тренировка-оценка проходят как на комбинированном датасете, так и на разделенном на разные домены (например, только названия улиц). Для оценки используются WER, precision (точность) и recall (полнота). Ниже приведена таблица с результатами.Сравнение результатов обученных PAT (без хранилища) и k-PAT (с хранилищем) моделей на разных доменах (Bekal et al., 2021)К сожалению, авторы не привели метрики вывода только ASR-модели, остается только предположить, что они хуже. Из таблицы выше видно, что использование k-NN хранилища дало значительное улучшение результатов по всем доменам и всем метрикам. Ниже таблица с конкретными хорошими-плохими примерами работы ASR, PAT и k-PAT.Примеры тестовых фраз сгенерированных ASR, PAT и k-PAT (Bekal et al., 2021)Эта статья является хорошим примером сложной архитектуры, сочетающей в себе как глубокое обучение (трансформер), так и алгоритм из классического машинного обучения (k-NN). Предложенная архитектура достаточно сложная как для понимания, так и для реализации, но дает отличные результаты.Clinical Dialogue Transcription Error Correction using Seq2Seq ModelsВ этой статье вновь исправляются ошибки в диалогах между пациентами и врачами, или просто между медиками. Однако авторы поставили перед собой интересную и сложную задачу. Они собрали совсем небольшой датасет разговоров на медицинские темы, Gastrointestinal Clinical Dialogue Dataset (GCD), состоящий из всего 329 озвученных реплик. Очевидно, что на таком крохотном наборе данных невозможно что-либо обучить, поэтому авторы пошли на некоторые хитрости.В качестве sequence-to-sequence моделей были использованы два предобученных трансформера: T5 и BART (в данном обзоре я не буду останавливаться на разборе их архитектур, потому что они и так известны всем, кто занимается задачами в области NLP). За неимением достаточного количества данных для перевода из “ошибочного” языка ASR модели в “правильный” авторы решили файнтюнить модели на трех других задачах: генерация краткого содержания (суммаризация), парафраз и предсказание маскированных слов. Гипотеза авторов состоит в том, что таким образом можно “познакомить” языковые модели с доменной лексикой, что поможет им в исправлении ASR ошибок, хоть они и не были обучены этому напрямую.Далее авторы собрали заголовки и абстракты статей из базы данных PubMed. Для задачи суммаризации были использованы пары абстракт-заголовок. Для обучения парафразу заголовки прогнали через уже обученный этому отдельный T5, таким образом получив пары заголовок-перефразированный заголовок. Для обучения предсказанию маскированных слов в заголовках четверть слов заменили на маски.В качестве базовых ASR-систем были использованы четыре коммерческие модели: AWS Transcribe, Microsoft, IBM Watson, Google. Ниже представлены WER-метрики транскрибации GCD датасета каждой из моделей.WER оценка транскриптов GCD датасета для каждой ASR модели (Nanayakkara et al., 2022)Получив транскрипты от ASR-моделей, авторы прогнали их через зафайнтюненные трансформеры. Результаты представлены в таблице ниже.Сравнение зафайнтюненных моделей (Nanayakkara et al., 2022)Метрики ожидаемо неровные: результат работы Google ASR обеим моделям удалось улучшить, в то время как AWS Transcribe в обоих случаях ухудшился. Несмотря на весьма скромные показатели, в целом эта статья демонстрирует интересный и нестандартный подход к решению проблемы, поэтому я не смогла пройти мимо нее. Error Correction in ASR using Sequence-to-Sequence ModelsПоследний подход, про который я расскажу в обзоре, вновь инкорпорирует фонетические данные в seq2seq-модель, а также предлагает техники аугментации данных, которых, как обычно, недостаточно.Авторы опираются на тот факт, что большое количество ASR-ошибок происходит из-за схожести произношения слов. Поэтому они предложили архитектуру, которая на вход получает не только текстовую репрезентацию, но и фонетическую - RoBART (robust BART - устойчивый BART).Фонетическая репрезентация вывода ASR-модели создается с помощью grapheme-to-phoneme (G2P) инструмента. Известные слова он находит в словаре, а для незнакомых (OOV, out-of-vocabulary) слов последовательность фонем предсказывается с помощью натренированной нейронной сети. Текстовая и фонетическая последовательности соединяются и направляются на вход в seq2seq-модель.Базовая ASR-модель была создана с помощью библиотеки ESPnet. В качестве источника тренировочных данных используется датасет CommonVoice, состоящий из ~119 тысяч расшифрованных аудиозаписей (из которых примерно одна пятая была произнесена не американцами - non-US). Авторы также предложили три техники аугментации данных.На датасете  LibriSpeech-960-hr была натренирована дополнительная ASR-модель wav2vec2. Таким образом один и тот же аудиофайл можно было распознавать двумя моделями. Это дало возможность seq2seq-модели выучить ошибки, произведенные разными архитектурами.Во время тренировки базовой ASR модели была сохранена частично натренированная модель. Данный подход авторы назвали Weak ASR (“слабый” ASR). Как и в первом пункте, этот метод аугментации давал альтернативное распознавание аудиофайла. Но в данном подходе ставка делалась на увеличение количества разнообразных ошибок, на которых должна выучиться seq2seq модель.Третий способ аугментации вообще не предполал использование ASR-модели. Из CommonVoice датасета сразу брались правильные транскрибации аудиозаписей. Далее случайные слова заменялись случайными схожими по произношению словами (Synthetic1 подход) или словами, схожими и по произношению и по написанию (Synthetic2 подход).Схема предложенной архитектуры RoBART (Dutta et al., 2022)В качестве seq2seq-модели использовался натренированный трансформер BART. Далее он файнтюнился с каждой техникой аугментации с/без фонемными репрезентациями. Результаты оценивались с помощью метрики WER. Ниже таблица с результатами.WER различных конфигураций RoBART (Dutta et al., 2022)BART pretrained - вывод BART без какой-либо дополнительной тренировки. Ph и NPh означают, что входная последовательность в RoBART соответственно была/не была соединена со своей фонетической репрезентацией. Из таблицы можно сделать вывод, что синтетические аугментации не дают эффективного улучшения качества. В то же время, добавление фонетических данных и дополнительных способов распознавания существенно снижают WER.Эта статья демонстрирует простой подход к инкорпорации фонетических данных в ввод seq2seq модели, а также предлагает несколько вполне рабочих техник аугментации данных.ИтогиВ данном обзоре представлены несколько разных и интересных способов корректировки ошибок ASR-моделей. Поскольку все они использовали разные данные, сложно оценить, какой метод является самым лучшим. Есть более простые варианты, а есть и многоэтажные архитектуры, с фонетическими данными и без - словом, подходы на любой вкус. Одним из главных факторов, тормозящих их применение и в целом развитие этого направления, является существенный недостаток доменных данных. Авторы материалов по-разному стараются справиться с этой проблемой: генерация искусственных данных, обучение на чисто текстовых данных, использование альтернативных моделей распознавания - и получают, как мы увидели, различные результаты.Надеюсь, вам был полезен мой обзор. Делитесь своими подходами к исправлению ASR-ошибок, оставляйте комментарии :)Библиография[1] D’Haro, L. F. and Rafael E. Banchs. “Automatic Correction of ASR Outputs by Using Machine Translation.” Interspeech (2016).[2] Mani, Anirudh et al. “ASR Error Correction and Domain Adaptation Using Machine Translation.” ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2020): 6344-6348.[3] Bekal, Dhanush et al. “Remember the Context! ASR Slot Error Correction Through Memorization.” 2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU) (2021): 236-243.[4] Nanayakkara, Gayani et al. “Clinical Dialogue Transcription Error Correction using Seq2Seq Models.” ArXiv abs/2205.13572 (2022).[5] Dutta, Samrat et al. “Error Correction in ASR using Sequence-to-Sequence Models.” ArXiv abs/2202.01157 (2022).      Tags: asrnlpmldeeplearningmachinelearningartificial intelligence  Hubs: MTS AI corporate blogMachine learningReading roomArtificial IntelligenceNatural Language Processing          


