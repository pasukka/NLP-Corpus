

GPT агент для запросов к большим структурированным документам с «пошаговым сохранением информации» / Habr


               GPT агент для запросов к большим структурированным документам с «пошаговым сохранением информации» Level of difficulty  
    Easy
   Reading time  
    3 min
   Views  2.7K Machine learning *Artificial Intelligence Natural Language Processing * 
    Opinion
        Midjourney prompt: step by step knowledge increments in artificial consciousnessХотел бы продемонстрировать сообществу экспериментальный подход к решению проблемы ограниченного размера контекста в GPT-4. Модель GPT-4 имеет ограничение в 8 тысяч токенов (32 тысячи токенов пока еще недоступны?), что эквивалентно примерно 32 Кбайт английского текста (128 Кбайт для 32 тысяч токенов). Это ограничение подразумевает, что суммарный размер вашего запроса и ответа модели должен быть в пределах этих ограничений. В результате модель не может отвечать на вопросы о больших документах (или обширных программных проектах), так как они не умещаются в контексте модели.Типичное решение этой проблемы - подход с использованием "embeddings" (представление смысла текста в виде числовых векторов). Подробнее об этом методе можно, например, прочитать в этой статье. Однако этот метод имеет ограничения в плане точности, и сгенерированный контекст часто является фрагментированным, что приводит к снижению качества ответов.Метод, который я хотел бы представить здесь, вдохновлен тем, как люди изучают большие, структурированные документы. Сначала мы определяем наиболее релевантные разделы для целевого вопроса, изучая оглавление. Затем мы просматриваем документ раздел за разделом, сохраняя актуальную информацию и игнорируя нерелевантный контент.В этой статье я попытаюсь воспроизвести этот метод, используя ChatGPT. Для упрощения процесса мы рассмотрим небольшой программный проект на JavaScript вместо документа. Для понимания концепции не требуется знание программирования.Код:function a(v) {
    return b(v) + c(v)
}
function b(v) {
    if (v < 10) {
        return 2 * v
    } else {
        return 0
    }
}
function c(v) {
    return v * v
}
console.log(a(5))Вопрос: сколько будет a(5)? Правильный ответ: 35.Первый промпт:Вы - разработчик программного обеспечения с ограниченной памятью, способный запоминать код только одной функции и краткие сведения о ранее просмотренных функциях. Ваша задача - найти результат a(5) в файле на JavaScript, содержащем три функции: a(v), b(v) и c(v). Вы должны выяснить это через ряд шагов. На каждом шаге вы можете вспомнить код функции, о которой просили ранее, и связанную с вопросом информацию, которую вы поняли и сохранили ранее.код функции: пока нет. это первый шагкраткие сведения: пока нет. это первый шагКакую функцию (только одну) вы хотели бы увидеть на следующем шаге? Какую актуальную информацию вы собрали на данный момент, и что бы вы хотели запомнить для предстоящего шага? У вас есть ответ на начальный вопрос?Модели необходимо определить функцию для анализа на следующем шаге и резюмировать информацию, касательно целевого вопроса, которую она собрала и обобщила на данный момент.Ответ модели:Она запрашивает код a(v), и пока не хочет ничего сохранять.На следующем шаге мне просто нужно скопировать и вставить предоставленные моделью данные в новый запрос. Затем я открываю НОВУЮ сессию чата (с пустым контекстом) и повторяю процесс:Ответ:Ей нужен код b(v), также она успешно сохранила логику функции a(v).Промпт (только измененная часть):Ответ:Промпт:Ответ:Это правильный ответ!Этот пример иллюстрирует, как ChatGPT-4 может одновременно выбирать подходящую стратегию решения проблем и собирать релевантную информацию.Хотя в этом эксперименте используется очень простой код и вопрос, в других тестах я получал более сложные ответы для реального кода в 400 строк, используя примерно те же условия эксперимента.Достоинства метода:потенциально практически неограниченная масштабируемость. GPT агент, использующий этот метод, может исследовать обширные программные проекты, перечисляя файлы в различных папках и обрабатывая их, возможно, по частям, если файлы большие. Этот подход также может быть применен к списку документов или любой базе знаний.потенциально высокое качество результатов. По крайней мере в сравнении c методом основанным на "embeddings" Недостатки:высокая стоимость и невысокая скорость. Метод не переиспользует информацию полученную в процессе ответа на текущий вопрос для ответа на последующие вопросы. Потенциально можно решить организовав еще один уровень памяти релевантный не к текущему вопросу, а к документу / программному проекту вообще.высокие требования к интеллекту модели. Подобный эксперимент не работает с ChatGPT-3.5. А для более сложных вопросов интеллекта ChatGPT-4 тоже начинает не хватать и он начинает терять информацию о ранее просмотренном и просто зацикливается.Так как у моделей, очевидно, никогда не будет неограниченного по размеру контекста - я считаю, что с будущими версиями GPT (и их конкурентами),  имеющими более сильную логику, а также более низкую стоимость обработки информации, некая форма этого метода может быть эффективно применена к реальным задачам.      Tags: NPLembeddinchatgptopenaigpt-4javascript  Hubs: Machine learningArtificial IntelligenceNatural Language Processing          


