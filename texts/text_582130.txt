

AntiToxic Bot — бот, распознающий токсичных пользователей в телеграм чатах / Habr


              7  October  2021 at 12:43  AntiToxic Bot — бот, распознающий токсичных пользователей в телеграм чатах Python *Natural Language Processing * 
        Sandbox
           Что меня побудило это делать?Есть известная проблема с токсичными людьми в чатах. У модераторов чатов не всегда получается отслеживать и банить токсичных людей, хотелось бы автоматизировать процесс.Стек проектаВесь проект будет писаться на python, с использованием библиотек pytorch и pyTeleramBotApi.Разделение проекта на этапыЯ разделил проект на 3 этапа.1 этап - написать телеграм-бота, который ведёт статистику о токсичности пользователей, написать определение токсичности по простейшим правилам.2 этап - найти датасет с токсичными комментариями, выбрать архитектуру нейросети, написать нейросеть, обучить нейросеть.3 этап - отладить телеграм бота в большом чате.1 Этап - написание ботаСначала я написал обычного телеграм бота, который собирает и выводит статистику, и уведомляет  админа чата о токсичных пользователях, если их рейтинг < -5. На первом этапе для определение токсичных предложений я решил использовать поиск матерных слов.Пример вывод статистикиПример уведомления2 Этап - написание и обучение нейросетиПеред тем, как начать писать и обучать нейросеть, я нашёл датасет на kaggle с токсичными комментариями. В датасете около 14000 сообщений и 2 класса(токсичный, позитивный)Следующий шаг. Надо выбрать архитектуру нейросети. Я остановился на CNN + GRU.Архитектура нейросетиДальше я поставил нейросеть обучаться на Google Colab`e. Нейросеть обучилась за 30-45 минут.После обучения нейросети я построил табличку, где показано, как справились другие варианты классификации токсичных сообщений.ИмяaccuracyprecisionrecallCNN+GRU0.90.90.85CatBoost0.860.750.83Rules (проверка на матные слова)0.660.690.53Осталось, только интегрировать нейросеть в бота.3 этап - отладка проектаЯ запустил своего телеграм бота в чат с 65 людьми. В течение 3 дней у бота были обнаружены небольшие баги, которые были исправлены.ИтогПример обработки сообщенийБот более-менее справляется со своей задачей, но иногда нормальное сообщение определяет, как токсичное. Эта проблема решается, нахождением датасета побольше и усложнением архитектуры нейросети, но при усложнении архитектуры ресурсов Google Colab`а может не хватить.СсылкиРепозиторий проектаБот в телеграмме2 Часть - Немного об архитектуре нейросети бота    Tags: нейросетьнейросети и machine learningботы для мессенджеровтоксичные сообщенияклассификацияпроект Hubs: PythonNatural Language Processing          


