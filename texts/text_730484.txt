

Nvidia совместно с Корнельским университетом создала ИИ-модель для превращения текста в видео под названием VideoLDM / Habr


               Nvidia совместно с Корнельским университетом создала ИИ-модель для превращения текста в видео под названием VideoLDM  Reading time  
    1 min
   Views  1.7K Working with video *Artificial Intelligence IT-companies       Nvidia рассказала о новой ИИ-модели для превращения текста в видео под названием VideoLDM. Эту модель производитель видеокарт разработал вместе с Корнельским университетом. Модель способна генерировать видео в разрешении до 2048 × 1280 пикселей с частотой 24 FPS и длительностью 4,7 секунд на основе текстового описания. В основе VideoLDM заложены наработки нейросети Stable Diffusion.У ИИ-модели 4,1 млрд параметров, 2,7 млрд из них использовали на видео для тренировки. С помощью подхода к модели скрытой диффузии (LDM — Latent diffusion model) разработчики создавали  видео высокого разрешения с высоким качеством.В VideoLDM есть генерация персонализированного видео и свёрточный синтез во времени. Временные слои (обученные в VideoLDM для превращения текст в видео) вставляются в опорные сети LDM изображений. Изображения заранее настроены в DreamBooth. Модель может генерировать сцены вождения. Такие видео имеют разрешение 1024 × 512 точек и длительность 5 минут. Если нужно моделирование конкретного сценария вождения, за основу берутся ограничивающие рамки для создания нужной обстановки. Далее синтезируется начальный кадр, а затем создаются правдоподобные видеоролики. Кроме того,  модель делает мультимодальное прогнозирование сценариев движения, сгенерировав несколько правдоподобных развёртываний на основе начального кадра.      Tags: nvidiaКорнельский университетии-модельldmVideoLDMdreamboothstable diffusionнейросетьработа с видео  Hubs: Working with videoArtificial IntelligenceIT-companies          


