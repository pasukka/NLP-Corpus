

Синтезируем голос бабушки, дедушки и Ленина + новости нашего публичного синтеза / Habr


              21  October  2021 at 13:55  Синтезируем голос бабушки, дедушки и Ленина + новости нашего публичного синтеза Machine learning *Start-up development Sound Natural Language Processing *      
На Хабре часто висят в топе: политика и очередные запреты, трактор, ну и конечно сенсационные новости про "очередные достижения AI". Также журналисты маркетологи любят перепечатывать нормальные статьи наподобие этой но под максимально кричащими заголовками в духе "AI поработит мир, ваш голос уже украли".
Не секрет, что имея бюджет на вычисления в единицы или десятки миллионов долларов, напоказ достичь можно многого. Но реальность как правило оказывается более сложной и прозаической.
Вопреки этому тренду, в этой статье мы постараемся на пальцах и близко к народу:

На реальных примерах показать возможности генерации голоса на малом числе данных или на данных с неидеальным качеством;
Немного порассуждать на тему цифровых памятников (это чем-то похоже на интерактивные или трехмерные фотографии), сделанных из голоса человека;
Также немного порассуждать на тему того, какую объективную опасность это представляет для общества;

И также мы конечно поделимся новостями нашего публичного синтеза речи.
Границы возможного
Сейчас вовсю лютует эпоха пост-модернизма. Тренд на утерю рационального мышления принял системный характер. Развитие Интернета скорее привело не к массовому распространению "fake news", а скорее массовой низкопробной фантастики (самый яркий пример — Hyperloop), которая согласуется с чаяниями обычных граждан. Скорее получается не "fake news", а усилитель неграмотности с локальной спецификой. Я постоянно вижу какие-то новости на тему того, что или кого должны уже заменили роботы сильный ИИ нейросети. Отсюда также растут тренды про плоскую землю, чипирование, вышки 5G и прочее мракобесие.
Хорошая актуальная иллюстрация на злобу дня — маркетинговые материалы OpenAI против более менее вменяемых попыток повторения от комьюнити:

Но если вернуться к нашей реальности, то в современной парадигме машинное обучение — это скорее сжатие данных. Фотографии уже как более века не являются диковинкой (и в современном понимании тоже являются сжатыми данными, тот же JPEG — это максимально популярный пример). Трехмерные фотографии (голограммы) — на самом деле в самом примитивном исполнении — тоже есть везде (стикеры, магнитики и вкладыши). Фотографии с картой "глубины" до недавнего времени требовали специального оборудования. Но сейчас появляются смартфоны с такими камерами и ее восстанавливают (точнее галлюцинируют) те же нейросети. 
В самом-самом эпизоде сериала Черное Зеркало "White Christmas" четко прослеживается идея цифрового посмертия и сохранения каких-то цифровых артефактов.
Сейчас такими артефактами обычно являются фотографии, аудио и видео. Но как правило, такие артефакты не являются интерактивными. Появляются алгоритмы для анимации лиц и / или фото. Но что если рассмотреть сам голос непосредственно как некоторую "открытку" или привет из прошлого от некоего человека? Вы не можете заставить такую открытку саму говорить то, что бы говорил реальный человек (говорящие про "мышление" нейросетей люди просто лукавят), но голос может быть узнаваем или даже неотличим от реального при каких-то условиях.
В принципе "успехи" так называемых больших языковых моделей (LLM) могут сделать примеры из Черного Зеркала с созданием полных цифровых аватаров людей чем-то извращенно похожим на реальность. Но при детальном общении они будут рассыпаться буквально через 1-2 фразы и в лучшем случае пока будут примером грубой "китайской комнаты", которая сделала лишь один маленький шаг от бредогенераторов. Но голос, если вынести за скобки огромную палитру человеческих эмоций и интонаций, сохранить в принципе можно уже более менее точно и неотличимо.
Отдельный философский вопрос возникает: вот я сделал "копию" голоса близкого человека, но что будет с этим файлом через 50 лет? С одной стороны веса нейросети так и останутся матрицами, но все теперешнее окружение (например PyTorch) скорее всего уже уйдет в небытие. Возникает некая аналогия с тем, что HiFi электроника из 70х является условно самодостаточной (если есть розетка 220V и заменить резиновые ремни), а современные "подписочные сервисы" не будут найдены археологами. По этой причине интересно будет посмотреть на маркетинговые материалы инвестиционных стартапов, которые рано или поздно возьмутся за такое дело. 
Будут ли они предлагать саппорт на 1 год, 5 лет, 50 лет, или будут как обычно все умалчивать и потом тихо пропадать? Логичной кажется конечно генерация большого количества каких-то неслучайных (?) фраз и просто хранение их тупо на диске или в какой-то физической оболочке. Например, если человек записал книгу или статью, можно ее озвучить и показывать потомкам.

Критерии успеха при создании голоса
В течение последних нескольких месяцев мы сделали несколько пробных и не очень проектов и выделили основные критерии, которые влияют на качество синтезированного аудио (сначала самые важные):

Качество и количество аудио;
Качество и свойства самого голоса, четкая дикция, консистентность (мы не умеем сохранять всю палитру эмоций); 
Соответствие канонам произношения и соответствие фонем их типичному произношению, точность произнесенного написанному (да, внезапно);
Похожесть на существующих спикеров и наличие базы "идеальных" спикеров на нужном языке;

В прошлой статье мы приводили примеры запуска похожих голосов и даже более менее похожих голосов на разных языках "с холодного старта" и "с теплого старта" (пример чего-то относительно похожего в литературе). В этот раз мы уже провели сильно больше экспериментов и у нас сложилась некоторая более связная картинка мира.
В прошлых статьях мы подметили, что ударение сильно повышает качество синтеза для русского языка, а фонемы как будто не очень. Поигравшись с языками народов СНГ, также мы обратили внимание на сильную "фонетическость" записи некоторых языков (особенно на кириллице, когда письменный язык делали лингвисты не так давно). В каком-то смысле это также применимо к немецкому и испанскому. 
Картинка сложилась, когда мы пробовали тренировать модель "с теплого старта", когда целевой спикер говорит по-английски, а спикер-донор — по-русски. Предсказуемо, так просто не работало даже с теплого старта при прочих равных и похожих голосах. При более детальном рассмотрении оказалось, что у русского, испанского и немецкого языков очень похож набор фонем, в отличие от английского.
Чтобы не растекаться мыслью по древу, сведу все итоги по абстрактным типам экспериментов в одну несколько упрощенную таблицу:



Номер
Старт
Качество / дикция / шум
Количество аудио
Фонетика
Качество




Яндекс
Холодный
Диктор с "войс-коучем"
40 часов
В примерах был русский
4-5+


(1)
Холодный
Хорошее, диктор
3+ часов (лучше 5)
Любой язык
4-5


(2)
Теплый
Хорошее, диктор, нет шума
От 5-15 минут
Тот же язык и диалект
~4


(3)
Теплый
Среднее, нет дикции, мало шума
От 5-15 минут
То же, но голос похож
4-, артефакты


(4)
Теплый
Среднее, нет дикции, мало шума
20-30 минут
То же
4-


(5)
Теплый
Голос В.И. Ленина
15-20 минут
То же
3-


(6)
Теплый
Хорошее, голос диктора
3+ часов
Другой язык, похожая фонетика
4


(7)
Теплый
Среднее, дикция "плавает"
15-20 минут
Другой язык, не похожая фонетика
не работает


(8)
Теплый
Среднее, дикция "плавает"
15 минут
Тот же язык, разный акцент
4-


(9)
Холодный
Хорошее, голос 1 диктора
15 минут
Любой язык
не работает


(10)
Холодный
Хорошее, много дикторов
10+ часов
Любой язык, дикторы похожи
4+



Что интересно, в случае (6) пол, язык и похожесть голоса особой роли не играют, если язык похожий по звучанию. Если построить ментальную модель происходящего, то усилия дикторов можно экономить имея в загашнике много дикторов даже не с похожими голосами, а с похожими соответствиями между произносимыми звуками и "фонемами", которые с листа читает диктор. Простым языком — похожий диалект / акцент / набор часто произносимых фонем. 
Ну то есть грубо говоря, если вы хотите сделать максимально качественную модель для людей, говорящих на индийских языках или на английском с индийским акцентом на малом числе данных, вам надо иметь данные не с идеальным британским произношением, а с произношением похожим на целевой домен. В ретроспективе это кажется очевидным, но в процессе постановки экспериментов гипотез была тонна.
Примеры
Мой голос на малом числе плохого аудио
Вводные:

Мало аудио (около 12 минут после чисток);
Плохое качество (пьезо-микрофон в гарнитуре);
В оригинале это был недельный звонок в Телеграме, я говорил быстро и без дикции;


Теплый старт на нормальном количестве аудио
Вводные:

Известный язык (русский), без акцента и прочих сложностей;
Нормальное количество аудио (от 5 минут до нескольких часов);
Хорошее качество и микрофон, но шум на фоне;
Не очень хорошая дикция;


В.И. Ленин
Вводные:

Мало аудио, аудио записано около 100 (!) лет назад (в 1919—1921 годах);
Для аудио столетней давности, качество очень высокое;
Шума на фоне не слышно, но есть сильные артефакты записи (пластинки или цилиндра);
Очень своеобразная манера разговора, длинные фразы, небольшие проблемы с дикцией;
Поскольку дедушка Ленин этими речами поднимал людей на трудовые подвиги, речь очень "неровная" и отчасти эмоциональная;


Голоса бабушки и дедушки

Мало аудио (20-30 минут на человека);
Средней руки микрофон (3000 рублей), небольшой шум и эхо;
Записывали мои бабушка и дедушка. Они уже в возрасте, поэтому это вносит некие коррективы;
Синтез немного хромает, но очень четко передает манеру их речи;
Они оба не далеко не дикторы, но старались просто четко литературно читать предложения без особых изысков;


Более качественное говорение на другом языке

Самая главная недавняя находка наших изысканий — дикторы могут говорить на других языках гораздо качественнее;
Тут приведен самый яркий пример этого прогресса на английском языке. Просто послушайте;
Примеры даны парами — сначала аудио примерно соответствующее нашей старой публичной мультиспикерной модели, а потом новая улучшенная модель;


Более качественное говорение на другом языке 2

Аналогичный пример, но с другими языками;


Существует ли массовая опасность со стороны "ИИ"
Короткий ответ именно для вас — пока вероятно нет.
Длинный ответ — it depends. Наши примеры и опыт (у нас не по 10-30 фразам конечно, но 5-15 минутам, что тоже немного) и примеры из статьи подсказывают, что:

Ключевым является именно качество аудио, его все-таки надо еще где-то взять (аудио и видео с хорошим звуком люди обычно не постят направо-налево);
У реальных продакшен систем там относительно низкие шансы успеха атак даже на качественных студийных аудио;
При атаке на другом языке / акценте / диалекты шансы успеха еще падают;
В случае простых атак… можно просто записать голос и проиграть, зачем париться (и почему мы не слышали про массовое применение таких атак);

Ну то есть получается, что сделать качественную копию вашего голоса неотличимую от вашего голоса по телефону можно. И мы это неоднократно демонстрировали даже на относительно малом числе аудио.
Но чтобы постоянно атаковать миллионы людей подходят наверное только zero-shot системы. А они ограничиваются тем, что нужно во-первых разбираться в них (а публичные системы всегда хуже чем коммерческие), а во-вторых все-таки надо собрать качественные примеры аудио для всех атакуемых.
Наверное в случае какой-то массовой дыры в горячо любимой всеми социальной сети такой сценарий отдаленно возможен, но почему тогда идти по сложному пути, когда просто фишинговые письма + вирусы + СМС кажутся гораздо более эффективным инструментом "сужения" воронки. А голосовые интерфейсы все-таки еще не нашли массового применения. Наверное потому, что разумные люди понимают, что голос — это не уникальный ключ, и существуют люди, которые умеют имитировать чужие голоса.
И на всякий случай очевидная мысль — если ваш банк использует голос в качестве единственного (а не составного ключа, допустим из телефона, 2FA и SMS) ключа — то немедленно бегите. А если проверка еще text-independent (то есть сказать можно любую фразу) или только по одной фиксированной не меняющейся фразе (без какого-то сценария в духе "прочитайте эти три слова или решите капчу 2 + 3 = ?"), то это обходится банально записью одного телефонного разговора с вами по нужному сценарию. По этой причине — не только не берите трубку, когда вам звонят из "службы поддержки Сбербанка", но если взяли — не говорите ни в коем случае и не ведите пространные беседы.
Новости нашего синтеза
Публичные голоса народов СНГ
Вместе с комьюнити мы сделали и опубликовали полностью уникальные модели языков народов СНГ:

Башкирский (aigul_v2);
Калмыцкий (erdni_v2);
Татарский (dilyara_v2);
Узбекский (dilnavoz_v2);

Мы также попробовали сделать украинский голос на публичных данных (из аудиокниг), но там получилось весьма посредственное качество (все остальные голоса люди записали с нуля). 
Некоторые модели звучат почти идеально, некоторые похуже. Обычно это связано со стабильностью дикции. Но поскольку дикторы участвовали в этом на общественных началах, сложно было приставлять к ним "войс-коучей" и вообще стоять над душой.
На каждый голос мы использовали от 1 до 6 часов записей. Это модели без автоматической простановки ударения, они чуть быстрее как и все V2 модели.
К сожалению пока публичного украинского языка не будет, но просто в качестве дразнилки, вот пример того как это может звучать (автор голоса не разрешил нам публиковать модель) на голосе профессионального диктора:

Воспользоваться моделями можно по ссылке или напрямую в Colab .
Улучшенные и приватные голоса
Когда мы делали публичный релиз нашего синтеза номер два у нас был нелегкий выбор между:

Работой с комьюнити, чтобы создать хоть какие-то голоса народов СНГ;
Увеличение скорости (которое всё еще не вышло сделать до конца);
Качеством существующих голосов;

В силу малого количества свободных ресурсов, мы решили пожертвовать качеством публичных моделей. И в ретроспективе мы не прогадали, так как потом люди стали присылать ссылки на паблики в социальных сетях, где люди пытаются "учить" других людей, как заниматься телефонным мошенничеством с использованием наших голосов. Понятно, что паблики эти условно мертвые (40 подписчиков), но направление мысли в принципе понятно и коррелирует с трендами.
По этой причине скорее всего максимально качественные модели на русском языке (особенно для своих коммерческих голосов) выкладывать мы больше не будем.
Тем не менее максимально возможное качество получилось еще улучшить, послушайте:


Дальнейшая работа
С тех пор данных для синтеза на разных языках у нас стало сильно много (больше, чем железа), но мы решили полностью сконцентрироваться на так сказать technology push-e, на качестве, а не количестве.
Текущий чеклист:

Еще большее снижение требований по данным;
Добавление малых языков и языков народностей России и СНГ по мере сбора датасетов;
Дальнейшая работа над качеством (в следующем большом релизе будет сюрприз!);
Высота голоса и скорость;
Радикальное ускорение моделей (10+ раз);
Эмоции, управление интонацией;
Добавление новых голосов по мере появления открытых голосов на других языках;

Последний пункт является по сути низко висящим фруктом (нужно просто вложить много вычислительных ресурсов и грамотно продумать каскад моделей), но мы решили отложить его до решения всех остальных задач и закрытия ряда проектов.     Only registered users can participate in poll. Log in, please. Есть ли угроза со стороны мошенников, связанная с клонированием вашего голоса? 
            36.84%
           Да 
            28
           
            36.84%
           Возможно 
            28
           
            18.42%
           Скорее нет 
            14
           
            3.95%
           Точно нет 
            3
           
            3.95%
           Не знаю / не уверен / не разбираюсь в сути вопроса 
            3
            
       76 users voted.  
       6 users abstained. 
     Tags: ttstext-to-speechсинтез речи Hubs: Machine learningStart-up developmentSoundNatural Language Processing          


