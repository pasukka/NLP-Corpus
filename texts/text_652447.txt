

AntiToxicBot — бот, распознающий токсичных пользователей в телеграм чатах. Немного об архитектуре нейросети бота.Часть 2 / Habr


              18  February   at 23:16  AntiToxicBot — бот, распознающий токсичных пользователей в телеграм чатах. Немного об архитектуре нейросети бота.Часть 2 Python *Natural Language Processing *      ПредысторияЕсть известная проблема с токсичными людьми в чатах. У модераторов чатов не всегда получается отслеживать и банить токсичных людей, хотелось бы автоматизировать процесс.В прошлой статье было мало уделено архитектуре нейросети. Цель данной статьи рассказать больше об архитектуре сети и её компонентов, которые использует бот для определения токсичных сообщений.Если вы не читали предыдущую статью, пожалуйста, ознакомьтесь.Об архитектуре.Архитектура нейросети CNN + GRU. Почему же выбрано CNN+GRU, а не просто GRU или CNN? Нейросеть состоит из 3-х основных частей(CNN, GRU, Linear). Давайте рассмотрим каждую часть сети, чтобы понять, для чего они.Архитектура нейронной сетиГиперпараметры(conv1): Conv1d(300, 512, kernel_size=(5,), stride=(1,), padding=(2,))(conv2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))(conv3): Conv1d(1024, 2048, kernel_size=(5,), stride=(1,), padding=(2,))(gru): GRU(2048, 512, batch_first=True)         (fc1): Linear(in_features=512, out_features=256, bias=True)(fc2): Linear(in_features=256, out_features=2, bias=True)CNN – Convolution Neural NetworkОбычно свёрточные слои используют для классификации изображений. Как и в классификации картинок, свёрточный слой выделяет “признаки”, но в нашем случае векторизированный текст. То-есть данная часть сети учится выделять признаки токсичных и позитивных сообщений. GRU - Recurrent Neural NetworkТекст – это последовательность слов или, в нашем случае, векторов, которую свёрточный слой обработал и выделил признаки. Чтобы обрабатывать последовательности произвольной длины, используют рекуррентные слои. В архитектуре используется рекуррентный слой GRU.Linear – линейный слойДанный слой учится делать заключительное решение по определению тональности текста на основе предыдущих слоёв.Об обучение нейросети и результатовПодготовка данныхДля обучения нейросети нужен датасет. Датасет был взят с  сайта kaggle. Около 14000 комментариев  с разметкой токсичное сообщение или нет. Но данный датасет имеет изъян – орфографические ошибки. Для решения данной проблемы была использована библиотека Yandex Speller, которая исправляет орфографические ошибки.Дальше надо превратить текст в числа, т.к нейросети только с ними и работают.  Можно было обучить собственный Word2Vec на основе данного набора данных, но лучше взять уже обученный. Например: Navec. Модель обучали на русской литературе (~150gb), что говорит о качественной векторизации текста.Также надо разделить датасет на тренировочную и тестовую выборки.Обучение нейросетиДля классификации используется обыкновенная функция потерь – кросс энтропия.При обучении сети надо обращать внимание на основные параметры такие, как loss, precision и accuracy. Всего сеть пройдёт 5 эпох, т.к начиная с 5-ой эпохи нейронная сеть начинает переобучаться.РезультатыПосле обучения сети мы имеем вот такие результаты на тестовой выборке:lossaccuracyprecision0.3620.8570.92График точностиГрафик loss функцииВыводРезультаты обучения вполне хорошие, но хочется добиться результата получше, т.к на практике модель всё-таки ошибается, но не часто. В ~80% случаев нейросеть классифицирует тональность текста правильно.СсылкиТелеграм ботРепозиторий проектаПрошлая статья     Tags: нейросетьmachine-learningmachine learningтоксичные сообщенияклассификацияпроект Hubs: PythonNatural Language Processing          


