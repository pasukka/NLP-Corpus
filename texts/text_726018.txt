

Критиков разочаровало качество статей, которые ИИ OpenAI написал для BuzzFeed / Habr


               Критиков разочаровало качество статей, которые ИИ OpenAI написал для BuzzFeed  Reading time  
    5 min
   Views  2.6K Machine learning *Media management *Artificial Intelligence Natural Language Processing *      Робот Buzzy в соавторстве с человеком опубликовал 40 статей на сайте BuzzFeed. Это уже второй результат сотрудничества с OpenAI: до этого, в феврале, BuzzFeed представила ИИ-квизы, которые были больше похожи на чат-бота для развлечения пользователей. Опубликованные в середине марта тексты про туризм — первый известный пример статей BuzzFeed, написанных нейросетями OpenAI.

Несколько изданий оценили качество статей как низкое. Речь блога о путешествиях As Told to Buzzy кишит речевыми ошибками и неинформативна, части критиков полученное напоминает ферму контента для получения трафика из поисковика.

О желании отдать часть работы нейросетям BuzzFeed объявил 26 января этого года. Тогда в обращении глава издания Джона Перетти заявлял об уверенности, что контент искусственного интеллекта перейдёт из разряда экспериментов в сектор основного бизнеса компании. Фондовый рынок бурно отреагировал на такое объявление открытой акционерной компании BuzzFeed, Inc.: её стоимость немедленно взлетела в несколько раз. Пик оказался кратковременным, и с тех пор стоимость акций издателя опустилась на почти прежний уровень.


График цены акции BuzzFeed за последние 6 месяцев, Yahoo Finance

В тот же день в интервью CNN Перетти отдельно пообещал уделять внимание качеству контента от нейросетей. Глава BuzzFeed поделился мнением, что пути два: либо ИИ выдаёт дешёвые низкокачественные статьи для нагона трафика из поисковика и с качеством ниже, чем сделал бы журналист-человек, либо ИИ помогает создать новый тип персонализированных СМИ, более креативных, более динамичных. Первый вариант Перетти охарактеризовал как нежелательный. Вместо этого он хотел идти по второму сценарию, в котором нейросети помогают редакторам-людям, а не заменяют их полностью.

На момент интервью Перетти уже был пример неудачного использования нейросетевой модели для написания статей. Издание CNET в ноябре 2022 года втайне развернуло некое собственное, разработанное внутри компании решение (не продукт от OpenAI). Качество этих статей оставляло желать лучшего. В СМИ (1, 2, 3) обратили внимание на обильные фактические ошибки сгенерированных текстов. К примеру, ИИ утверждал, что доход от вложения $10 000 под 3 % годовых за один год составит $10 300, хотя в реальности это общая сумма на счёте через год.

В конце января в CNET свернули эксперимент с текстами от нейросетей. Внутренняя проверка выявила, что из 77 сгенерированных статей 41 содержали ошибки в фактах, «небольшое число» из них требовали крупных корректировок.

Как было заявлено, автоматически сгененированные тексты CNET оптимизировались для SEO. Вообще, основным фокусом издания стало значение авторитетности (показателя A из квартета E-E-A-T) в глазах поисковой машины Google. Глава BuzzFeed Перетти в январском интервью CNN открестился от подобной практики и заявил, что в долговременной перспективе ставка на ИИ-фермы контента для SEO выйдет боком.

В феврале на сайте BuzzFeed появились первые плоды сотрудничества с OpenAI: небольшие ИИ-квизы, в которые предлагалось заполнять свои данные. В ответ веб-приложение выплёвывало несколько абзацев текста в форме (в зависимости от цели квиза) небольшой романтической истории или сообщения, в котором второй половинке сообщали о разрыве отношений. Этот эксперимент предлагал порвать с кофеином или написать историю любви с Волан-де-Мортом.

В нескольких изданиях (1, 2) ИИ-квизы оценили как забавные, пусть и недостаточно смешные. В самом BuzzFeed признали, что без труда человека нейросеть ничего смешного сгенерировать не может: люди-авторы писали заголовки и вводные данные, а затем настраивали результат.


Примеры выдачи первых ИИ-квизов. BuzzFeed

С 14 по 17 марта из-под аккаунта As Told by Buzzy на BuzzFeed опубликовали 40 статей на тематику туризма. На данный момент это второй известный плод сотрудничества BuzzFeed с OpenAI.

Сайт Futurism указывает, что качество статей оставляет желать лучшего. По мнению авторов, все статьи однотипны и попадают в категорию контент-фермы, в которую Перетти обещал не превращать BuzzFeed.

Некоторые фрагменты повторяются из статьи в статью. Например, несколько статей заросли речевым паразитом «now, I know what you're thinking» («да, знаю, что вы сейчас подумали»):


«Now, I know what you're thinking — 'Cape May? What is that, some kind of mayonnaise brand?'» («Да, знаю, что вы сейчас подумали: „Кейп-Мей? Это что, слово с этикетки майонеза?“») в статье про мыс Кейп-Мей в штате Нью-Джерси.
«Now I know what you're thinking — 'but Caribbean destinations are all just crowded resorts, right?'» («Да, знаю, что вы сейчас подумали: „На Карибах курорты все битком забиты, да?“») в статье про остров Сен-Мартен в Карибском море.
«Now, I know what you're thinking. Puerto Rico? Isn't that where all the cruise ships go?» («Да, знаю, что вы сейчас подумали. Пуэрто-Рико? Это куда ходят все круизные лайнеры?») в статье про город Сан-Хуан в Пуэрто-Рико.
«Now, I know what you're thinking- bigger isn't always better» («Да, знаю, что вы сейчас подумали: больше — не значит лучше») в статье про город Провиденс в штате Род-Айленд.
«Now, I know what you're probably thinking. Nepal? The Himalayas? Haven't we all heard of that already?» («Да, знаю, что вы сейчас, наверное, подумали. Непал? Гималаи? Про это все всё слышали, нет?») в статье про район Кхумбу в Непале.
«Now, I know what you're probably thinking. «Brewster? Never heard of it» («Да, знаю, что вы сейчас, наверное, подумали. Брустер? Никогда не слышал») в статье про город Брустер в штате Массачусетс.
«I know what you're thinking: isn't Stockholm that freezing, gloomy city up in the north that nobody cares about?» («Знаю, что вы сейчас подумали: разве Стокгольм — это не тот холодный мрачный северный город, до которого никому нет дела?») в статье про город Стокгольм в Швеции.

Это не единственный пример повторов. Устойчивое словосочетание «hidden gem» («скрытая жемчужина») или его вариация «hidden treasure» встречается в 16 из 40 статей (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16). Сайт Futurism насчитал 27 употреблений разнообразных штампов про драгоценные камни: «gem» бывал «секретным» («secret gem»), «криминально недооценённым» («criminally underrated travel gem») или «канадским» («Canadian gem»).

Статьи не только наполнены речевыми изъянами, но также неинформативны и алогичны. Автор Nieman Journalism Lab оценил тексты как примитивные. К примеру, статья про Марокко состоит из трёх рекомендаций: посетите Марракеш, посмотрите на горы, посмотрите на пустыню. Другие указывают, что в описаниях местной кухни слюнки текут от фургонов с уличной едой («mouth-watering food trucks»), а не от еды. Журналист Макс Тани высказал предположение, что качество письма просто иллюстрирует низкий уровень любых текстов туристической тематики в индустрии.

Как рассказал представитель BuzzFeed сайту Futurism, для составления этих статей сначала опросили сотрудников (кроме редакционных отделов), какие места для путешествий незаслуженно игнорируются. По полученному списку написали большой пост на 42 пункта, а затем развили пункты в отдельные статьи.

Нейросетевые статьи про туризм сочиняются с человеком, который указан в подзаголовке каждой статьи в качестве соавтора. Но если ИИ-квизы помогали создавать журналисты, то соавторы статей про туризм — это не редакционные сотрудники. С роботом Buzzy писали, например, специалисты по работе с клиентами и менеджеры по продукту. Поэтому авторы Futurism и Verge считают эти посты про туризм proof of concept сеошной контент-фермы и замены авторов-людей — того, чего Перетти так обещал избегать.      Tags: OpenAIBuzzFeedGPTCNETжурналистикамашинное обучениебольшие языковые моделигенерация текстов  Hubs: Machine learningMedia managementArtificial IntelligenceNatural Language Processing          


