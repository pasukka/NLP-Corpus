

Как AI превращает интернет в мусорку / Habr


               Как AI превращает интернет в мусорку  Reading time  
    11 min
   Views  20K Xeovo VPN corporate blog Information Security *Research and forecasts in IT *Legislation in IT Artificial Intelligence  
    Analytics
        Фундаментальный парадокс ИИ заключается в том, что раньше люди его представляли идеальным разумом: всезнающим, корректным и точным, который благодаря доступу к массиву всех накопленных человечеством знаний, свободе от эмоциональных искажений и мощности своих алгоритмов, может стать совершенным помощником человека, извне компенсирующего внутренние изъяны человеческой натуры — эдаким Джарвисом, с которым каждый может быть Железным человеком. Надежда была, что таким образом ИИ станет решением проблем роста человеческой цивилизации и отношений людей в ней далеко за пределами сугубо технологического применения: вплоть до разрешения политических конфликтов, войн и коррупции. Но первые эксперименты с современными чат-ботами, ChatGPT 3.5, ChatGPT 4 и их конкурентами, показывают, что ИИ несёт в себе в равной степени потенциалы решения одних проблем вместе с усугублением других. Такие проблемы как спам, скам и ложная информация силами ИИ прямо на наших глазах начинают мутировать из обычных злодеев интернета в будущих суперзлодеев.***В конце марта Илон Маск и другие тяжеловесы IT-отрасли подписали открытое письмо, в котором заявляли, что ИИ представляет «экзистенциальный риск» для человечества. Они призвали лаборатории ввести шестимесячный мораторий на разработку любой технологии, более мощной, чем GPT-4. Подобные публичные выступления редко объясняются единственной причиной, скорее всего за ними стоит комплекс различных мотиваций, сошедшихся в одной точке. Одна из них, вполне возможно — тревога людей, чьи капиталы напрямую завязаны на IT и в том числе AI, что конкуренты убегают слишком далеко вперёд и за эти полгода могут набрать скорость отрыва. Особенно это актуально для самого Маска, капитализация «Теслы», его основного богатства, критически завязана на ИИ — в его случае, автомобильный автопилот. Именно поэтому, компания «Тесла» в 3 раза дороже «Тойоты», несмотря на то, что производит в восемь раз меньше автомобилей (1,3 млн против 10,5 млн в 2022 году). Обычно крупные капиталисты против госрегулирования, но только не когда они чувствуют, что проигрывают конкурентную борьбу. Будь то китайский ТикТок, побивший американские корпорации в их же собственной игре на поле соцсетей, или компании, вырывающиеся вперёд в создании продвинутых чатботов — тогда принципы невмешательства государства уступают необходимости выдержать конкурентную борьбу любой ценой. Так и в этом случае, запрос о госрегулировании пришёл от участников, которые выражают интерес к собственным разработкам в ИИ. Тогда как текущие лидеры разработки ИИ этот призыв проигнорировали. С другой стороны, с фокусом этого письма на абстрактных и немного фантастических угрозах «нечеловеческого разума, который, в конечном итоге, может превзойти нас числом, умом, сделать нас устаревшими и заменить нас» не согласны многие эксперты по ИИ: проблема современного ИИ не в абстрактной пока угрозе, что он станет врагом человека, а во вполне реальном вреде, который он причинит в качестве помощника человека. Прежние системы ИИ, используемые в разных сферах, где принимают зачастую судьбоносные решения, из-за своей предвзятости своих моделей загоняют людей в нищету или приводят к неправомерным арестам. Модераторам приходится просеивать горы травмирующего контента, созданного искусственным интеллектом, всего за 2 доллара в день. Количество вычислительной мощности, используемой языковыми моделями ИИ, ведёт к загрязнению окружающей среды. Новые модели уровня ChtaGPT 3 и 4, которые выходят на первый план сейчас, в самом ближайшем будущем вызовут хаос совершенно иного порядка. Как пишет MIT Technology Review, языковые модели ИИ до смешного легко использовать не по назначению и использовать в качестве мощных инструментов фишинга или мошенничества. Известные угрозы безопасности пользователей и адекватности информации в интернете, которые несут ошибки и злоупотребления моделями ИИ:Взлом и «угон» ИИ-чат-ботов с получением доступа к их базовому коду и данным позволит использовать их для создания вредоносных чат-ботов, которые могут выдавать себя за обычные.Содействие цифровым атакам. Чат-боты с искусственным интеллектом могут использоваться для помощи в мошеннических и фишинговых атаках путем создания убедительных сообщений, которые обманом заставляют пользователей раскрывать конфиденциальную информацию или выполнять действия, которые они не должны делать. Например, всё, что нужно для атаки, называемой скрытой prompt-инъекцией — это скрыть запрос (prompt) для бота на веб-странице нулевым или невидимым на белом фоне белым шрифтом. Сделав это, злоумышленник может приказать ИИ делать то, что ему нужно — например, выведать данные банковской карты пользователя.Цифровой помощник преступников. Новейшие возможности нейросетей уже берутся на вооружение мошенниками всех сортов, размывая границу между цифровыми и оффлайновыми преступлениями. В апреле уже прогремел случай, когда вымогатели потребовали у женщины выкуп в миллион долларов за возврат якобы похищенного ребёнка, используя дипфейк голоса её дочери. Правдоподобные дипфейки аудио, видео, созданные нейросетями реалистичные картинки и тексты в совокупности создают мощный инструмент для обмана и принуждения людей. Отравление данных. Чат-боты с искусственным интеллектом можно обучать на зараженных наборах данных, содержащих вредоносный контент, которые затем можно использовать для создания вредоносных материалов — например, фишинговых писем.ИИ-галлюцинации. Этот термин используется для описания вымышленных ответов чатботов. С этим феноменом столкнулись уже очень многие пользователи, но объяснения ему до сих пор нет. ChatGPT отличается тем, что выдумывает несуществующие книги, цитаты, исследования и людей, причём снабжает их подробными оглавлениями, списками источников, насыщает биографии вымышленных людей событиями — и тараторит это с такой убедительностью, словно он пересказывает статью из «Википедии», но всё это — полностью, с нуля сфабрикованное на ходу. И хотя здесь нет (скорее всего,) чьего-то злого умысла — по крайней мере, пока — трудно даже представить, к какому засорению интернета продуктами ИИ-галлюцинаций это приведёт. Но не приходится сомневаться, что это произойдёт: цитаты в интернете были проблемой и до ИИ.  В апреле Италия стала первым государством, отреагировавшим на совокупность новых угроз, которые несёт последний прорыв в развитии нейросетей, запретив ChatGPT на своей территории из соображений защиты личных данных, и пообещав расследовать соответствие продукта OpenAI общеевропейским нормам GDPR (General Data Protection Regulation) — что, в свою очередь, может грозить последствиями уже на уровне всего Евросоюза. Технологические компании знают об этих проблемах, но пока не имеют хороших решений. Microsoft говорит, что работает со своими разработчиками, чтобы отслеживать, как их продукты могут быть использованы не по назначению, и снижать эти риски, но, учитывая масштабы и сложность проблем, общих заявлений совершенно недостаточно. Прямо сейчас технологические компании встраивают эти фундаментально уязвимые модели во всевозможные продукты — от программ, генерирующих код, до виртуальных помощников, которые просеивают наши электронные письма и календари, тем самым, закладывая топливо, которое будет питать приводимый в работу ИИ-моделями глючный, спамный, мошеннический интернет.«Разрешение этим языковым моделям извлекать данные из Интернета дает хакерам возможность превратить их в «сверхмощный механизм для спама и фишинга», — говорит Флориан Трамер, доцент кафедры компьютерных наук в ETH Z