

Windows 10 с Tesla T4 в Azure на примере Stable Diffusion и Automatic1111. Недорого / Habr


               Windows 10 с Tesla T4 в Azure на примере Stable Diffusion и Automatic1111. Недорого Level of difficulty  
    Medium
   Reading time  
    7 min
   Views  3.6K Image processing *Machine learning *Artificial Intelligence  
    Case
        ВведениеПоскольку я люблю высокую степень контроля, всякие дискорд/телеграм чаты меня устроить не могли. Разве что получить первый опыт. Ну как же без inpaint…Следующий шаг – Colab. Довольно много можно нагенерировать в рамках бесплатных лимитов. При использовании ноутбука (.ipynb) с Automatic1111 контроль практически полный. Разве что мелкие неприятности (не открывался posex - ну поставил openpose-editor, разве что canvas-zoom не победил). А уж с подключением shared диска для работы с одной установкой с разных аккаунтов и вообще красота. И все-таки хотелось попробовать «полностью свое». Поскольку мне это не для работы по 8 часов день, компьютера нет (карту воткнуть некуда), но есть ноутбук с поддержкой Thunderbolt 3, стал смотреть в сторону внешних боксов типа AORUS. Однако подержанные, в основном, были с 10-11GB видеопамяти, что достаточно для генерации, но не очень для обучения.  Даже для Vicuna 13B может не хватить (рекомендуют 12GB). Что-то более приличное уже слишком дорого, чтобы простаивать (обычно все-таки попроще карточки достаточно), и все равно может не хватить для редких серьезных потребностей. Пока думал, реальность подсказала, что с железкой связываться точно не стоит.В общем, стал смотреть, как бы запуститься в облаке в режиме «оплаты за использование». ВариантыОдним из основных требований было использование spot instance, чтобы выполнение было подешевле, поэтому «готовые» скрипты не очень устраивали. Хотелось запустить инстанс именно такой, какой нужен, и самому в нем все настроить. Платить за готовый образ из маркетплейса тоже не интересно.Причем предпочтительно (хотя и не обязательно) – Windows [10], ибо меньше заморочек с драйверами, есть прекрасныая portable сборка… В AWS цены вроде норм. g4ad.xlarge (4vCPU, 16GB RAM) spot примерно $0.15 в час. Правда AMD Radeon Pro V520 GPUs, что для Stable Diffusion потребует танцев. g4dn.xlarge (тоже 4/16), но уже NVIDIA T4 GPUs – совсем другое дело. Правда уже $0.20 в час (спот, конечно).При этом использование Windows server стоит дополнительных денег. А чтобы Windows 10 со своей лицензией установить нужно сначала локально собрать VHD, залить в AWS. В общем, не тривиально. Хотя если кому надо, описание есть.Стал смотреть в Azure. Там для запуска Windows 10 уже все готово. И можно подтвердить, что лицензия своя (у меня и правда есть). Поэтому остановился на NC4as_T4_v3 (4 vCPU, 28GB RAM, тоже Tesla T4). $0.15/час на споте.УстановкаСовсем детально описывать не буду, приведу скриншоты для ориентира и укажу на основные моменты.ТипAvailability zoneСразу скажу – это не лучший вариант. При таком выборе Availability options (по умолчанию) действительно можно найти зону (в данном случае 3) с дешевыми инстансами. Причем глядя на view pricing history можно увидеть, что в Западной Европе существенно дороже:Сравнение ценОднако в таком случае ваш IP адрес будет Standard. Зарезервированный. И за него будут брать деньги, когда виртуалка выключена (примерно $2.5 в месяц).Лучше указать, что отказоустойчивость не требуется:No redundancyЗадать пароль админстратору.Порты 80 и 443 я открыл на случай публикации веб интерфейса SD для себя, возможно с LetsEncrypt. А так же открыл SSH. Позже объясню задумку.ДискКогда виртуалка будет выключена, придется оплачивать дисковое пространство. А оно у данного типа немалое – 128GB (на портале нельзя выбрать, вроде при запуске через Terraform можно уменьшить). Поэтому диск я выбрал HDD. Он обойдется примерно в $6 в месяц. И я бы не сказал, что он сильно тормозит. Перезагрузка тоже чрезвычайно быстрая. У меня ноут на NVMe дольше загружается (там, правда, много всего установлено)Standard HDDВпрочем, можно и SSD выбрать. Тогда примерно $10 в месяц выйдет.СетьСетевой интерфейсПубличный адрес лучше явно создать (Create New) и указать Basic, DynamicРасширенияНам нужно установить драйвера для Tesla T4. Укажем это сразу же (Select an extension to install):И тут сюрприз. Про GPU только AMD.Только AMDНужно нажать Load more, и появится NVIDIAРазумеется, можно было сразу NVIDIA набрать. Страница была бы пустой, после Load more появилось бы искомое.Возможно стоит еще и SSH добавить. По крайней мере я планирую вместо публикации веб-интерфейса наружу прокинуть туда туннель через SSH по сертификату, чтобы браузер локально работал (как с Colab). С ноутбука будет обращение на 127.0.0.1:7860, а в реальности через SSH-туннель уходить в виртуалку. Хотя, конечно, можно и по RDP сидеть, не выставляя Web наружу совсем.Подтверждаем, что все хорошоИ ждем, пока все установится, включая драйвера.После созданияНужно кое-что настроить. Поскольку мы хотим сэкономить на IP, при каждом запуске нам будет выдаваться новый. Значит подключаться удобнее по DNS имени. Жмем Not configured в DNS Name. Настроим DNSИ указываем желаемое имя для DNS (у меня sda1111). Потом SaveТеперь видим DNS имя sda1111.germanywestcentral.cloudapp.azure.com, по которому можем подключаться по RDP (т.е. сохраним в RDP клиенте и будем подключаться одним кликом), хотя при каждом запуске IP будет новым.На скриншоте чуть выше в IP address management была только опция Static (дорогая, из-за «отказоучстойчивости» в самом начале конфигурации).Если же было выбрано «без отказоустойчивости», будет выбор Dynamic. Он и нужен.Виртуалка при этом должна быть остановлена. Т.е. это можно сделать и позже (если забыли на этапе создания).Если что-то не будет получаться, можно вообще удалить публичный IP и создать новый. Только сначала его нужно «отвязать» (dissociate). А потом новый правильно созданный associate обратно.Важный моментДаже после Shutdown изнури виртуалки (остановлен Windows) ресурсы остаются выделенными (allocated), и Azure берет деньги, как будто вируталка работает. Нужно не забывать ей делать Stop (deallocate).Для подстраховки рекомендую настроить автоматическое выключениеНу и чтобы закончить на этом с интерфейсом Azure, сразу покажу на будущее. Вдруг одной Nvidia Tesla T4 не хватит для чего-то супер-большого. На выключенной виртуалке можно сделать resize до NC64as_T4_v3 аж с четырмя Теслами.В виндеПроверяем драйвераNVIDIA Control Panel есть. Уже хорошо.Device Manager:Есть наша Tesla T4. Правда это отдельный адаптер, мы-то сейчас работаем через Microsoft Remote Display Adapter. Может быть поэтому я не вижу GPU:Возможно надо активировать что-то подобное, но я не разбирался. Мне нужно быстро картинки генерировать, а не в игрушки на виртуальном десктопе играть.Смотрим, что покажет родная NVIDIA утилита (перетащил nvidia-smi в cmd) Как в Colab :) Tesla T4, 16GB VRAM. CUDA 11.4, можно обновить до 12 версии.Если кому интересно, dxdiag:Ставим Stable DiffusionВоспользуюсь удобной portable сборкой https://github.com/serpotapov/stable-diffusion-portableПосмотреть про нее можно тут: https://www.youtube.com/watch?v=jepK6ufemMw. И вообще крайне рекомендую этот канал и автора.C githubСкачиваю одним файлом zip-архив по ссылке из п.1Раскрываю архив, кладу в корень, переименовываю папку для своего удобства просто в sd.Запускаю webui-user-first-run. Стартует довольно длительный процесс.В это время скачиваю первую модель (без этого не запустится). В п.4 есть ссылка на Deliberate – то, что надо.Как только в моей папке sd появится models\Stable-diffusion, кладу эту модель туда. Также можно пока скачать VAE и прочее, но это все можно и потом. Для запуска достаточно модели.Пока все устанавливается, дописываю --theme dark в основной запускательный файл webui-user.bat (тоже не обязательно)По завершении установки может появиться ошибкаЭто не страшно. Главное, что не про «не найден GPU»Просто закрываем это окно, стартуем, как положено, webui-user.bat  и ждем ссылки на web-интерфейсМожет даже браузер сам откроется.Для доступа снаружи есть разные варианты. Например, в том видео Хачатура, что я приводил, описано. Есть расширения в т.ч. для SSL. Я планирую через SSH туннель.Пока просто «изнутри RDP».Первые генерации могут быть медленными. В консоли видно, что система что-то докачивает.В итоге получаем получаем почти 7 итераций в секунду. В Colab у меня обычно 2.5-3.5 it/secТакже запустил генерацию 512x512, Euler a, Sampling steps 20, Batch Count 24. Было выполнено за 90 секунд.24 count * 20 steps / 90 sec - так и получается 5 с чем-то. По ощущениям реально быстрее Колаба.Что в итоге по стоимости?Рассмотрим использование «по часу в день». День-другой пропустим, в выходные побольше посидим, условно 30 часов в месяц. У меня даже меньше времени на SD уйдет. Ну т.е. в первое время может и так же, а потом явно уменьшится.30 часов в месяц * $0.15 = $4.5 – за время работы виртуалки.Диск S10 128GB в месяц стоит $5.89.Работа диска: «We charge $0.0005 per 10,000 transactions for Standard HDDs». Не готов оценить, не знаю, насколько интенсивно SD дергает диск. Даже медленный выбранный мной HDD, даже в пиках был загружен слабо, и по ощущением задержки вовсе не в диске. Так что вряд ли будет  чего-то существенного стоить. В принципе есть еще вариант – к виртуалкам данного типа прилагается «эфемерный диск». Временный, только на время текущего запуска. Возможно будет иметь смысл что-то интенсивно дисковое сначала копировать на него и дергать оттуда, а не только своп и временную директорию туда направить. Хотя при оперативной памяти 28GB (существенно больше, чем у аналогичного инстанса в AWS), думаю, все достаточно хорошо кешируется.Иными словами, около $11 в месяц для «поизучать, побаловаться». Поскольку буквально за час поднимается, можно вообще поднять только «на время отпуска».Для профессионального использования «8  часов в день в помощь фотошопу» это дороговато. Хотя $5.89+22дня*8ч*$0.15 = $33 в месяц - фактически стоимость видеокарты за 3 года. С учетом динамично меняющихся обстоятельств, требований к мобильности, тоже может быть вариантом попробовать и решить, насколько нужна своя карта, какой производитеьности, с каким количеством памяти…По идее и пара-тройка человек может одновременно через Web работать с одной такой виртуалкой (если не для видео много кадров подряд генерируем). По крайней мере я запускал из разных браузеров одновременно, и норм (просто задержка, пока в другой сессии генерируется). Если бы им можно было output директорию сделать каждому свою (добавив в название IP адрес, к примеру), вообще было бы здорово. Ну типа Stable Diffusion общий, а Web UI у каждого свой, со своими настройками. Может даже у одно Automatic, а у другого Comfy, к примеру.ВопросыОчень интересует вопрос, как делится видеокарта между приложениями. Допустим, у меня запущен Stable Diffusion, но ничего в это время не генерируется. Могу я запустить что-то еще? Условную LLaMA/Alpaca/Vicuna?Ну типа идет генерация картинки – текстовые запросы ждут. Идет генерация текста – ждут картинки. Или SD захватывает карту монопольно и постоянно держит в памяти видеокарты модели и все такое?Я видел что-то вроде разделения на несколько кусочков «GKE’s GPU time-sharing feature allows you to partition a single NVIDIA A100 GPU into up to seven instances» и по времени «You can configure time-sharing GPUs on any NVIDIA GPU on GKE including the A100». Первый вариант «вместо одной мощной карты получить несколько маленьких»  не особо мне интересен. А со вторым непонятно, как все-таки с загружаемыми текстурами, моделями и прочим в случае частого переключения контекстов. И требуется ли поддержка со стороны софта (надо же понять, что ранее загруженные в видеопамять текстуры кто-то грохнул).API Remoting производительностью не радует (Performance ranges from 86% to as low as 12% of native performance in applications that issue a large number of drawing calls per frame).В общем, буду рад услышать ваши соображения.      Tags: stable diffusionautomatic1111AzureTesla T4GPU  Hubs: Image processingMachine learningArtificial Intelligence          


