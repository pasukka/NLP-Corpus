

Качественный набор данных от Microsoft для обучения компактных, но мощных языковых моделей, генерирующих код / Habr


               Качественный набор данных от Microsoft для обучения компактных, но мощных языковых моделей, генерирующих код Level of difficulty  
    Medium
   Reading time  
    4 min
   Views  2.4K Wunder Fund corporate blog Programming *Algorithms *Artificial Intelligence   
    Translation
     
                Original author:
                
                  Hecate He
                  Обучение больших нейронных сетей — это искусство. В сфере ИИ уже давно известны следующие два факта. Во-первых — высококачественные учебные данные оказывают значительное влияние на улучшение результатов работы больших моделей. Во-вторых — применение таких данных способно бросить вызов законам масштабирования, имеющим отношение к размерам моделей и данных.Исследовательская команда Microsoft, вдохновлённая этими идеями, провела эксперимент, отчёт о котором — Textbooks Are All You Need — можно найти на arXiv.org. В рамках эксперимента была создана большая языковая модель для генерирования кода, названная phi-1. Обучение этой модели проводилось с использованием специально подготовленного набора данных, качество которого сопоставимо с учебниками по программированию. В результате модель phi-1, при том, что в ней используется всего 1,3 миллиарда параметров, показала результаты, превосходящие то, на что способны самые совершенные большие языковые модели.Исследование направлено на обучение языковых моделей для генерирования кода. Оно ориентировано на демонстрацию того, что в высококачественных данных есть сила, способная изменить текущую ситуацию, когда улучшение возможностей моделей напрямую связано с увеличением их размеров.Данные разной образовательной ценности (слева — высокой, справа — низкой)Сначала команда показала методику создания высококачественных наборов данных, использование которых позволяет улучшить результаты обучения компактных моделей. При подготовке данных применялся классификатор, основанный на трансформере (GPT-4). С его помощью отобрали примеры Python-кода, имеющие высокую образовательную ценность. Источниками кода стали общедоступные данные платформ The Stack и StackOverflow. Модели, с помощью которой аннотировали образцы кода, давали такой промпт: «determine its educational value for a student whose goal is to learn basic coding concepts», то есть — ей предлагалось определить образовательную ценность текста в расчёте на учащегося, цель которого — освоить базовые концепции программирования. Исследователи позаботились о том, чтобы образцы кода, которые будут включены в итоговый набор данных, отличались бы разнообразием и не повторялись бы.Исследователи создали базовую модель phi-1-base — трансформер, содержащий лишь декодирующий компонент и имеющий 1,3 миллиарда параметров. Базовую модель обучили на наборе данных CodeTextbook. После этого, дообучив модель на наборе данных CodeExercises, вышли на модель phi-1. Эксперименты проводились и с уменьшенной версией модели — phi-1-small.Результаты работы моделей phi-1, phi-1-base и phi-1-small. Модель phi-1-base испытывает затруднения в интерпретации логических связей в промпте, в то время как модель phi-1 способна правильно интерпретировать вопрос и выдавать ответ. Здесь показано, что даже небольшая модель phi-1-small, имеющая 350 миллионов параметров, хотя и даёт неверный ответ, демонстрирует некоторый уровень понимания задачи.В ходе исследований оказалось, что дообучение модели на наборе данных CodeExercises привело к значительным улучшениям не только в тех навыках модели, которые планировалось усилить, но и в навыках, не связанных с ними. В частности, речь идёт о возможностях использования моделью внешних библиотек, таких, как как Pygame и Tkinter, даже учитывая то, что в упражнениях этих библиотек не было.Количество импортов различных библиотек в 879486 упражнениях, использованных для дообучения модели (здесь нет библиотек, которые импортировались менее 10 раз). Эта диаграмма сгенерирована моделью phi-1, которой был предоставлен следующий промпт: «I have a dictionary, first sort the dictionary using the value, from largest to smallest. Then generate a pyplot bar plot. First set font size to be 7, then rotate the x-axis label by 90 degree, the x-axis is the key, y-axis is the value of the dictionary. Use log-scale on y-axis. Moreover, set the y-axis label to be ‘Log Number of Times’ and x-axis label to be ‘Imports’. Set dpi to be 1000.»Модель phi-1, несмотря на то, что она гораздо меньше других моделей, обходит их в тестах HumanEval и MBPP. Исключения составляет лишь GPT-4 (а так же — WizardCoder, но эта модель лучше phi-1 лишь в тесте HumanEval)Экспериментальные результаты показывают, что модель phi-1 достигла уровня 50,6% в тесте HumanEval (Pass@1), а в тесте MBPP (Pass@1) она получила оценку 55,5%.В результате можно сказать, что данное исследование подтверждает значимость разработки методов создания высококачественных наборов данных. Такие методы являются важным элементом работ по улучшению возможностей обучения больших языковых моделей. В частности, речь идёт о совершенствовании способностей моделей по генерированию кода.О, а приходите к нам работать? 