

WaveNet: синтезированная компьютером речь, похожая на человеческую / Habr


              10  September  2016 at 21:09  WaveNet: синтезированная компьютером речь, похожая на человеческую Popular science Artificial Intelligence       

DeepMind — это автономное подразделение Google, которое занимается разработками в области искусственного интеллекта. Эта компания разработала AlphaGo — систему, обыгравшую в го чемпиона мира по го Ли Седоля. 


Но удел DeepMind — не только игры. Сейчас сотрудники компании занимаются разработкой компьютерной системы синтезирования речи. Как и во всех прочих проектах DeepMind, здесь замешана слабая форма искусственная интеллекта. Она, по мнению специалистов, может кардинально улучшить ситуацию с синтезированной речью. 


Использование компьютеров для синтезирования речи — вовсе не новая идея. Наиболее простое решение — использование фрагментов речи реального человека, переведенной в цифру. Речь идет об отдельных звуках, из которых складываются более сложные звуковые фразы, слова и предложения. Но такой способ нельзя назвать идеальным. Здесь любой человек сразу замечает проблемы с произношением и интонацией. 


В других случаях используются различные математические модели для того, чтобы синтезировать звуки, из которых можно собрать слова и предложения. Здесь примерно те же проблемы, что и в предыдущем случае. Да и сразу понятно, что говорит машина, а не человек.




Оба метода схожи тем, что из мелких фрагментов собираются более крупные и сложные. В результате такой компиляции компьютер произносит слова и сложные фразы. 


Третий метод, WaveNet, предложенный компанией DeepMind, объединяет достоинства предыдущих двух. В методе используется обучение нейронных сетей с использованием фрагментов реальных человеческих голосов. Также система получает информацию о правилах лингвистики и фонетики, соответствующих каждому отдельному случаю. В процессе работы системе показывают строку текста и дают «слушать» соответствующий набор звуков. После этого система пробует синтезировать речь человека, используя ряд фрагментов. Делается это пошагово, с обучением на примере каждого конкретного фрагмента. Разработка ведется таким образом, чтобы каждый предыдущий «пройденный материал» давал нейронной сети представление о новом задании. 


Аналогом того, что может сделать система WaveNet и обычная система синтеза речи является создание чашки. Обычная компьютерная система синтезирования речи для создания чашки использует как бы кубики Lego. В итоге чашка выглядит неплохо, но это не совсем чашка, а ее имитация. А вот WaveNet для создания чашки использует глину. Работа ведется вручную, без гончарного круга, но чашка получается похожей на чашку. Так и с речью. WaveNet синтезирует человеческую речь, которая немного отличается от того, к чему мы привыкли, но не очень значительно. 


Результат впечатляет. Прослушать то, что получилось, можно здесь. Звучит уже действительно по-человечески. Конечно, отличия есть, но они уже не такие значительные, как в других случаях. 




Единственная проблема в том, что этот метод требует большого количества машинного времени и ресурсов. Система, которая может генерировать внятную человеческую речь, должна быть очень мощной. Дело в том, что WaveNet для синтезирования человеческой речи обрабатывает каждую секунду 16000 образцов аудио. И даже в этом случае результат получается среднего качества. Тем не менее, в тестах на определение «человек или машина» результат был около 50%. То есть половина добровольцев, прослушавших аудио сэмпл, созданный машиной, считали, что это говорит человек. 


Исследователи из DeepMind уже загрузили в систему более 44 часов речи. Загружаемые в систему слова, звуки и фразы принадлежат 109 участникам эксперимента, разговаривающих на английском языке. Как оказалось, WaveNet может смоделировать речь практически каждого из участников эксперимента. Система воспроизводит даже придыхание и дефекты речи оригинального «оратора».


Несмотря на то, что система говорит уже довольно неплохо, до настоящего совершенства еще далеко. Еще одна проблема — это то, что слабая форма ИИ пока что не умеет понимать язык. Максимального успеха в этом направлении добилась компания IBM с ее когнитивной системой IBM Watson. Но и здесь пока что речь идет о распознавании не слишком сложных устных и письменных команд, а также ответах на простые вопросы. Поддерживать разговор когнитивные системы пока не умеют. Тем не менее, технологии развиваются, и специалисты утверждают, что уже через 5-10 лет ситуация может кардинально измениться. 


Ряд ученых утверждают, что сейчас слабой форме ИИ все же не хватает специфических компонентов разума. И это никак не зависит от размера самой сети. „Язык построен на других возможностях, вероятно, лежащих более глубоко и присутствующих в младенцах ещё до того, как они начинают владеть языком: визуальное восприятие мира, работа с нашим двигательным аппаратом, понимание физики мира и намерений других существ“, — говорит Тененбаум. 




DeepMind и команда исследователей из Оксфордского университета сейчас работают еще над одним проектом. Это создание условной «красной кнопки» для сильной формы ИИ, которая, предположительно, может выйти из-под контроля человека после того, как человек создаст искусственный разум.    Tags: искусственный интеллектdeepmindwavenet Hubs: Popular scienceArtificial Intelligence          


