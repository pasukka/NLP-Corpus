

YandexGPT в Браузере: как мы учили модель суммаризировать статьи / Habr


                YandexGPT в Браузере: как мы учили модель суммаризировать статьи  Reading time  
    7 min
   Views  22K Яндекс corporate blog Browsers Machine learning *Artificial Intelligence IT-companies       Неделю назад на сайте 300.ya.ru мы продемонстрировали возможности языковой модели YandexGPT применительно к задаче суммаризации текстов. С тех пор многое изменилось: мы обучили новую, более качественную модель, в пересказах которой в 4 раза меньше ошибок. А сегодня мы внедрили её в Яндекс Браузер. Может показаться, что мы просто взяли ту же модель, о которой уже рассказывали сообществу на примере Алисы, и прикрутили к ней кнопку в Браузере. Но не всё так просто. Да, наша базовая модель уже понимала, что такое суммаризация в общих чертах. Но для нас было важно добиться результата в нужной нам форме и с предсказуемым качеством. И вот тут-то начинаются нюансы.


Сегодня поделюсь с Хабром не столько новостью, сколько нашим опытом и советами из области дообучения моделей и промпт-инжиниринга. Расскажу, через что пришлось пройти нашей команде, чтобы модель начала делать то, что от неё ожидают.



Коротко — о продукте

Для начала немного расскажу о том, как краткий пересказ работает в Яндекс Браузере. Это позволит понять, какие продуктовые требования предъявлялись к языковой модели. 


Итак, с чего всё начиналось. Наше основное желание — экономить людям время. Поэтому мы решили сделать так, чтобы пользователь браузера в один клик мог увидеть краткий пересказ статьи, новости, обзора или исследования. Причём пересказ должен укладываться примерно в тысячу символов. В этом случае пользователь, которому попался материал на 30 тыс. знаков (наш текущий лимит, который мы планируем поднять), сможет меньше чем за минуту понять суть текста и решить, нужно ли читать его прямо сейчас. 


Идём дальше. Краткий пересказ может выглядеть по-разному. Например, он мог бы выглядеть как короткая версия исходной статьи. Но мы осознанно пошли в сторону списка тезисов. У такого формата множество достоинств: по списку удобно пробежаться глазами, он подходит и для новостей, и для других видов текстов. Кроме того, мы считаем, что краткий пересказ должен экономить время и помогать принять решение о чтении, а не пытаться заменить статью. 


И ещё кое-что. Мы решили, что важно дать возможность делиться кратким пересказом — так люди смогут помогать друг другу. А ещё так будет проще присылать нам очевидные ошибки суммаризации, которые помогут совершенствовать технологию. Поэтому мы предоставили пользователям возможность делиться краткими пересказами, которые будут жить на сайте 300.ya.ru по своим уникальным ссылкам.


Пожалуй, это главное, что нужно знать о продуктовой стороне вопроса. Теперь перейдём к технологической.

Подробнее — о суммаризации

Задача суммаризации текста известна давно, существует много классических методов, а количество научных статей с каждым годом только растёт.


Источник картинки: https://arxiv.org/pdf/2204.01849.pdf


Существует много подходов к решению этой задачи. Если рассматривать их классификацию из статьи, то мы идём по пути абстрактивной суммаризации. Это значит, что текст краткого пересказа не копируется, а генерируется на основе всего текста статьи. 


Подобно тому, как сверточные сети изменили подход в задачах работы с изображениями, так и большие языковые модели изменили работу с текстом. Имея большую языковую модель, обученную на условно «всём интернете», задача суммаризации может быть решена способом, который уже не требует тонкой инженерной настройки.


Этот способ можно разделить на два этапа.


Сначала идёт исследовательская часть:

Подбираем исходную генеративную модель. В нашем распоряжении было несколько базовых генеративных моделей семейства YandexGPT, а также дообученные для различных задач. Мы выбрали ту, которая уже была обучена на различных задачах по работе с текстом, в том числе умела решать несложные задачи суммаризации.
Определяемся с областью применения модели. Для оценки качества её работы собираем корзину текстов страниц, которые будут максимально репрезентативны потоку посещаемых страниц пользователями браузера. На основе этих данных готовим процесс приемки качества.
Используя открытые или свои датасеты, изучаем, какое количество данных требуется для качественного дообучения базовой модели (P-tuning, fine-tuning, а также их комбинации). О том, как они работают для больших генеративных моделей, мы уже рассказывали в посте про нашу модель YaLM.


Этот процесс итеративный и может занять какое-то количество циклов.




После того, как нам удалось получить исследовательскую модель хорошего качества, мы переходим к обучению продакшн-модели:

Собираем датасет необходимого объёма с помощью асессоров и AI-тренеров.
Дообучаем модель и измеряем качество, используя уже готовый процесс.
Сталкиваемся с тем, что итоговое качество нас не устраивает, и итеративно экспериментируем.




В этой схеме нет ничего специфичного для суммаризации, поэтому она подходит и для других задач. 


Схема выглядит просто, но на практике с задачей краткого пересказа пришлось повозиться. Пожалуй, расскажу о некоторых проблемах, опыт преодоления которых может быть полезен и другим. 


Практически все современные языковые модели так или иначе уже справляются с задачей суммаризации. Пользователю достаточно скопировать текст статьи, написать промпт-подводку, в которой он просит модель кратко пересказать текст, и радоваться результату. Но это долгий и неудобный процесс, к тому же качество и формат результата могут быть непредсказуемыми. Задача хорошего продукта — быть простым и удобным. Жмёшь всего одну кнопку — текст сам отправляется куда надо с нужной подводкой, а затем возвращается в виде наглядных тезисов. Но как сделать так, чтобы модель придерживалась всегда одного и того же формата результата?


Первое решение простое — давайте попросим её прямо в промпт-подводке. Чтобы продемонстрировать, как это работает, возьмём текст этой новости и попросим Алису её пересказать в навыке «Давай придумаем». Модель в Алисе уже дообучена под определённые задачи, но базовая модель та же самая, поэтому эксперимент будет не сильно отличаться от проведённого нами. Подводка может выглядеть так: «Алиса, у меня есть текст статьи, тебе нужно её суммаризовать в формате тезисов».




У неё получилось пересказать новость. Но, как мы уже писали выше, такой формат не очень нам подходит.


Давайте попробуем доуточнить промпт: «Алиса, у меня есть текст статьи, тебе нужно её суммаризовать в формате тезисов. Тезисы представляют из себя список, каждый элемент списка должен начинаться с новой строки и символа “—”».




Успех! Но радоваться рано. Если мы попробуем воспроизвести упражнение несколько раз или дать на вход более сложную статью, формат может непредсказуемо измениться. Нет гарантий, что результат будет воспроизводиться.


Если идти по пути подбора усложнения и уточнения промпта, то итоговый формат тоже будет подвергаться изменениям. Результаты экспериментов видно на картинке ниже. 

Можно заметить, что, подбирая всё более сложную инструкцию для модели, мы, вопреки ожиданиям, пришли к ещё большей непредсказуемости результата.




Кроме требования к формату, у нас есть и другие аспекты качества:

суммаризация не должна быть слишком длинной;
тезисы должны быть лаконичными;
основная мысль не должна искажаться;
любые факты, которых не было в оригинальной статье, недопустимы.


Как же нам добиться большей предсказуемости от модели? Тут как раз на помощь и приходят методы P-tuning и Fine-tuning. P-tuning подходит и значимо улучшает результат, если у вас есть возможность собрать десятки или сотни примеров решения задачи. Наши модели мы обучали на 35