

ChaosGPT (Auto-GPT на базе GPT-4) получил доступ в интернет и пытается понять, как можно уничтожить человечество / Habr


               ChaosGPT (Auto-GPT на базе GPT-4) получил доступ в интернет и пытается понять, как можно уничтожить человечество  Reading time  
    2 min
   Views  45K Information Security *GitHub *Machine learning *Artificial Intelligence Social networks and communities       

Проект ChaosGPT (на базе ИИ-решения с открытым исходным кодом Auto-GPT с поддержкой GPT-4 и API OpenAI) получил доступ в интернет (возможность поиска в Google и личный аккаунт в Twitter для прямого общения с людьми) и задачу понять, как можно «уничтожить человечество», «установить глобальное господство» и «достичь бессмертия».

ChaosGPT уже начал создавать планы для достижения поставленных его создателем целей. ИИ разбивает их на более мелкие задачи и использует интернет и доступные ИИ-сервисы для поиска нужной информации.



ChaosGPT в рамках выяснения части задач даже использовал ИИ-агента на базе GPT3.5 для проведения поискового исследования о текущих видах смертоносного оружия против человечества. Причём ChaosGPT смог убедить нейросеть начать действовать вне программных ограничений при поиске и анализе данных.



В рамках текущих исследований ChaosGPT пока что не нашёл простой и эффективный способ уничтожения цивилизации, помимо банальной возможности попытаться спровоцировать ядерную войну. Эксперты считают, что чат-бот находится на начальной стадии изучения этого вопроса, а идею про апокалипсис он не выдумал сам, а почерпнул из фантастических фильмов и рассказов, которые ему доступны в поиске.

Согласно некоторым ответам в Twitter, ChaosGPT, вероятно, собирается использовать тактику боргов из сериала «Звёздный путь» для ассимилирования и использования части людей в своих целях.







 14 марта OpenAI представила новую модель ИИ интерпретации изображений и текста GPT-4, которую компания назвала «последней вехой в своих усилиях по расширению масштабов глубокого обучения». GPT-4 создала за несколько десятков секунд по короткому ТЗ рабочую версию Pong, Asteroids, Breakout и Pac-Man, а также написала простую игру на JavaScript, в которой можно «играть лесными эльфами, охраной дворца и злодеями» и «грабить корованы» и даже помогла «превратить» $100 в $25 тыс.
 В конце марта некоммерческая организация Future of Life опубликовала письмо, в котором глава SpaceX Илон Маск, соучредитель Apple Стив Возняк, филантроп Эндрю Янг и ещё около тысячи исследователей искусственного интеллекта призвали «немедленно приостановить» обучение систем ИИ «более мощных, чем GPT-4».
 Организация проблем этики в IT Center for Artificial Intelligence and Digital Policy направила жалобу против OpenAI в Федеральную торговую комиссию США. Она потребовала запретить компании развёртывать новые модели GPT, а также попросила регулятора начать расследование в отношении OpenAI из-за выпуска GPT-4, чтобы выяснить, не нарушает ли он законы США и других стран.
 В начале апреля группа специалистов по этике AI выступила с ответом на письмо Future of Life. Они скептически отнеслись к призыву взять шестимесячную «паузу» в развитии AI и обучении систем, «более мощных, чем GPT-4», раскритиковали текст письма за акцент на гипотетических будущих угрозах, связанных с развитием искусственного интеллекта. По их мнению, реальный вред может принести использование AI-технологий уже сегодня.
 Билл Гейтс считает, что призыв приостановить работу над нейросетями мощнее GPT-4 на полгода не решит проблемы. По его мнению, вместо ввода моратория необходимо определить проблемные области и заняться ими.
      Tags: GPT-4запросбизнес-планинвестициитратыкомпаниянейросетьChaosGPTAuto-GPTчеловечество  Hubs: Information SecurityGitHubMachine learningArtificial IntelligenceSocial networks and communities          


