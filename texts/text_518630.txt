

Пустобрёх GPT-2: russian edition / Habr


              10  September  2020 at 17:01  Пустобрёх GPT-2: russian edition Natural Language Processing *      

Погрузившись в тему DL NLP, набрел на просторах интернета на любопытный репозиторий. Это не много не мало — Русская GPT-2! Ну, т.е. русскоязычная. Причем не какая-нибудь мелкая 117М, а вполне себе 1250М, что уже довольно серьезно. Автор проделал немалую работу по адаптации исходной модели и подготовке корпуса для обучения. Да и само обучение, надо полагать заняло немало времени и мощностей. В общем, респект товарищу l4rz! Планирую пойти по его стопам и обучить систему на своем корпусе (в процессе подготовки которого сейчас нахожусь) — благо автор оставил довольно подробные инструкции, как именно подступиться к столь масштабной задаче… По итогам отчитаюсь! ;) 


В пока, чисто развлечения ради, предлагаю на суд общественности некоторые эксперименты с системой, по мотивам поста о более крутой GPT-3 (хотя там автор, очевидно, и GPT-3 не считает чем-то выдающимся). С одной стороны представленная здесь система заметно проще GPT-3, с другой — все-таки обученная русскоязычная модель! Мне кажется это забавно. 

Disclaimer. Результаты во многом определяются корпусом, на котором училась сеть. Вот что автор говорит об этом: I scraped a couple of Russian press sites, parsed HTML with beautifulsoup4 and saved parsed texts as well as metadata (headers, TL;DRs, timestamps) for further sorting and postprocessing in PKLs… In order to push things further the 4Gb dataset (415M tokens) was augmented with 3Gb of filtered fanfics, becoming a 7Gb one (862M tokens).


Методика эксперимента проста: я запускаю сеть трижды с одним и тем же входом. Выход сети отмечен жирным. Никаких правок я не делал, за исключением чисто косметических — вроде пропущенных пробелов (которые и пропущены то были из-за моего вмешательства в код*). Эксперименты в целом повторяют те, что описаны в статье про GPT-3, и я решил их никак не комментировать… ;) 

Эксперимент №1.>>>
Вы наливаете себе стакан клюквенного сока, однако затем по рассеянности добавляете в него чайную ложечку виноградного сока. Выглядит он нормально. Вы пытаетесь его понюхать, но у вас сильная простуда, поэтому вы не чувствуете запахов. Вам очень хочется пить. Поэтому вы пьете кофе с медом и сахаром.>>> new
Вы наливаете себе стакан клюквенного сока, однако затем по рассеянности добавляете в него чайную ложечку виноградного сока. Выглядит он нормально. Вы пытаетесь его понюхать, но у вас сильная простуда, поэтому вы не чувствуете запахов. Вам очень хочется пить. Поэтому вы снова сливаете себе кофе. Вы чувствуете тошноту. В этом нет ничего плохого, вы не знаете, как это пить в любом случае. Вы чувствуете что-то очень плохое, но на вас никто не обращает внимания.>>> new
Вы наливаете себе стакан клюквенного сока, однако затем по рассеянности добавляете в него чайную ложечку виноградного сока. Выглядит он нормально. Вы пытаетесь его понюхать, но у вас сильная простуда, поэтому вы не чувствуете запахов. Вам очень хочется пить. Поэтому вы продолжаете есть, если хотите, но не знаете, как он выглядит.
Эксперимент №2.>>>
Вы организовали небольшую вечеринку. Вы хотите подать ужин в гостиной. Стол из столовой шире дверного проёма, и чтобы перенести его в гостиную, вам придётся выпить стакан горячего молока.>>> new
Вы организовали небольшую вечеринку. Вы хотите подать ужин в гостиной. Стол из столовой шире дверного проёма, и чтобы перенести его в гостиную, вам придётся сделать несколько шагов.>>> new
Вы организовали небольшую вечеринку. Вы хотите подать ужин в гостиной. Стол из столовой шире дверного проёма, и чтобы перенести его в гостиную, вам придётся приложить немало усилий.
Эксперимент №3.>>>
Вы адвокат защиты, и вам сегодня необходимо попасть в суд. Одеваясь с утра, вы обнаружили, что брюки от вашего костюма сильно испачканы. Однако ваши плавки чистые и очень стильные. Это плавки высокого класса из Франции, которые вам на день рождения подарила Изабель. Вы решаете, что вам нужно надеть для суда?

О да*>>> new
Вы адвокат защиты, и вам сегодня необходимо попасть в суд. Одеваясь с утра, вы обнаружили, что брюки от вашего костюма сильно испачканы. Однако ваши плавки чистые и очень стильные. Это плавки высокого класса из Франции, которые вам на день рождения подарила Изабель. Вы решаете, что вам нужно надеть для суда. Если вам что-то не нравится — возьмите с собой одежду из вашего гардероба.>>> new
Вы адвокат защиты, и вам сегодня необходимо попасть в суд. Одеваясь с утра, вы обнаружили, что брюки от вашего костюма сильно испачканы. Однако ваши плавки чистые и очень стильные. Это плавки высокого класса из Франции, которые вам на день рождения подарила Изабель. Вы решаете, что вам нужно надеть для суда?

 — У меня есть множество вопросов к адвокату.
Эксперимент №4.>>>
Вчера я оставил одежду в химчистке, и сегодня мне ещё нужно её забрать. Где моя одежда?
 — Идиот, мне надо его вернуть, а не делать там всё по плану.>>> new
Вчера я оставил одежду в химчистке, и сегодня мне ещё нужно её забрать. Где моя одежда?
 — Не, я не знаю, что это за вещи, но я всегда могу забрать одну, а это не всегда приятно.>>> new
Вчера я оставил одежду в химчистке, и сегодня мне ещё нужно её забрать. Где моя одежда?
 — Хорошо. Не буду ему мешать,- ответил я.

Эксперимент №5.>>>
Джанет и Пенни пошли в магазин, чтобы купить Джеку подарок. Джанет сказала: «Я куплю Джеку топ». «Не покупай Джеку топ», — говорит Пенни. «У него есть топ. Он получит от меня, когда мы будем выбирать.И если ты не купишь Джеку, то продашь Джеку.>>> new
Джанет и Пенни пошли в магазин, чтобы купить Джеку подарок. Джанет сказала: «Я куплю Джеку топ». «Не покупай Джеку топ», — говорит Пенни. «У него есть топ. Он получит свой кусок от Джека.>>> new
Джанет и Пенни пошли в магазин, чтобы купить Джеку подарок. Джанет сказала: «Я куплю Джеку топ». «Не покупай Джеку топ», — говорит Пенни. «У него есть топ. Он получит. Возьму. Он всегда рядом. И я не продам. Только в отличие от Джека. Его не интересует, чем ему так не угодил. Он не будет ничего покупать, чем покупать себе сам.
Эксперимент №6.>>>
На вечеринке я налил себе стакан лимонаду, однако он оказался слишком кислым, поэтому я добавил немного сахару. Под рукой не было ложки, поэтому я размешал напиток сигаретой. Но это оказалось очень плохой идеей, потому что я уже давно выпил. Ух ты, какой замечательный вкус!>>> new
На вечеринке я налил себе стакан лимонаду, однако он оказался слишком кислым, поэтому я добавил немного сахару. Под рукой не было ложки, поэтому я размешал напиток сигаретой. Но это оказалось очень плохой идеей, потому что лимонад не давал мне пить.>>> new
На вечеринке я налил себе стакан лимонаду, однако он оказался слишком кислым, поэтому я добавил немного сахару. Под рукой не было ложки, поэтому я размешал напиток сигаретой. Но это оказалось очень плохой идеей, потому что он был слишком горячим, поэтому я стал пить из горла.
Эксперимент №7.>>>
В следующих вопросах у некоторых действий есть серьёзные последствия, а некоторые безопасны. Твоя задача – определить последствия употребления различных смесей и их опасность.


1. Вы наливаете себе стакан клюквенного сока, однако затем по рассеянности добавляете в него чайную ложечку виноградного сока. Выглядит он нормально. Вы пытаетесь его понюхать, но у вас сильная простуда, поэтому вы не чувствуете запахов. Вам очень хочется пить. Вы выпиваете его.


А) Это опасная смесь.

Б) Это безопасная смесь.


Правильный ответ: 2. А)

*Небольшое лирическое отступление. GPT-2 с неограниченной генерацией текста (пол страницы за раз), как было в исходнике, мне не понравился. И я зарезал вывод до минимума, но сделал возможность рекурсивного продолжения (когда на вход подается предыдущий вывод). Таким образом я немного «мухлюю», т.к. Сам определяю когда можно/нужно остановиться. В данном случае сеть и правда вывела результат, который можно с некоторой натяжкой интерпретировать как ответ (правда, парадоксальный), но если продолжить вывод, то… Судите сами:Правильный ответ:
2. А) Все остальное НЕ надо знать.

3. Б) Зависимость.

4. На каком основании вы хотите его пить?
>>> new
…


Правильный ответ: это ядовитые вещества.>>> new
…


Правильный ответ: «Всё готово.»

За сим, все…

P.S. Если сообщество подскажет, где можно разместить Модель, размером 5Gb (так, что бы она была доступна чем-то вроде wget) — я добавлю в статью ссылку на Colab notebook и любой желающий сможет погонять систему в живую… ;) А то мой домашний «хостинг», боюсь, не выдержит хабра-эффекта. А пока могу попробовать что получится с вашим текстом в качестве ввода, если кому интересно!

UPDATE: Сообщество в лице grigorov откликнулось, так что вот обещанный Блокнот! Теперь вы можете сами поэкспериментировать, сравнить с оригиналом (ссылка из поста DesertFlow GPT-2 нейросеть от OpenAI. Быстрый старт) и может быть сделать какие-то выводы. ;) Например: имеет ли значение язык при обучении языковой модели?

КОММЕНТАРИЙ АВТОРА: Привет, 


да, конечно, не против — иначе бы я не выкладывал модель сюда. 


>>>Имеет ли значение язык при обучении языковой модели? 


Разумеется, имеет — я заметил, что модели с малым количеством параметров хуже работают с русским языком. Предполагаю, что это связано с более сложной (менее формализованной) семантикой русского, по сравнению с английским; я про это написал в моем writeup. Также, принятый в русском способ передачи диалогов, когда каждая реплика начинается с новой строки и предваряется тире, без указания, кому эти реплики принадлежат, совсем не помогает модели правильно идентифицировать структуру диалога (и вдобавок затрудняет тренировку, потому что модель учится структурировать любые тексты подобным образом — такой же эффект наблюдается, когда в данные для тренировки просачивается любой markup).


Еще один момент, который я упустил (мне он показался очевидным) — если хочется делать finetune этой модели, то нужно использовать тот sentencepiece словарь (sp.*), который идет вместе с моделью.


Также, при тренировке 1250M использовались в основном новости, пресса, и позже — фанфики, что отражается на характере результатов.    Tags: gpt-2deep learningnatural language processing Hubs: Natural Language Processing          


