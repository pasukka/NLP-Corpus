

Заметки об NLP (часть 9) / Habr


              8  January  2010 at 20:05  Заметки об NLP (часть 9) Artificial Intelligence Natural Language Processing *      (Первые части: 1 2 3 4 5 6 7 8). Да возрадуются минусующие, сегодня представляю вниманию читателей последнюю, по всей видимости, часть «Заметок». Как и предполагалось, мы поговорим о дальнейшем семантическом анализе; также я порассуждаюю немного о том, чем в принципе можно заняться в нашей области и какие есть трудности «научно-политического» характера.

В предыдущей части мы обсуждали «синтакстико-семантический анализатор», при разборе фразы обращающий внимание не только на синтаксис фразы, но и на смысл входящих в предложение слов. Тогда мне показалось, что проще всего приравнять «семантику» к переводу: умеем перевести слово, значит, понимаем его смысл.

Надо сказать, что в некоторых случаях знание базовой семантики слова необходимо даже для синтаксического анализа, если под синтаксическим анализом понимать не только установление связи между словами, но и выявление её роли. Например, фразы «Иван пришёл из дома» и «Иван пришёл из вежливости» синтаксически устроены одинаково. Однако в первом случае «из дома» — это обстоятельство места (откуда), а во втором — причины (почему). Если не видеть разницы между «домом» и «вежливостью», определить роль члена предложения не получится.

Однако это так, ремарка в сторону. Основной вопрос в другом: существует ли другой способ определения «смысла» кроме перевода на иной язык? По всей видимости, слова можно определять только через другие слова, и в этом проблема. В комментариях уже обсуждались «языки-посредники» — интерлингва и аймара. По сути дела, их назначение как раз и состоит в «эталонном» описании семантики слова. Слова естественного языка (русского, английского и т.д.) каким-либо образом переводятся на интерлингву, а далее с интерлингвы на целевой язык. Соответственно, задача интерлингвы — хранить смысл слова, полученного из языка-источника, и отображать смысл на целевой язык.

Однако есть и попытки подойти к задаче более научно, а именно разработать специальный формальный язык для описания смыслов. Мой научный руководитель (Виталий Алексеевич Тузов) сам занимался этим направлением. Понятно, что его подход мне известен лучше всего. Впрочем, думаю, что между различными подходами больше общего, чем разного.

Толково-комбинаторный словарьНаверно, будет честно ещё до Тузова упомянуть об известном Толково-комбинаторном словаре Мельчука. Это поистине грандиозное начинание: не могу точно сказать, сколько слов русского языка в него вошло, но для французского за 20 лет работы (не в курсе, насколько активной) было описано всего около пяти сотен слов. То есть дело трудное.

Смысл работы таков. Любой толковый словарь трактует слова неформально: одно определяется через другое. В известной степени, это требует от нас определённого культурного «бэкграунда», иначе мы рискуем попасть в ловушку лемовских сепулек, то есть ходить по кругу, вместо искомого смысла получая себе на голову новые и новые слова.

Вот математика, скажем, работает не так. Имеются аксиомы, их немного. А дальше с помощью строгого языка рассуждений над этими аксиомами надстраиваются теоремы. Можно ли описывать таким же образом слова русского языка? Давайте посмотрим, что получилось у Мельчука:







Видите — слово описано как можно более формально, даже с буквенными переменными :) Обратите внимание на эти чеканные формулировки:







(«каузированное» значит «вызванное»). Заметьте, человек поступает даже не просто «как свинья», а как «свинья 2б»:



 



Соответственно, упомянутая здесь «свинья 1а» описана следующим образом:



 



К счастью, Мельчук — человек известный, он не нуждается в моих комплиментах. Но в любом случае хочу сказать, что сама идея такого словаря очень прогрессивна, и независимо от той роли, которую словарь в итоге займёт в науке и культуре XX века, я бы отдал дань уважения этой работе. Вот вы подумайте, многие ли гуманитарии способны таким вот математическим способом излагать толкования слов?

Помимо строгого описания слов, Мельчуку принадлежит ещё одна прекрасная идея: лексические функции. Суть их в том, что мы используем самые разные слова для описания одной и той же семантической операции. Например, у Мельчука используется функция Magn(), «усиливающая» переданное ей слово-аргумент. Чего общего между словами «тяжёлый», «бурный» и «большой»? А вот что:

 Magn(болезнь) = тяжёлая болезнь
 Magn(аплодисменты) = бурные аплодисменты
 Magn(радость) = большая радость 

Машинно-читаемый семантический словарьТузов попытался сократить описания Мельчука до машинно-читаемых формул. Для этого, во-первых, была расширена «аксиоматика». Скажем, слово «свинья» было сочтено атомарным — то есть можно считать, что «свинья» есть некий объект семантического поля языка, и «объяснять» его компьютеру, в принципе, незачем. Можно приписать атрибуты, если есть желание. Объяснение же неизбежно выльется в длинную абракадабру, освещающую самые разные свинские аспекты.

Во-вторых, был разработан механизм «семантических фунцкий», похожих на лексические функции Мельчука. Разница в том, что Мельчук всё-таки создавал словарь для людей — он объясняет слова языка. Тузов, по большому счёту, оперирует только смыслами, а какие конкретно слова за ними стоят — вопрос второй. Если какое-либо слово можно описать с помощью «атомов» и семантических функций, так оно и описывается. Например, имеются функции «становиться», «иметь свойство» и «усиливать»: IncepCopul(), Copul() и Magn(). Тогда с их помощью можно выразить слова мулатка, краснеть и огромный следующим образом:

 мулатка Copul(мулат, женщина) // мулат, который является женщиной
 краснеть IncepCopul(x, красный) // "x становится красным"
 огромный Copul(x, Magn(большой)) // x огромен, если он имеет сильно выраженное свойство "большой" 

Здесь я не хотел бы акцентировать внимание на особенностях данного конкретного формализма — подходы, идеи могут сильно отличаться. Должна быть ясна главная мысль: разработать систему «атомарных» понятий и «функций» над понятиями, с помощью которых можно описывать новые понятия. Тогда можно попытаться разработать формальный толковый словарь, математически описывающий слова (а не гоняющий по кругу, пытаясь определить одно через другое). Таким образом, мы уходим от слов и приходим к смыслам.

Если слово описано формулой, а предложение, соответственно, является композицией формул, то слова и предложения можно как-то изучать математически. Например, «раскрывать скобки», применять операции и так далее. Пищи для ума в этой идее предостаточно… Кстати, что-то подобное высказывается в работах Харриса об Operator Grammars, но честно признаюсь, его трудов я не осилил. Текст там куда ближе к традиционной лингвистике (много слов и мало математики :) ).

Семантические формулы могут быть полезны хотя бы в машинном переводе. Даже если вы не можете перевести какой-нибудь кусок, можно просто «раскрыть» формулу, заменяя лексические функции чеканным математическим текстом. Допустим, вы знаете, как по-английски «мулат» и «женщина», но у вас нет английского слова «мулатка» в словаре. Зато есть русскоязычный толковый семантический словарь. Тогда, встретив «мулатку», на английский можно перевести соответствующую фразу из семантического словаря: «мулат, который является женщиной».

В идеале, целые словосочетания из разных языков должны отображаться на одни и те же семантические формулы. Учительница — это «учитель, который является женщиной». А по-английски одного слова «учительница» нет, напишут что-то вроде «female teacher», если надо подчеркнуть пол — но на выходе будет та же самая формула.

Пополняя базу данных переводов семантических формул, можно добиваться всё меньшей и меньшей корявости перевода. То есть автоматический переводчик начинает с «мулата, который является женщиной», и при полной базе данных уже понимает, что правильный перевод — это просто «мулатка». Так же, в принципе, как и мы с вами — не зная точного перевода, начинаем объяснять слово через более простые.

А иногда это будет (впрочем, не забывайте, я теоретизирую!) просто спасать положение, если требуемого слова в целевом языке попросту нет — тогда «раскрытие формулы» может дать понятие о происходящем. Пример не праздный. Скажем, в финском нет глагола «иметь», как ни странно это звучит. Можно сказать «у меня есть» («у тебя есть», «у него есть»), но абстрактно «иметь» нельзя. И перевести даже такую простую фразу как «хорошо иметь собаку!» оказывается сложнее, чем казалось бы. Есть, правда, глагол «владеть», но по-фински «хорошо владеть собакой!» звучит так же глупо, как и по-русски.

А теперь перейдём от семантики к политике :)

Куда податься? Вот тут я не специалист, сам в процессе :) Но некоторые мысли хотелось бы озвучить. Вообще говоря, сейчас мы всё ещё переживаем последствия AI Winter. На ИИ в целом и на компьютерную лингвистику в частности возгалались слишком большие надежды поначалу. Много чего лопнуло, и амбициозные проекты вроде Толково-комбинаторного словаря сейчас не в моде. Пока умные люди размышляют, почему так произошло, распределители ресурсов сконцентрировались на чётких приложениях отдельных методик. Умеем выполнять морфологический анализ? Отлично! Умеем разделять текст на предложения? Прекрасно — применим! Так мало-помалу добились отдельных неплохих результатов. Но в целом определённая стагнация присутствует. Например, едва ли не самым популярным коммерческим машинным переводчиком остаётся SYSTRAN, а это технология 60-70-х годов!

Проблема компьютерной лингвистики в том, что проверка любой гипотезы требует массы усилий. Ну представьте себе, вот завтра я начну писать XDG-грамматику для русского. Может, к пенсии закончу. При этом (побрюзжу немного, ладно?) пропихнуть в научное сообщество маленькие прототипы тоже непросто. Например, пару раз мои статьи отклоняли с таким разъяснением: непонятно, насколько излагаемые идеи способны справиться со всем разнообразием сложностей естественного языка. Мысль вполне понятная, и даже правильная. Но, с другой стороны, как можно доказать способность «справиться со всем разнообразием сложностей», не написав грамматику/словарь/whatever, умеющую справляться со всем подряд? А это и есть полномасштабный проект.

Для себя я пока придумал такую штуку: NLP в образовании. Посмотрим, насколько она сработает. Суть в следующем. Если вы посмотрите на софт, обучающий физике или химии, там всё уже прекрасно: самые настоящие виртуальные лаборатории. От программ же, обучающих иностранному языку, просто плакать хочется. Все, думаю, видели эти убожества: кошмарные клипартовские картинки, пара сотен озвученных слов, цветастые интерфейсики, сделанные на коленке… А на выходе просто гибрид книжки и магнитофона, то есть реально компьютер не стал чем-то более прогрессивным по сравнению с традиционным оборудованием.

Вот я думаю, чего не хватает образовательному софту (для изучения языка), чтобы превратиться в виртуальную лабораторию? А вот NLP и не хватает! Начнём с простого: тот же морфологический анализатор/синтезатор. Уверен, такая софтина пригодится каждому человеку, изучающему язык. А если пойти дальше? Например, сейчас обкатываю идею «лего-кубиков» для слов. Представьте себе карточки со словами на экране компьютера. Их можно склеивать в словосочетания, а словосочетания — в предложения. Но при этом не сочетающиеся между собой слова клеиться не будут. Например, «красный» и «корова» не склеятся, пока не согласуешь их в роде, числе и падеже. Можно придумать мощные средства проверки правописания (не как в Ворде, а именно для нужд и типичных ошибок новичков...)

А почему, собственно, образование? Да потому, что словарный запас новичка мал, и используемые им конструкции тоже ограничены. Стало быть, даже прототип на 500 слов может быть реально полезен, может кому-то пригодиться, привлечь внимание… А то выльется и во что-то более серьёзное. Не знаю пока :) Но примкнуть к существующему проекту пока не надумал. Что где хорошее есть? Насколько помню, в Чехии пытаются работать с XDK. Но это чешский язык — так что, начнём с изучения чешского, а там примкнём, если проект ещё будет жив на тот момент? ;) И так везде!

В общем, на этой мажорной ноте закончим сей длинный цикл. Дальше — скорее всего, по следам дискуссий и по заявкам читателей. Ну или когда появятся интересные новости в нашей замечательной области. Всем спасибо за внимание!    Tags: NLPобработка текстовкомпьютерная лингвистика Hubs: Artificial IntelligenceNatural Language Processing          


