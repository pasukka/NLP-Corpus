

Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей / Habr


              10  June  2020 at 12:00  Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей Сбер corporate blog Machine learning *Project management *Artificial Intelligence Natural Language Processing *      Чтобы машины могли обрабатывать текст на русском и «понимать» его, в NLP используются универсальные языковые модели и трансформеры — BERT, RoBERTa, XLNet и другие — архитектуры от 100 миллионов параметров, обученные на миллиардах слов. Все оригинальные модели появляются обычно для английского, показывают state-of-the-art в какой-нибудь прикладной задаче и только спустя полгода-год появляются и для русского языка, без тюнинга архитектуры. 




Чтобы корректнее обучать свою модель для русского или другого языка и адаптировать её, хорошо бы иметь какие-то объективные метрики. Их существует не так много, а для нашей локали и вовсе не было. Но мы их сделали, чтобы продолжить развитие русских моделей для общей задачи General Language Understanding. 


Мы — это команда AGI NLP Сбербанка, лаборатория Noah’s Ark Huawei и факультет компьютерных наук ВШЭ. Проект Russian SuperGLUE — это набор тестов на «понимание» текста и постоянный лидерборд трансформеров для русского языка. 


Проект включает:


Тесты навыков: здравый смысл, целеполагание, логика.
Тестирование уровня человека для сравнения. 
Оценку существующих моделей — BERT, RоBERTa и другие. 
Ответы на вопрос, как оценить свою модель.

Тесты фактически представляют собой расширенный тест Тьюринга. Задача модели — доказать, что она сойдёт за среднего носителя языка. Тесты затрагивают такие базовые, но неосознаваемые знания об объектах и их взаимодействии:

Пример вопроса: «Почему судья стучал молоточком?»
А: «В зале стало шумно».
Б: «Жюри огласило свой вердикт». 


В этой подгруппе тестов робот должен был доказать свою начитанность и на основе всех русских текстов (а это вся литература, очень много новостей, учебников, баз знаний и статей из Интернета, включая Хабр) сделать вывод, почему судья так сделал. 

Почему модели нужно оценивать независимо?

В 2018 году, когда появились универсальные языковые модели и трансформеры, можно назвать «временем ImageNet в NLP». Что это значит? Раньше нельзя было построить ML-решение на 200 примеров от заказчика — а теперь можно! И вполне нормальную модель. Чем меньше примеров, тем дальше в лес (few-shot learning, one-shot learning, zero-shot learning...). Выборки не просто не хватает, а её практически и нет. Но актуальные модели справляются с этим, потому что они уже видели почти всю вариативность языка, — они обучены на десятках млрд слов на каждом языке, а языков может быть больше 100.


Появляются такие модели, конечно, в основном для английского, а для остальных берётся «что есть» и дотюнивается. Появился набор тестов, позволяющий всесторонне и очень тщательно оценить качество работы модели. Благодаря этим тестам появились метрики, позволяющие эти модели сравнивать между собой — и между своими промежуточными версиями и форками. 


Каждая модель получила свой огромный обучающий корпус, но, по сути, они более-менее одинаковы, и главные отличия — в архитектуре и заточенности под определённый тип заданий:




Некоторые модели мультиязычные, хотя в основном нет. На других языках работает, например, multilingual BERT, и даже частично переносит логику английского текста, хотя и обычно даёт качество чуть ниже модели, обученной на единственном языке. Насколько такая модель универсальна, если она оценивается только по своей англоязычной проходить тесты? Можно ли сказать, что такой «английский образ мышления» хуже подходит для японского дзен-процессинга или разбора исландских баз данных?


Benchmark-подход в машинном обучении подразумевает, что мы оцениваем вклад модели не в одну прикладную задачу, а сразу во много, и берём среднюю оценку. 

Собираем тесты или проблемы русского здравого смысла

Текст: «Сконструировали чудо-сани воспитанники Дома юношеского технического творчества. Базируются они на танке, который ребята сделали ранее, только срезали башенку, соорудили новый корпус и расписали хохломой — поскольку нас ждёт год Петуха».

Вопрос: «Есть ли между конструкцией и действиями в тексте причинно-следственная связь?»

А она есть!


Прежде чем мы разберёмся с этим примером, расскажу, как обычно составляются такие тесты. Англоязычный проект SuperGLUE, устроен так: набираются списки однотипных заданий, у которых содержание достаточно сложное — затрагивает знания о мире, здравый смысл, логику, целеполагание — а формат ответа простой, обычно — бинарная классификация. Часть из которых идёт на обучение модели, меньшая часть — на валидацию, и кусочек — на тест. Пример из начала главы как раз такой: в нём даётся пара предложений, и нужно ответить, есть ли между ними причинно-следственная связь или нет. Примеры в англоязычном наборе тестов сильно заточены под американские реалии — баскетбол, звёзды Голливуда и т. д. Собрать аналог мы решили, распарсив новостные сайты — и были поражены сложными примерами. Конкретно в данном случае, связь есть, потому что танк расписан хохломой в честь наступления года Петуха 