

Google: «У нас нет преимущества перед открытым кодом, и у OpenAI тоже нет» / Habr


               Google: «У нас нет преимущества перед открытым кодом, и у OpenAI тоже нет» Level of difficulty  
    Medium
   Reading time  
    12 min
   Views  26K Open source *Research and forecasts in IT *Copyright Artificial Intelligence The future is here  
    Analytics
   
    Translation
     
                Original author:
                
                  аноним из Discord
                  Утекший внутренний документ Google утверждает, что открытый исходный код AI обойдет Google и OpenAI.  ДИЛАН ПАТЕЛ и АФЗАЛ АХМАД (это не авторы, а копипастеры из Discord, авторы предисловия курсивом), 4 мая 2023Исходный текст Google "We Have No Moat, And Neither Does OpenAI".Текст ниже - только что утекший из Google документ опубликованный анонимным пользователем на открытом сервере Discord с разрешением на его переиздание. Мы проверили его подлинность. Единственные изменения касаются форматирования и удаления ссылок на внутренние веб-страницы. Документ является мнением только одного сотрудника Google, а не всей компании. Мы (Пател и Ахмад), как и другие исследователи с которыми общались, не согласны с тем, что написано ниже. Своё мнение мы опубликуем в отдельной статье для подписчиков. Мы просто поделимся документом, который поднимает очень интересные вопросы.У нас нет преимущества, И у OpenAI тоже нетМы много раз оглядывались через плечо на OpenAI. Кто первым преодолеет следующий рубеж? Каким будет следующий шаг? Но неудобная правда заключается в том, что мы не готовы выиграть эту гонку вооружений, и OpenAI тоже. Пока мы ссорились, третья сторона тихо забирала наш обед. Я, конечно, говорю об открытом исходном коде. Проще говоря, они опережают нас. То, что мы считаем "основными открытыми проблемами", уже решено и находится в руках людей. Достаточно назвать лишь несколько примеров:Большая языковая модель на телефоне: люди запускают базовые модели на Pixel 6 со скоростью 5 токенов/сек.Масштабируемый персональный AI: вы можете настроить персонализированный AI на своем ноутбуке за вечер. Ответственный выпуск: этот пункт не столько "решен", сколько "устарел". Существуют целые сайты с художественными моделями без каких-либо ограничений, и тексты отстают совсем немного.Мультимодальность: текущая мультимодальная модель ScienceQA была обучена до совершенства (SOTA) за час.Хотя наши модели все еще имеют небольшое преимущество в качестве, разрыв уменьшается удивительно быстро. Модели с открытым исходным кодом работают быстрее, их легче настраивать, они более конфиденциальны и весомее с точки зрения возможностей. Они делают с помощью 100 долларов и 13 миллиардов параметров то, с чем мы мучаемся имея 10 миллионов долларов и 540 миллиардов параметров. И делают это за недели, а не месяцы. Это имеет глубокие последствия для нас:У нас нет секретного ингредиента. Наша лучшая надежда - учиться и сотрудничать с тем, что делают другие вне Google. Мы должны приоритизировать интеграцию с решениями третьих сторон.Люди не будут платить за ограниченную модель, когда бесплатные, без ограничений альтернативы сопоставимы по качеству. Мы должны рассмотреть, где у нас действительная добавленная стоимость.Огромные модели замедляют нас. В долгосрочной перспективе лучшими моделями являются те, над которыми можно быстро работать. Мы должны уделить больше внимания вариантам поменьше, теперь, когда мы знаем, что возможно в режиме менее 20 миллиардов параметров.https://lmsys.org/blog/2023-03-30-vicuna/Что произошлоПосле утечки исходников LLaMA от Meta (признана экстремистской организацией и запрещена в России) в начале марта этого года, сообщество открытого кода получило в свои руки первую действительно способную базовую модель. У нее не было настройки инструкций или разговоров, а также отсутствовало обучение с подкреплением на основе отзывов людей (RLHF). Тем не менее, сообщество сразу же осознало значение того, что им было предоставлено.За ним последовал великолепный всплеск инноваций, с лишь несколькими днями между основными разработками (см. Хронологию для полного разбора). И вот мы здесь, всего через месяц, и существуют варианты с настройкой инструкций, квантованием, улучшением качества, оценками людей, мультимодальностью, обучение с подкреплением на основе отзывов людей и т. д., многие из которых базируются друг на друге.Самое главное, они решили проблему масштабирования настолько, что каждый может экспериментировать. Многие новые идеи приходят от обычных людей. Барьер для входа в обучение и экспериментирование снизился с общей работы крупной исследовательской организации до одного человека, одного вечера и мощного ноутбука.Почему мы могли бы это предвидетьВо многих отношениях это не должно быть сюрпризом для кого-либо. Нынешнее возрождение больших языковых моделей с открытым исходным кодом происходит сразу после возрождения в области генерации изображений. Сходство не осталось незамеченным сообществом, многие называют это "моментом стабильной диффузии (Stable Diffusion)" для большой языковой модели.В обоих случаях участие широкой публики с низкими затратами было обеспечено благодаря гораздо более дешевому механизму для тонкой настройки, называемому адаптацией низкого ранга или LoRA, в сочетании с существенным прорывом в масштабе (скрытая диффузия для синтеза изображений, Chinchilla для больших языковых моделей). В обоих случаях доступ к модели достаточно высокого качества стал стимулом для потока идей и итераций со стороны частных лиц и учреждений по всему миру. В обоих случаях это быстро обогнало крупных игроков.Эти вклады оказались решающими в области генерации изображений, установив стабильную диффузию на другой путь, отличный от Dall-E. Наличие открытой модели привело к интеграции продуктов, рынкам, пользовательским интерфейсам и инновациям, которых не было у Dall-E.Эффект был ощутимым: быстрое доминирование в плане культурного воздействия по сравнению с решением OpenAI, которое становилось все менее актуальным. Будет ли то же самое происходить с большими языковыми моделями, пока неизвестно, но основные структурные элементы одинаковы.Что мы пропустилиИнновации, которые стимулировали последние успехи открытого исходного кода, напрямую решают проблемы, с которыми мы до сих пор боремся. Уделяя больше внимания их работе, мы могли бы избежать изобретения велосипеда.LoRA - невероятно мощная технология, на которую мы, вероятно, должны обращать больше вниманияLoRA работает путем представления обновлений модели в виде факторизаций низкого ранга, что уменьшает размер матриц обновлений в несколько тысяч раз. Это позволяет тонко настраивать модель за долю стоимости и времени. Возможность персонализации языковой модели за несколько часов на потребительском оборудовании - большое достижение, особенно для стремлений, которые предполагают включение новых и разнообразных знаний в режиме близком к реальному времени (уже мертвая ссылка, нет копий на Wayback Machine). Тот факт, что эта технология существует, недооценивается внутри Google, хотя это напрямую влияет на некоторые из наших самых амбициозных проектов.Переобучение моделей с нуля - сложный путьЧастью того, что делает LoRA настолько эффективной, является то, что - как и другие формы тонкой настройки - она настраиваемая. Улучшения, такие как настройка инструкций, могут быть применены, а затем использованы, когда другие участники добавляют диалог, логическое рассуждение или использование инструментов. Хотя отдельные тонкие настройки имеют низкий ранг, их сумма не обязательно должна быть таковой, что позволяет с течением времени накапливать полноранговые обновления модели.Это означает, что по мере того, как становятся доступными новые и лучшие наборы данных и задачи, модель можно недорого поддерживать в актуальном состоянии, не оплачивая полный запуск.В отличие от этого, обучение гигантских моделей с нуля не только теряет предварительное обучение, но и все итеративные улучшения, которые были внесены поверх. В мире открытого исходного кода это занимает немного времени, прежде чем эти улучшения начинают доминировать, что делает полное переобучение чрезвычайно затратным.Мы должны тщательно подумать о том, требует ли каждое новое приложение или идея совершенно новой модели. Если у нас действительно есть значительные архитектурные улучшения, которые исключают прямое использование весов модели, тогда мы должны вложиться в более агрессивные формы дистилляции, которые позволят нам сохранить максимальное количество возможностей предыдущего поколения.Большие модели не обладают преимуществами в долгосрочной перспективе, если мы можем быстро обновлять малые моделиОбновления LoRA очень дешевы в производстве (~ 100 долларов) для самых популярных размеров моделей. Это означает, что почти любой человек с идеей может создать и распространить такую модель. Время обучения менее суток является нормой. На таком темпе накопительный эффект всех этих тонких настроек быстро преодолевает начальный недостаток размера. В самом деле, с точки зрения рабочих часов инженеров, темп улучшения этих моделей значительно опережает то, что мы можем сделать с нашими самыми большими вариантами, и лучшие из них уже во многом неотличимы от ChatGPT. Сосредоточение на поддержании некоторых самых больших моделей на планете на самом деле ставит нас в невыгодное положение.Качество данных масштабируется лучше, чем их размерМногие из этих проектов экономят время, обучаясь на небольших, тщательно отобранных наборах данных. Это свидетельствует о некоторой гибкости в законах масштабирования данных. Наличие таких наборов данных вытекает из логики в статье "Данные не делают то, что вы думаете" (та же мертвая ссылка), и они быстро становятся стандартным способом проведения обучения вне Google. Эти наборы данных создаются с использованием синтетических методов (например, фильтрация лучших ответов из существующей модели) и заимствования из других проектов, ни одна из которых не доминирует в Google. К счастью, эти высококачественные наборы данных с открытым исходным кодом, так что их можно использовать бесплатно.Прямая конкуренция с открытым исходным кодом - проигрышное предложениеЭтот недавний прогресс имеет прямые, немедленные последствия для нашей бизнес-стратегии. Кто будет платить за продукт Google с ограничениями использования, если есть бесплатная высококачественная альтернатива без них?И мы не должны рассчитывать на то, что сможем догнать. Современный интернет работает на открытом исходном коде по хорошей причине. У открытого исходного кода есть ряд значительных преимуществ, которые мы не можем повторить.Нам они нужны больше, чем мы имСохранение нашей технологии в секрете всегда было сомнительной идеей. Исследователи Google уходят в другие компании с определенной периодичностью, поэтому мы можем предположить, что они знают все, что мы знаем, и будут это знать, пока этот канал остается открытым.После того как передовые исследования в области больших языковых моделей стали доступными, удерживать конкурентное преимущество в технологии становится всё сложнее. Исследовательские учреждения по всему миру наращивают знания на основе работ друг друга, изучая пространство решений методом "в ширину", что значительно превосходит наши собственные возможности. Мы можем попытаться крепко держаться за наши секреты, пока внешние инновации уменьшают их ценность, но лучше постараться учиться друг у друга.Индивидуальные пользователи не сталкиваются с ограничениями лицензий в той же степени, что и корпорацииБольшая часть этих инноваций происходит на основе утечки весов моделей от Meta. Хотя это, несомненно, изменится по мере улучшения действительно открытых моделей, суть в том, что им не нужно ждать. Юридическая защита, предоставляемая для "личного использования", и непрактичность преследования отдельных лиц означают, что эти пользователи получают доступ к этим технологиям, пока они актуальны.Быть своим собственным клиентом означает понимание практики использованияПросматривая модели, которые люди создают в области генерации изображений, можно увидеть огромное разнообразие творчества, от генераторов аниме до HDR-пейзажей. Эти модели используются и создаются людьми, которые глубоко погружены в свои конкретные поджанры, что дает глубину знаний и эмпатии, с которыми мы не можем соперничать.Владение экосистемой позволяет использовать открытый код в свою пользуПарадоксально, но единственным явным победителем во всем этом является Meta. Их утечка модели позволила им получить труд целой планеты бесплатно. Поскольку большинство инноваций в сфере открытого исходного кода происходит на основе их архитектуры, им ничто не мешает напрямую внедрять эти инновации в свои продукты.Ценность владения экосистемой нельзя преувеличить. Google успешно использовал этот подход в своих продуктах с открытым исходным кодом, таких как Chrome и Android. Владея платформой, где происходят инновации, Google укрепляет свое положение в качестве лидера мысли и определяет направление, получая возможность формировать представление о идеях, превосходящих самого себя.Чем сильнее мы контролируем наши модели, тем привлекательнее становятся открытые альтернативы. Как Google, так и OpenAI оборонительно перешли к моделям выпуска, которые позволяют им сохранять жесткий контроль над использованием своих моделей. Но этот контроль – это фикция. Любой, кто хочет использовать большие языковые модели для неразрешенных целей, может просто выбрать одну из свободно доступных моделей.Google должен утвердить себя в качестве лидера в сообществе открытого исходного кода, взяв на себя роль лидера благодаря сотрудничеству, а не игнорированию широкого общественного разговора. Вероятно, это означает принятие некоторых неудобных шагов, таких как публикация весов моделей для небольших вариантов ULM (от переводчика: ULM – большая языковая модель Google). Это, в свою очередь, означает отказ от некоторого контроля над нашими моделями. Но такой компромисс неизбежен. Мы не можем надеяться и на то, чтобы стимулировать инновации, и на то, чтобы контролировать их.Эпилог: что c OpenAI?Весь этот разговор об открытом исходном коде может показаться несправедливым, учитывая текущую закрытую политику OpenAI. Почему мы должны делиться, если они этого не делают? Но факт в том, что мы уже делимся всем с ними в виде постоянного потока перехваченных старших исследователей. Пока мы не остановим этот поток, секретность теряет свою актуальность.В конечном счете, OpenAI не имеет значения. Они совершают те же ошибки, что и мы, в своем отношении к открытому исходному коду, и их способность сохранять преимущество обязательно вызывает сомнения. Альтернативы с открытым исходным кодом могут и в конечном итоге затмить их, если они не изменят свою позицию. По крайней мере, в этом отношении мы можем сделать первый шаг.Хронология24 февраля 2023 года - Запуск LLaMAMeta запускает LLaMA, открывая исходный код, но не веса. На этот момент LLaMA не настроена на инструкции или диалог. Как и многие современные модели, это относительно небольшая модель (доступная с 7 млрд, 13 млрд, 33 млрд и 65 млрд параметров), которая обучалась в течение довольно долгого времени и поэтому обладает достаточно высокими способностями относительно своего размера.3 марта 2023 года - Неизбежное происходитЧерез неделю LLaMA утекает в общественное пространство. Эффект на сообщество невозможно переоценить. Существующие лицензии запрещают использование для коммерческих целей, но внезапно каждый может проводить эксперименты. С этого момента инновации идут быстро и уверенно.12 марта 2023 года - Языковые модели на тостереЧуть больше чем через неделю Артем Андреенко заставляет модель работать на Raspberry Pi. На данный момент модель работает слишком медленно, чтобы быть практичной, потому что веса должны быть загружены в память и из нее. Тем не менее, это задает тон ряду усилий по минимизации.13 марта 2023 года - Тонкая настройка на ноутбукеНа следующий день Стэнфорд выпускает Alpaca, который добавляет настройку инструкций в LLaMA. Однако, более важным, чем сами веса, был репозиторий alpaca-lora от Эрика Ванга, который использовал тонкую настройку низкого ранга для обучения модели "в течение нескольких часов на одном RTX 4090".Внезапно каждый смог тонко настраивать модель для выполнения любых задач, начав гонку к дешевым проектам по тонкой настройке. В статьях с гордостью описывается общая сумма затрат в несколько сотен долларов. Более того, обновления низкого ранга могут быть легко распространены отдельно от исходных весов, что делает их независимыми от оригинальной лицензии от Meta. Ими может поделиться и применить каждый.18 марта 2023 года - Теперь это быстроГеорги Герганов использует квантование на 4 бита для запуска LLaMA на MacBook. Это первое практичное решение "без GPU".19 марта 2023 года - Модель на 13 млрд параметров достигает "равенства" с BardНа следующий день совместная работа нескольких университетов приводит к выпуску Vicuna, и с использованием оценки, основанной на GPT-4, предоставляют качественные сравнения результатов моделей. Несмотря на подозрительный метод оценки, модель существенно лучше предыдущих вариантов. Стоимость обучения: 300 долларов.Примечательно, что они смогли использовать данные от ChatGPT, обойдя ограничения на его API - они просто отобрали примеры "впечатляющих" диалогов ChatGPT, размещенных на сайтах вроде ShareGPT.25 марта 2023 года - Выберите свою собственную модельNomic создает GPT4All, который является одновременно и моделью, и, что более важно, экосистемой. Впервые мы видим модели (включая Vicuna), собранные в одном месте. Стоимость обучения: 100 долларов.28 марта 2023 года - Открытый исходный код GPT-3Cerebras (не путать с нашим Cerebra) обучает архитектуру GPT-3, используя оптимальное расписание вычислений, подразумеваемое в Chinchilla, и оптимальное масштабирование, подразумеваемое в 