

Как аннотировать документы для обучения ИИ распознавания текста / Habr


               Как аннотировать документы для обучения ИИ распознавания текста  Reading time  
    5 min
   Views  1.6K Data Mining *Image processing *Big Data *Machine learning *Artificial Intelligence   
    Translation
     
                Original author:
                
                  humansintheloop.org
                  Введение в ИИ для распознавания текста


Автоматизированная обработка документов — необходимое требование для модернизации рабочих процессов современных компаний; оно связано с широким спектром процессов, например, с управлением расходами, автоматизацией кредиторских задолженностей, снабжением, бухгалтерским делом, страхованием, адаптацией пользователей и сотрудников, подачей заявок на кредит, приёмом на страхование и так далее.


Однако обработка неструктурированных данных, например, PDF или отсканированных документов, при помощи ИИ — не такая уж простая задача. Для обучения и поддержки инструментов ИИ обработки и парсинга документов необходимо высококачественное аннотирование данных.


По оценкам специалистов, рынок интеллектуальной обработки документов к 2028 году вырастет до 6,3 миллиардов долларов, а большая часть решений для распознавания текста в этой сфере уже использует ИИ и машинное обучение.

Проблемы и решения

На основании своего огромного опыта аннотирования данных для обработки данных и распознавания текста мы приведём советы и рекомендации, помогающие гарантировать успех проекта ИИ:




Проблема
Решение


ИИ обработки документов сложно масштабировать на разные рынки, потому что модели, предназначенные для латиницы и языков наподобие английского гораздо более развиты, чем модели для других алфавитов.
С помощью многонациональной команды, работающей в разных регионах, вы можете собирать по всему миру произвольные обучающие датасеты с изображениями документов на многих языках. Это поможет масштабировать ваше решение на различные рынки с гарантией того, что оно хорошо будет работать во всех регионах.


Во время развёртывания ИИ-системы могут иметь дело с различными размерами, типографикой, дизайном и форматированием каждого документа, и им придётся подстраиваться под каждый из них.
При помощи сервисов для сбора состязательных примеров вы сможете выявить конкретные режимы отказа своей модели, требующие сбора дополнительных примеров, и дополнить свой датасет сложными примерами.


Документы могут содержать широкий спектр типов контента: в них может присутствовать рукописный текст поверх печатного, а также изображения с графиками. Кроме того, качество и освещённость изображений может сильно варьироваться, могут присутствовать размытые или плохо отсканированные страницы, сгибы и смятия, тени или другие дефекты. Иногда текст может быть расположен под наклоном или из-за форматирования, или просто потому, что всю страницу сканировали со сдвигом.
Эти проблемы можно решить, написав чёткие инструкции по аннотированию и воспользовавшись услугами опытных разметчиков, способных обучиться тонкостям процесса аннотирования: нужно ли аннотировать рукописный текст и подписи, размечать ли текст на графиках, и так далее. Кроме того, вы можете использовать дополнительные функции, например, использование четырёхточечных многоугольников или повёрнутых ограничивающих прямоугольников вместо прямых, что решает проблему выявления текста под наклоном.




Именно поэтому очень важно начинать с подходящими данными обучения и использовать методику human-in-the-loop для непрерывного совершенствования ИИ-моделей классификации документов и извлечения данных!

Типы аннотаций для ИИ распознавания текста

Ниже мы перечислим способы применения аннотирования данных для обработки данных, а также приведём рекомендации.

Распознавание документов


Многие приложения для сканирования или обработки документов начинают с простой задачи распознавания наличия на изображении документа и определения его местоположения; особенно справедливо это для мобильных приложений. Чтобы обучить такой распознаватель, необходим датасет, в котором документы точно аннотированы при помощи многоугольников или семантической сегментации для определения контура страницы.

Классификация документов


Для правильной обработки документов необходимо сначала классифицировать их по типу: например, счёт, чек, договор, книга, журнал и так далее. Здесь необходимо аннотирование в виде меток или разделение датасета по типам. Кроме того, документы можно классифицировать по языкам, на которых они написаны, но стоит помнить, что в документе может быть несколько языков.

Обнаружение текста


Чтобы понять текст в документе, сначала необходимо обнаружить его, чтобы идентифицировать само существование текста. Для этого необходимо аннотирование ограничивающими прямоугольниками или многоугольниками на уровне блоков, параграфов или строк.

Транскрипция текста


После обнаружения текста необходимо понять слова в нём и превратить их в машиночитаемый текст, применив модель распознавания текста (OCR). Большинство систем OCR сегодня работает на уровне слов или даже строк, а не на уровне символов, поэтому их англоязычная аббревиатура оказывается устаревшей, потому что означает «оптическое распознавание символов» (Optical Character Recognition). На этом уровне требования к датасету заключаются в аннотировании ограничивающими прямоугольниками с транскрипцией значения в каждом прямоугольнике.

Парсинг документов


После преобразования текста документа в текст без форматирования важно единообразно структурировать его на основании иерархии заголовков и подзаголовков, а также существования таблиц, графиков подписей и других текстовых разделов. Для этого требуется датасет, в котором ограничивающие прямоугольники разбиты на категории в зависимости от типа текста (например, H1, H2, H3 и так далее).

Извлечение сущностей


В некоторых случаях, например, при обработке счетов, необходимо распознавать и извлекать значения только отдельных сущностей. Например, это могут быть общая сумма счёта, стоимость за единицу, количество единиц, дата выставления счёта, дата оплаты и так далее. Задача может оказаться сложной, потому что расположение и форматирование элементов могут сильно варьироваться на разных счетах, в некоторых счетах отдельные элементы могут отсутствовать, другие элементы могут быть разбросаны по нескольким страницам, и так далее.

Наши любимые инструменты

Здесь представлены наши советы и рекомендации по лучшим инструментам, которые мы использовали для этого вида аннотирования; надеемся, они окажутся полезными для всех, кто работает над моделями парсинга или обработки документов.

1. LabelStudio (опенсорсный)



Опенсорсный инструмент LabelStudio может отлично подойти для новичков в аннотировании документов благодаря своему настраиваемому UI и возможности поддержки разных типов аннотирования.

2. V7 (бесплатная и платная версии)



V7 — это более функциональный инструмент, предоставляющий великолепные функции автоматической разметки ограничивающими прямоугольниками и многоугольниками, способными существенно ускорить процесс аннотирования. 

Как использовать human-in-the-loop при аннотировании документов для ИИ распознавания текстов

Обработка документов — это процесс, который выполняется компаниями непрерывно, поэтому чтобы обеспечивать актуальность моделей и учитывать неизбежный дрейф данных, важно использовать вмешательство людей постоянно, а не только при первоначальном обучении моделей. Вот некоторые из способов участия людей в цикле MLOps:

1. Сбор документов: сотрудники могут собирать многоязычные датасеты различных типов документов из множества географических регионов.

2. Аннотирование эталона данных: для обучения исходных моделей вы можете реализовать аннотирование с нуля полного датасета: классификацию, аннотирование ограничивающими прямоугольниками, транскрибирование и сегментацию страниц.

3. Валидация результатов при помощи активного обучения: после обучения исходной модели вы можете использовать её для предварительного аннотирования большой части датасета, что увеличит и скорость аннотаторов, и степень влияния их работы благодаря подготовке процесса активного обучения и повышения приоритета примеров, с которыми модель справляется хуже всего.

4. Сбор состязательных примеров: после обучения исходной модели можно расширить базовый датасет дополнительными сложными пограничными случаями, например, размытыми, тёмными или наклонёнными изображениями, а также отдельными классами, которые представлены недостаточно широко; необходимые данные выявляются при тестировании в зависимости от режимов отказа модели.

5. Обработка пограничных случаев в реальном времени: после развёртывания модели ваши сотрудники humans-in-the-loop в режиме 24/7 способны обрабатывать потенциальные пограничные случаи в реальном или почти реальном времени; для этого они используют простые запросы API и за считанные секунды отправляют правильный ответ, создавая второй слой верификации для самых критически важных ответов модели.      Tags: OCRAIразметка данныхdata labelingcomputer visionмашинное обучениеdata annotationsoftwaredatasetTraining Data  Hubs: Data MiningImage processingBig DataMachine learningArtificial Intelligence          


