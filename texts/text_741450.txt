

Подходит ли Nvidia RTX A4000 ADA для машинного обучения? / Habr


               Подходит ли Nvidia RTX A4000 ADA для машинного обучения? Level of difficulty  
    Easy
   Reading time  
    14 min
   Views  2.6K HOSTKEY corporate blog Hosting Computer hardware Artificial Intelligence Video cards       В апреле компания NVIDIA выпустила на рынок новый продукт — графический процессор малого форм-фактора RTX A4000 ADA, предназначенный для применения в рабочих станциях. Этот процессор пришел на смену A2000 и может быть использован для выполнения сложных задач, в том числе для научно-исследовательских и инженерных расчетов и для визуализации данных.RTX A4000 ADA оснащена 6144 ядрами CUDA, 192 тензорами и 48 ядрами RT, оперативной памятью GDDR6 ECC VRAM объемом 20 Гб. Одно из ключевых преимуществ нового графического процессора — его энергоэффективность: RTX A4000 ADA потребляет всего 70 Вт, что снижает затраты на электроэнергию и уменьшает тепловыделение в системе. Графический процессор также позволяет управлять несколькими дисплеями благодаря подключению 4x Mini-DisplayPort 1.4a.При сравнении графических процессоров RTX 4000 SFF Ada с другими устройствами того же класса можно отметить, что при работе в режиме одинарной точности данный продукт показывает производительность, аналогичную последнему поколению графического процессора RTX A4000, который потребляет вдвое больше энергии (140 Вт против 70 Вт). RTX 4000 SFF Ada построена на архитектуре Ada Lovelace и техпроцессе 5 нм. Это позволяет использовать ядра Tensor Core нового поколения и ядра трассировки лучей, которые значительно повышают производительность, обеспечивая более быструю и эффективную работу с трассировкой лучей и тензорными ядрами, чем RTX A4000. Кроме того, RTX 4000 SFF Ada упакован в небольшой корпус — длина карты 168 мм, толщина равна двум слотам расширения.Улучшение ядер трассировки лучей обеспечивает эффективную работу в средах, где используется эта технология, таких как 3D-дизайн и рендеринг. Объем памяти нового GPU (20 Гб) позволяет справляться с большими средами.Согласно заявлениям производителя, тензорные ядра четвертого поколения обеспечивают высокую производительность вычислений ИИ — двукратное увеличение производительности по сравнению с предыдущим поколением. Новые тензорные ядра поддерживают ускорение FP8. Эта особенность нового графического процессора может хорошо подойти тем, кто разрабатывает и развертывает модели ИИ в таких средах, как геномика и компьютерное зрение.Также стоит отметить, что увеличение количества механизмов кодирования и декодирования делает RTX 4000 SFF Ada хорошим решением для мультимедийных рабочих нагрузок, таких как работа с видео.Технические характеристики видеокарт NVIDIA RTX A4000 и RTX A5000, RTX 3090:RTX A4000 ADA NVIDIA RTX A4000NVIDIA RTX A5000RTX 3090АрхитектураAda LovelaceAmpereAmpereAmpereТехпроцесс5 нм8 нм8 нм8 нмГрафический процессорAD104GA102GA104GA102Количество транзисторов (млн)35,80017,40028,30028,300Пропускная способность памяти (Гб/с)280.0448768936.2Разрядность шины видеопамяти (бит)160256384384Память GPU (Гб)20162424Тип памятиGDDR6GDDR6GDDR6GDDR6XЯдра CUDA6,1446 144819210496Тензорные ядра192192256328Ядра RT48486482SP perf (терафлопс)19.219,2 27,835,6 RT Core performance (терафлопс)44.337,454,269,5Tensor performance (терафлопс)306.8153,4222,2285Максимальная мощность (Вт)70140230350ИнтерфейсPCIe 4.0 x 16PCI-E 4.0 x16PCI-E 4.0 x16PCIe 4.0 x16Разъемы4x Mini DisplayPort 1.4aДП 1.4 (4)ДП 1.4 (4)ДП 1.4 (4)Форм-фактор2 слота1 слот2 слота2-3 слотаПрограммное обеспечение vGPUнетнетесть неограниченноесть с ограничениямиNvlinkнетнет2x RTX A5000естьПоддержка CUDA11.68.68.68.6Поддержка VULKAN1.3естьестьесть, 1.2Цена (руб.)100 000125 000 220 000 100 000Описание тестовой средыRTX A4000 ADARTX A4000ПроцессорAMD Ryzen 9 5950X 3.4GHz (16 cores)OctaCore Intel Xeon E-2288G, 3,5 GHzОперативная память4x 32 Gb DDR4 ECC SO-DIMM2x 32 GB DDR4-3200 ECC DDR4 SDRAM 1600 МГцНакопитель1Tb NVMe SSDSamsung SSD 980 PRO 1TBМатеринская платаASRock X570D4I-2TAsus P11C-I SeriesОперационная система Microsoft Windows 10Microsoft Windows 10Результаты в тестахV-Ray 5 BenchmarkPoints scoredPoints scoredТесты V-Ray GPU CUDA и RTX позволяют измерить относительную производительность GPU при рендеринге. GPU RTX A4000 незначительно уступает по производительности RTX A4000 ADA (4% и 11% соответственно). Машинное обучение«Собаки против кошек»Для сравнения производительности GPU для нейросетей мы используем набор данных «Собаки против кошек» — тест анализирует содержимое фотографии и различает, изображена на фото кошка или собака. Все необходимые исходные данные находятся здесь. Мы запускали этот тест на разных GPU и в различных облачных сервисах и получили следующие результаты:Points scoredВ этом тесте результат RTX A4000 ADA незначительно превзошел RTX A4000 (9%), но следует помнить о небольшом размере и низком энергопотреблении нового GPU.AI-BenchmarkAI-Benchmark позволяет измерить производительность устройства во время выполнения задачи вывода AI-моделей. Единицы измерения могут зависеть от теста, но обычно это количество операций в секунду (OPS) или количество изображений в секунду (FPS).Points scoredRTX A4000RTX A4000 ADA1/19. MobileNet-V21.1 — inference | batch=50, size=224x224: 38.5 ± 2.4 ms1.2 — training | batch=50, size=224x224: 109 ± 4 ms1.1 — inference | batch=50, size=224x224: 53.5 ± 0.7 ms1.2 — training | batch=50, size=224x224: 130.1 ± 0.6 ms2/19. Inception-V32.1 — inference | batch=20, size=346x346: 36.1 ± 1.8 ms2.2 — training | batch=20, size=346x346: 137.4 ± 0.6 ms2.1 — inference | batch=20, size=346x346: 36.8 ± 1.1 ms2.2 — training | batch=20, size=346x346: 147.5 ± 0.8 ms3/19. Inception-V43.1 — inference | batch=10, size=346x346: 34.0 ± 0.9 ms3.2 — training | batch=10, size=346x346: 139.4 ± 1.0 ms3.1 — inference | batch=10, size=346x346: 33.0 ± 0.8 ms3.2 — training | batch=10, size=346x346: 135.7 ± 0.9 ms4/19. Inception-ResNet-V24.1 — inference | batch=10, size=346x346: 45.7 ± 0.6 ms4.2 — training | batch=8, size=346x346: 153.4 ± 0.8 ms4.1 — inference batch=10, size=346x346: 33.6 ± 0.7 ms4.2 — training batch=8, size=346x346: 132 ± 1 ms5/19. ResNet-V2-505.1 — inference | batch=10, size=346x346: 25.3 ± 0.5 ms5.2 — training | batch=10, size=346x346: 91.1 ± 0.8 ms5.1 — inference | batch=10, size=346x346: 26.1 ± 0.5 ms5.2 — training | batch=10, size=346x346: 92.3 ± 0.6 ms6/19. ResNet-V2-1526.1 — inference | batch=10, size=256x256: 32.4 ± 0.5 ms6.2 — training | batch=10, size=256x256: 131.4 ± 0.7 ms6.1 — inference | batch=10, size=256x256: 23.7 ± 0.6 ms6.2 — training | batch=10, size=256x256: 107.1 ± 0.9 ms7/19. VGG-167.1 — inference | batch=20, size=224x224: 54.9 ± 0.9 ms7.2 — training | batch=2, size=224x224: 83.6 ± 0.7 ms7.1 — inference | batch=20, size=224x224: 66.3 ± 0.9 ms7.2 — training | batch=2, size=224x224: 109.3 ± 0.8 ms8/19. SRCNN 9-5-58.1 — inference | batch=10, size=512x512: 51.5 ± 0.9 ms8.2 — inference | batch=1, size=1536x1536: 45.7 ± 0.9 ms8.3 — training | batch=10, size=512x512: 183 ± 1 ms8.1 — inference | batch=10, size=512x512: 59.9 ± 1.6 ms8.2 — inference | batch=1, size=1536x1536: 53.1 ± 0.7 ms8.3 — training | batch=10, size=512x512: 176 ± 2 ms9/19. VGG-19 Super-Res9.1 — inference | batch=10, size=256x256: 99.5 ± 0.8 ms9.2 — inference | batch=1, size=1024x1024: 162 ± 1 ms9.3 — training | batch=10, size=224x224: 204 ± 2 ms10/19. ResNet-SRGAN10.1 — inference | batch=10, size=512x512: 85.8 ± 0.6 ms10.2 — inference | batch=1, size=1536x1536: 82.4 ± 1.9 ms10.3 — training | batch=5, size=512x512: 133 ± 1 ms10.1 — inference | batch=10, size=512x512: 98.9 ± 0.8 ms10.2 — inference | batch=1, size=1536x1536: 86.1 ± 0.6 ms10.3 — training | batch=5, size=512x512: 130.9 ± 0.6 ms11/19. ResNet-DPED11.1 — inference | batch=10, size=256x256: 114.9 ± 0.6 ms11.2 — inference | batch=1, size=1024x1024: 182 ± 2 ms11.3 — training | batch=15, size=128x128: 178.1 ± 0.8 ms11.1 — inference | batch=10, size=256x256: 146.4 ± 0.5 ms11.2 — inference | batch=1, size=1024x1024: 234.3 ± 0.5 ms11.3 — training | batch=15, size=128x128: 234.7 ± 0.6 ms12/19. U-Net12.1 — inference | batch=4, size=512x512: 180.8 ± 0.7 ms12.2 — inference | batch=1, size=1024x1024: 177.0 ± 0.4 ms12.3 — training | batch=4, size=256x256: 198.6 ± 0.5 ms12.1 — inference | batch=4, size=512x512: 222.9 ± 0.5 ms12.2 — inference | batch=1, size=1024x1024: 220.4 ± 0.6 ms12.3 — training | batch=4, size=256x256: 229.1 ± 0.7 ms13/19. Nvidia-SPADE13.1 — inference | batch=5, size=128x128: 54.5 ± 0.5 ms13.2 — training | batch=1, size=128x128: 103.6 ± 0.6 ms13.1 — inference | batch=5, size=128x128: 59.6 ± 0.6 ms13.2 — training | batch=1, size=128x128: 94.6 ± 0.6 ms14/19. ICNet14.1 — inference | batch=5, size=1024x1536: 126.3 ± 0.8 ms14.2 — training | batch=10, size=1024x1536: 426 ± 9 ms14.1 — inference | batch=5, size=1024x1536: 144 ± 4 ms14.2 — training | batch=10, size=1024x1536: 475 ± 17 ms15/19. PSPNet15.1 — inference | batch=5, size=720x720: 249 ± 12 ms15.2 — training | batch=1, size=512x512: 104.6 ± 0.6 ms15.1 — inference | batch=5, size=720x720: 291.4 ± 0.5 ms15.2 — training | batch=1, size=512x512: 99.8 ± 0.9 ms16/19. DeepLab16.1 — inference | batch=2, size=512x512: 71.7 ± 0.6 ms16.2 — training | batch=1, size=384x384: 84.9 ± 0.5 ms16.1 — inference | batch=2, size=512x512: 71.5 ± 0.7 ms16.2 — training | batch=1, size=384x384: 69.4 ± 0.6 ms17/19. Pixel-RNN17.1 — inference | batch=50, size=64x64: 299 ± 14 ms17.2 — training | batch=10, size=64x64: 1258 ± 64 ms17.1 — inference | batch=50, size=64x64: 321 ± 30 ms17.2 — training | batch=10, size=64x64: 1278 ± 74 ms18/19. LSTM-Sentiment18.1 — inference | batch=100, size=1024x300: 395 ± 11 ms18.2 — training | batch=10, size=1024x300: 676 ± 15 ms18.1 — inference | batch=100, size=1024x300: 345 ± 10 ms18.2 — training | batch=10, size=1024x300: 774 ± 17 ms19/19. GNMT-Translation19.1 — inference | batch=1, size=1x20: 119 ± 2 ms19.1 — inference | batch=1, size=1x20: 156 ± 1 msРезультаты этого теста показывают, что производительность RTX A4000 незначительно (на 6%) выше, чем у RTX A4000 ADA. Однако, стоит отметить, что результаты тестов могут различаться в зависимости от конкретных задач и условий работы.PyTorchРезультаты с RTX A 4000BenchmarkingModel average train time (ms)Training double precision type mnasnet0_562.995805740356445Training double precision type mnasnet0_7598.39066505432129Training double precision type mnasnet1_0126.60405158996582Training double precision type mnasnet1_3186.89460277557373Training double precision type resnet18428.08079719543457Training double precision type resnet34883.5790348052979Training double precision type resnet501016.3950300216675Training double precision type resnet1011927.2308254241943Training double precision type resnet1522815.663013458252Training double precision type resnext50_32x4d1075.4373741149902Training double precision type resnext101_32x8d4050.0641918182373Training double precision type wide_resnet50_22615.9953451156616Training double precision type wide_resnet101_25218.524832725525Training double precision type densenet121751.9759511947632Training double precision type densenet169910.3225564956665Training double precision type densenet2011163.036551475525Training double precision type densenet1612141.505298614502Training double precision type squeezenet1_0203.14435005187988Training double precision type squeezenet1_198.04857730865479Training double precision type vgg111697.710485458374Training double precision type vgg11_bn1729.2972660064697Training double precision type vgg132491.615080833435Training double precision type vgg13_bn2545.1631927490234Training double precision type vgg163371.1953449249268Training double precision type vgg16_bn3423.8639068603516Training double precision type vgg19_bn4314.5153522491455Training double precision type vgg194249.422650337219Training double precision type mobilenet_v3_large105.54619789123535Training double precision type mobilenet_v3_small37.6680850982666Training double precision type shufflenet_v2_x0_526.51611328125Training double precision type shufflenet_v2_x1_061.260504722595215Training double precision type shufflenet_v2_x1_5105.30067920684814Training double precision type shufflenet_v2_x2_0181.03694438934326Inference double precision type mnasnet0_517.397074699401855Inference double precision type mnasnet0_7528.902697563171387Inference double precision type mnasnet1_038.387718200683594Inference double precision type mnasnet1_358.228821754455566Inference double precision type resnet18147.95727252960205Inference double precision type resnet34293.519492149353Inference double precision type resnet50336.44991874694824Inference double precision type resnet101637.9982376098633Inference double precision type resnet152948.9351654052734Inference double precision type resnext50_32x4d372.80876636505127Inference double precision type resnext101_32x8d1385.1624917984009Inference double precision type wide_resnet50_2873.048791885376Inference double precision type wide_resnet101_21729.2765426635742Inference double precision type densenet121270.13323307037354Inference double precision type densenet169327.1932888031006Inference double precision type densenet201414.733362197876Inference double precision type densenet161766.3542318344116Inference double precision type squeezenet1_074.86292839050293Inference double precision type squeezenet1_134.04905319213867Inference double precision type vgg11576.3767147064209Inference double precision type vgg11_bn580.5839586257935Inference double precision type vgg13853.4365510940552Inference double precision type vgg13_bn860.3136301040649Inference double precision type vgg161145.091052055359Inference double precision type vgg16_bn1152.8028392791748Inference double precision type vgg19_bn1444.9562692642212Inference double precision type vgg191437.0987701416016Inference double precision type mobilenet_v3_large30.876317024230957Inference double precision type mobilenet_v3_small11.234536170959473Inference double precision type shufflenet_v2_x0_57.425284385681152Inference double precision type shufflenet_v2_x1_018.25782299041748Inference double precision type shufflenet_v2_x1_533.34946632385254Inference double precision type shufflenet_v2_x2_057.84676551818848Результаты с A4000 ADABenchmarkingModel average train timeTraining half precision type mnasnet0_520.266618728637695Training half precision type mnasnet0_7521.445374488830566Training half precision type mnasnet1_026.714019775390625Training half precision type mnasnet1_326.5126371383667Training half precision type resnet1819.624991416931152Training half precision type resnet3432.46446132659912Training half precision type resnet5057.17473030090332Training half precision type resnet10198.20127010345459Training half precision type resnet152138.18389415740967Training half precision type resnext50_32x4d75.56005001068115Training half precision type resnext101_32x8d228.8706636428833Training half precision type wide_resnet50_2113.76442432403564Training half precision type wide_resnet101_2204.17311191558838Training half precision type densenet12168.97401332855225Training half precision type densenet16985.16453742980957Training half precision type densenet201103.299241065979Training half precision type densenet161137.54578113555908Training half precision type squeezenet1_016.71830177307129Training half precision type squeezenet1_112.906527519226074Training half precision type vgg1151.7004919052124Training half precision type vgg11_bn57.63327598571777Training half precision type vgg1386.10869407653809Training half precision type vgg13_bn95.86676120758057Training half precision type vgg16102.91589260101318Training half precision type vgg16_bn113.74778270721436Training half precision type vgg19_bn131.56734943389893Training half precision type vgg19119.70191955566406Training half precision type mobilenet_v3_large31.30636692047119Training half precision type mobilenet_v3_small19.44464683532715Training half precision type shufflenet_v2_x0_513.710575103759766Training half precision type shufflenet_v2_x1_023.608479499816895Training half precision type shufflenet_v2_x1_526.793746948242188Training half precision type shufflenet_v2_x2_024.550962448120117Inference half precision type mnasnet0_54.418272972106934Inference half precision type mnasnet0_754.021778106689453Inference half precision type mnasnet1_04.42598819732666Inference half precision type mnasnet1_34.618926048278809Inference half precision type resnet185.803341865539551Inference half precision type resnet349.756693840026855Inference half precision type resnet5015.873079299926758Inference half precision type resnet10128.268003463745117Inference half precision type resnet15240.04594326019287Inference half precision type resnext50_32x4d19.53421115875244Inference half precision type resnext101_32x8d62.44826316833496Inference half precision type wide_resnet50_233.533992767333984Inference half precision type wide_resnet101_259.60897445678711Inference half precision type densenet12118.052735328674316Inference half precision type densenet16921.956982612609863Inference half precision type densenet20127.85182476043701Inference half precision type densenet16137.41891860961914Inference half precision type squeezenet1_04.391803741455078Inference half precision type squeezenet1_12.4281740188598633Inference half precision type vgg1117.11493968963623Inference half precision type vgg11_bn18.40585231781006Inference half precision type vgg1328.438148498535156Inference half precision type vgg13_bn30.672597885131836Inference half precision type vgg1634.43562984466553Inference half precision type vgg16_bn36.92122936248779Inference half precision type vgg19_bn43.144264221191406Inference half precision type vgg1940.5385684967041Inference half precision type mobilenet_v3_large5.350713729858398Inference half precision type mobilenet_v3_small4.016985893249512Inference half precision type shufflenet_v2_x0_55.079126358032227Inference half precision type shufflenet_v2_x1_05.593156814575195Inference half precision type shufflenet_v2_x1_55.649552345275879Inference half precision type shufflenet_v2_x2_05.355663299560547Training double precision type mnasnet0_550.2386999130249Training double precision type mnasnet0_7580.66896915435791Training double precision type mnasnet1_0103.32422733306885Training double precision type mnasnet1_3154.6230697631836Training double precision type resnet18337.94031620025635Training double precision type resnet34677.7706575393677Training double precision type resnet50789.9243211746216Training double precision type resnet1011484.3351316452026Training double precision type resnet1522170.570478439331Training double precision type resnext50_32x4d877.3719882965088Training double precision type resnext101_32x8d3652.4944639205933Training double precision type wide_resnet50_22154.612874984741Training double precision type wide_resnet101_24176.522083282471Training double precision type densenet121607.8699731826782Training double precision type densenet169744.6409797668457Training double precision type densenet201962.677731513977Training double precision type densenet1611759.772515296936Training double precision type squeezenet1_0164.3690824508667Training double precision type squeezenet1_178.70647430419922Training double precision type vgg111362.6095294952393Training double precision type vgg11_bn1387.2539138793945Training double precision type vgg132006.0230445861816Training double precision type vgg13_bn2047.526364326477Training double precision type vgg162702.2086429595947Training double precision type vgg16_bn2747.241234779358Training double precision type vgg19_bn3447.1724700927734Training double precision type vgg193397.990345954895Training double precision type mobilenet_v3_large84.65698719024658Training double precision type mobilenet_v3_small29.816465377807617Training double precision type shufflenet_v2_x0_527.401342391967773Training double precision type shufflenet_v2_x1_048.322744369506836Training double precision type shufflenet_v2_x1_582.22103118896484Training double precision type shufflenet_v2_x2_0141.7021369934082Inference double precision type mnasnet0_512.988653182983398Inference double precision type mnasnet0_7522.422199249267578Inference double precision type mnasnet1_030.056486129760742Inference double precision type mnasnet1_346.953935623168945Inference double precision type resnet18118.04479122161865Inference double precision type resnet34231.52336597442627Inference double precision type resnet50268.63497734069824Inference double precision type resnet101495.2010440826416Inference double precision type resnet152726.4922094345093Inference double precision type resnext50_32x4d291.47679328918457Inference double precision type resnext101_32x8d1055.10901927948Inference double precision type wide_resnet50_2690.6917667388916Inference double precision type wide_resnet101_21347.5529861450195Inference double precision type densenet121224.35829639434814Inference double precision type densenet169268.9145278930664Inference double precision type densenet201343.1972026824951Inference double precision type densenet161635.866231918335Inference double precision type squeezenet1_061.92759037017822Inference double precision type squeezenet1_127.009410858154297Inference double precision type vgg11462.3375129699707Inference double precision type vgg11_bn468.4495782852173Inference double precision type vgg13692.8219032287598Inference double precision type vgg13_bn703.3538103103638Inference double precision type vgg16924.4353818893433Inference double precision type vgg16_bn936.5075063705444Inference double precision type vgg19_bn1169.098300933838Inference double precision type vgg191156.3771772384644Inference double precision type mobilenet_v3_large24.2356014251709Inference double precision type mobilenet_v3_small8.85490894317627Inference double precision type shufflenet_v2_x0_56.360034942626953Inference double precision type shufflenet_v2_x1_014.301743507385254Inference double precision type shufflenet_v2_x1_524.863481521606445Inference double precision type shufflenet_v2_x2_043.8505744934082ЗаключениеНовая видеокарта показала себя эффективным решением для выполнения различных рабочих задач. Благодаря своим компактным размерам она отлично подойдет для мощных компьютеров форм-фактора SFF (Small Form Factor). Также стоит отметить, что 6144 ядра CUDA и 20 ГБ памяти со 160-разрядной шиной делают эту карту одной из самых производительных на рынке. При этом низкое TDP в 70 Вт позволяет снизить затраты на энергопотребление. Четыре порта Mini-DisplayPort позволяют использовать карту с несколькими мониторами или в качестве решения для многоканальной графики.RTX 4000 SFF Ada представляет собой значительный прогресс по сравнению с предыдущими поколениями, обеспечивает производительность, эквивалентную карте с удвоенной потребляемой мощностью. Благодаря отсутствию разъема питания PCIe RTX 4000 SFF Ada легко интегрировать в рабочие станции с низким энергопотреблением при сохранении высокой производительности.Арендуйте выделенные и виртуальные GPU серверы с профессиональными графическими картами NVIDIA RTX A5000 / A4000 в надежных дата-центрах класса TIER III в Москве и Нидерландах. Принимаем оплату за услуги HOSTKEY в Нидерландах в рублях на счет российской компании. Оплата с помощью банковских карт, в том числе и картой МИР, банковского перевода и электронных денег. 										        Tags: nvidia rtxмашинное обучениеnvidia4090gpuaiнейросетиа4000benchmarkcuda  Hubs: HOSTKEY corporate blogHostingComputer hardwareArtificial IntelligenceVideo cards          


