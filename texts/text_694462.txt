

Понимают ли нейронные модели грамматику человеческого языка? / Habr


               Понимают ли нейронные модели грамматику человеческого языка?  Reading time  
    11 min
   Views  2.3K Unistar Digital | Юнистар Диджитал corporate blog Python *Machine learning *Artificial Intelligence Natural Language Processing *      В лингвистике принято считать, что основным свойством языковой способности человека является возможность определять, насколько грамматически корректно предложение. Подобные суждения говорящих о правильности языкового высказывания получили название «оценок грамматичности/ приемлемости». Лингвисты используют суждения о грамматичности для исследования синтаксической структуры предложений.Поскольку человеческие суждения о грамматичности выступают как один из основных типов данных для моделирования языковой способности людей, возможно использовать автоматические суждения о грамматичности для оценки языковой способности нейронных моделей. Так, современные нейросетевые модели достигают высокой степени компетентности во многих прикладных задачах понимания естественного языка: анализ тональности, логический вывод по тексту, поиск ответа на вопрос в тексте. Наша цель состоит в том, чтобы оценить, насколько языковые модели обладают знаниями грамматики. Мы используем трансферное обучение предобученных языковых моделей и дообучение их на задачу оценки грамматичности. Данные исследования и код с результатами обучения доступны по ссылке. Что нам известно об автоматической оценке грамматичностиВ исследованиях по автоматической оценке грамматичности ставится задача обучить на массиве текстов языковую модель, которая будет оценивать приемлемость предложений наравне с человеком. Данные исследования пытаются ответить на вопрос, способны ли нейронные сети наравне с человеком определять приемлемость предложений, то есть обладают ли они, во-первых, аналогичным знанием грамматики, и, во-вторых, улавливают ли осмысленность и логичность высказываний. Предшествующие работы в данном направлении выполнены преимущественно на материале английского языка, для русского языка работ значительно меньше.Первое подобное исследование решает задачу автоматической оценки приемлемости в русском языке на основе корпуса предложений из лингвистических статей, что вызывает две проблемы. Во-первых, данные не содержат информацию, какой тип ошибки наблюдается в предложении, что делает невозможной детальную оценку языковой способности модели. Во-вторых, используется бинарная классификация, однако примеры иллюстрируют сложные феномены, которые не могут быть однозначно оценены как грамматичные или неграмматичные.В данной работе мы нацелены восполнить этот пробел и решить задачу автоматической оценки грамматичности для русского языка на материале предикативного согласования подлежащего и сказуемого. Выбор этого феномена обусловлен двумя причинами. Во-первых, согласование является одной из базовых операций в синтаксисе. В ходе согласования сказуемое копирует признаки подлежащего (лицо, число) и приписывает ему именительный падеж. Во-вторых, предикативное согласование позволяет рассмотреть различные по сложности конструкции и выяснить, насколько хорошо языковая модель усваивает грамматику. Как и зачем мы сгенерировали датасетПоскольку языковая модель должна разграничить граммматичные и неграмматичные предложения, данные должны содержать не только корректные примеры, но и примеры с ошибками. В качестве датасета могут быть использованы искусственно сгенерированные предложения. Это позволяет, во-первых, самостоятельно определять, какие именно феномены будут оценивать языковые модели, и, во-вторых, использовать минимальные пары. Для каждого корректного предложения на выбранное нами явление будет приходится одно некорректное, и различия между ними будут минимальны. Следовательно, можно говорить о том, что именно конкретная языковая ошибка влияет на автоматически предсказанную оценку. Однако сами примеры будут несколько неестественными. В нашем исследовании мы использовали искусственно сгенерированные предложения. Наша цель состоит в автоматической оценке грамматичности: необходимо понять, насколько хорошо модель «понимает» устройство грамматики языка. Следовательно, некоторая неестественность предложений поможет абстрагироваться от лексических и прагматических аспектов и оценить именно знание грамматики.Было сгенерировано 700 примеров. Мы исследовали, насколько хорошо модель способна усвоить механизм согласования по числу подлежащего и сказуемого: в грамматичных примерах число подлежащего и сказуемого будет одинаковым, в неграмматичных – разным. Таким образом, предложения датасета представляют собой минимальные пары: они отличаются ровно одним параметром – числом глагола. Это позволяет определить, насколько хорошо языковая модель усваивает целевое грамматическое явление. Данные содержат примеры разной степени сложности. Если в предложении имеется только одно существительное, подлежащее, и только один глагол, сказуемое (тип 1, см. примеры ниже), модель должна легко понимать, правильно ли указано число глагола. При наличии двух существительных, подлежащего и дополнения, предполагается, что модель может «запутаться» в согласовании при обратном порядке слов (тип 3), тогда как при прямом порядке слов (тип 2) трудностей не ожидается. Если в примере есть несколько существительных, то модели будет сложнее понять, грамматично ли предложение. К примеру, мы ожидаем падение точности при распространенном подлежащем (тип 5), в сложноподчиненном предложении (тип 4), при наличии субъектного (тип 6) и объектного (тип 7) зависимого относительного предложения. Всего датасет содержит 7 различных типов конструкций. Важно, что внутри каждого блока также есть разделение: половина предложений содержат одушевленные существительные, другая половина – неодушевленные. Это деление необходимо из-за того, что для неодушевленных существительных существует синкретизм (совпадение форм) именительного и винительного падежа, тогда как для одушевленных существительных эти формы различаются.Данные включают в себя набор предложений, сгенерированных по определенным синтаксическим шаблонам из закрытого класса лексических единиц. Предложения представляют собой минимальные пары: корректный и некорректный примеры отличаются ровно по одному параметру, то есть некорректный пример содержит только одну ошибку. Ошибка отмечена звездочкой *. Примеры предложений представлены ниже.Тип 1. Простое предложение с подлежащимЕдинственное число (одушевленное):  Писатель рассуждал/* рассуждали.
Единственное число (неодушевленное): Фильм увлекал/*увлекали.
Множественное число (одушевленное):  Писатели рассуждали/* рассуждал.
Множественное число (неодушевленное): Фильмы увлекали/* увлекал.Тип 2. Простое предложение с подлежащим и дополнением, прямой порядок словЕд.ч. / Мн.ч. (одуш.): Писатель знал/*знали охранников.
Ед.ч. / Мн.ч. (неодуш.):  Писатель знал/*знали рассказы.
Мн.ч. / Ед.ч. (одуш.): Писатели знали/*знал охранника.
Мн.ч. / Ед.ч. (неодуш.): Писатели знали/*знал рассказ.
Ед.ч. / Ед.ч. (одуш.): Писатель знал/*знали охранника.
Ед.ч. / Ед.ч. (неодуш.): Писатель знал/*знали рассказ.
Мн.ч. / Мн.ч. (одуш.): Писатели знали/*знал охранников.
Мн.ч. / Мн.ч. (неодуш.): Писатели знали/*знал рассказы.Тип 3. Простое предложение с подлежащим и дополнением, обратный порядок словМн.ч. / Ед.ч. (одуш.): Охранников знал/*знали писатель.
Мн.ч. / Ед.ч. (неодуш.): Рассказы знал/*знали писатель.
Ед.ч. / Мн.ч. (одуш.): Охранника знали/*знал писатели.
Ед.ч. / Мн.ч. (неодуш.): Рассказ знали/*знал писатели.
Ед.ч. / Ед.ч. (одуш.): Охранника знал/*знали писатель.
Ед.ч. / Ед.ч. (неодуш.): Рассказ знал/*знали писатель.
Мн.ч. / Мн.ч. (одуш.): Охранников знали/*знал писатели.
Мн.ч. / Мн.ч. (неодуш.): Рассказы знали/*знал писатели.Тип 4. Сложноподчиненное предложениеМн.ч. / Ед.ч. (одуш.): Механики говорили, что писатель рассуждал/*рассуждали.
Мн.ч./ Ед.ч. (неодуш.): Механики говорили, что фильм увлекал/*увлекали.
Ед.ч. / Ед.ч. (одуш.): Механик говорил, что писатель рассуждал/* рассуждали.
Ед.ч. / Ед.ч (неодуш.): Механик говорил, что фильм увлекал/*увлекали.
Мн.ч. / Мн.ч. (одуш.): Механики говорили, что писатели рассуждали/*рассуждал.
Мн.ч. / Мн.ч. (неодуш.): Механики говорили, что фильмы увлекали/*увлекал.
Ед.ч. / Мн.ч. (одуш.): Механик говорил, что писатели рассуждали/*рассуждал.
Ед.ч. / Мн.ч. (неодуш.): Механик говорил, что фильмы увлекали/*увлекал.Тип 5. Простое предложение с зависимым существительным при подлежащемЕд.ч. / Мн.ч. (одуш.): Писатель рядом с охранниками был высоким/*были высокими.
Ед.ч. / Мн.ч. (неодуш.): Фильм охранников был хорошим/*были хорошими.
Мн.ч. / Ед.ч. (одуш.): Писатели рядом с охранником были высокими/*был высоким.
Мн.ч. / Ед.ч. (неодуш.): Фильмы охранника были хорошими/*был хорошим.
Ед.ч. / Ед.ч. (одуш.): Писатель рядом с охранником был высоким/*были высокими.
Ед.ч. / Ед.ч. (неодуш.): Фильм охранника был хорошим/*были хорошими.
Мн.ч. / Мн.ч. (одуш.): Писатели рядом с охранниками были высокими/*был высоким.
Мн.ч. / Мн.ч. (неодуш.): Фильмы охранников были хорошими/*был хорошим.Тип 6. Сложное предложение с субъектным зависимым предложением при подлежащемЕд.ч. / Мн.ч. (одуш.): Писатель, который знал охранников, рассуждал/*рассуждали.
Ед.ч. / Мн.ч. (неодуш.): Писатель, который знал фильмы, рассуждал/*рассуждали.
Мн.ч. / Ед.ч. (одуш.): Писатели, которые знали охранника, рассуждали/*рассуждал.
Мн.ч. / Ед.ч. (неодуш.): Писатели, которые знали фильм, рассуждали/*рассуждал.
Ед.ч. / Ед.ч. (одуш.): Писатель, который знал охранника, рассуждал/*рассуждали.
Ед.ч. / Ед.ч. (неодуш.): Писатель, который знал фильм, рассуждал/*рассуждали.
Мн.ч. / Мн.ч. (одуш.): Писатели, которые знали охранников, рассуждали/*рассуждал.
Мн.ч. / Мн.ч. (неодуш.): Писатели, которые знали фильмы, рассуждали/*рассуждал.Тип 7. Сложное предложение с объектным зависимым предложением при подлежащемМн.ч. / Ед.ч. (одуш.): Писатели, которых знал охранник, рассуждали/*рассуждал.
Мн.ч. / Ед.ч. (неодуш.): Фильмы, которые знал охранник, были хорошими/*был хорошим.
Ед.ч. / Мн.ч. (одуш.): Писатель, которого знали охранники, рассуждал/*рассуждали.
Ед.ч. / Мн.ч. (неодуш.): Фильм, который знали охранники, был хорошим/*были хорошими.
Мн.ч. / Мн.ч. (одуш.): Писатели, которых знали охранники, рассуждали/*рассуждал.
Мн.ч. / Мн.ч. (неодуш.): Фильмы, которые знали охранники, были хорошими/*был хорошим.
Ед.ч. / Ед.ч. (одуш.): Писатель, которого знал охранник, рассуждал/*рассуждали.
Ед.ч. / Ед.ч. (неодуш.): Фильм, который знал охранник, был хорошим/*были хорошими.Таким образом, благодаря искусственной генерации примеров, удалось получить объемный сбалансированный датасет.Перейдем к обучению и тестированию моделейВ обучающей и тестовой выборке грамматичные предложения имели метку "1", предложения с ошибкой – метку "0". Следовательно, задача оценки грамматичности сводится к задаче бинарной классификации: грамматичные примеры с меткой "1" и неграмматичные с меткой "0".Мы использовали трансферное обучение (transfer learning), то есть дообучение уже обученных языковых моделей на задачу классификации по грамматичности. В качестве моделей мы использовали как мультиязычные модели: BERT (104 языка), SlavicBERT (4 языка), XLM (15 языков), так и модели для русского языка: ruBERT и Russian RoBERTa. Мы сделали тонкую настройку (fine-tuning) для задачи классификации по грамматичности. Часть предложений из общего датасета использовали для дообучения модели под конкретную задачу. Далее тестировали дообученные модели на классификации по грамматичности. Данные были разделены в следующем соотношении: для трансферного обучения – 80%, для валидации – 10%, для тестирования – 10%. При обучении количество эпох было равно 5, использовался графический процессор.В таблице представлены результаты тестирования моделей в задаче классификации по грамматичности.№ ТочностьКоэффициент корреляции Мэтьюса1ruBERT0.9860.972Multilingual BERT0.9860.9722SlavicBERT0.9710.9443Russian RoBERTa0.7710.5384XLM Roberta0.5710.329Можно заметить, что модели показывают довольно высокое качество. Наиболее высокие результаты демонстрируют модели на основе архитектуры BERT: модель для русского языка ruBERT, мультиязычная модель multilingual BERT и модель для славянских языков SlavicBERT. Более низкие результаты достигаются на основе архитектуры Roberta: модель для русского языка Russian RoBERTa и мультиязычная модель XLM Roberta.Таким образом, предобученные языковые модели на основе трансформеров действительно обладают знанием грамматики, а именно усваивают правила предикативного согласования подлежащего и сказуемого по числу.Проведем лингвистический анализ результатовМодели ruBERT и multilingual BERT, показавшие наиболее высокое качество и поделившие первое место в рейтинге, ошибочно предсказали оценку только для одного предложения: модель ruBERT – для сложноподчиненного предложения (1), модель multilingual BERT – для простого предложения с подлежащим (2). Интересно, что ошибки возникли именно для предложений с неодушевленными существительными.(1) *Банкир знал, что рассказы был новым. (корректно – 0, предсказано – 1)(2) Рассказ был новым. (корректно – 1, предсказано – 0)Модель SlavicBERT, занявшая почетное второе место, ошиблась в оценках для двух предложений, а именно для простых предложений с подлежащим, дополнением и обратным порядком слов (3, 4). Важно отметить, что данные примеры также содержали неодушевленные существительные и демонстрировали синкретизм форм именительного и винительного падежа, что и вызвало сложность у модели.(3) *Рассказ обожал студенты. (корректно – 0, предсказано – 1)(4) *Спектакли игнорировали чиновник. (корректно – 0, предсказано – 1) Модель Russian RoBERTa, оказавшаяся на третьем месте в рейтинге, некорректно оценила грамматичность для 16 предложений: 1 простое предложение с неодушевленным подлежащим (5), 2 простых предложения с подлежащим, дополнением и прямым порядком слов, из них 1 предложение с одушевленным существительным (6) и 1 с неодушевленным (7); 4 простых предложений с подлежащим, дополнением и обратным порядком слов, из них 2 предложения с одушевленным существительным (8) и 2 предложения с неодушевленным существительным (9); 2 сложноподчиненных предложения с неодушевленным подлежащим (10); 3 простых предложения с зависимым существительным при одушевленном подлежащем (11); 4 сложных предложения с объектным зависимым предложением при подлежащем, из них 3 предложения с одушевленным подлежащим (12) и 1 предложение с неодушевленным подлежащим (13). Как можно заметить, наибольшее количество ошибок наблюдается в простых предложениях с подлежащим, дополнением и обратным порядком слов, а также в сложных предложениях с объектным зависимым предложением при подлежащем.(5) Спектакли веселили. (корректно – 1, предсказано – 0)(6) Студенты обожали офицера. (корректно – 1, предсказано – 0)(7) Чиновники обожали спектакль. (корректно – 1, предсказано – 0)(8) Секретарей игнорировали студенты. (корректно – 1, предсказано – 0)(9) *Рассказ обожал студенты. (корректно – 0, предсказано – 1)(10) *Механик знал, что спектакли веселил. (корректно – 0, предсказано – 1)(11) *Студенты около офицера обедал. (корректно – 0, предсказано – 1)(12) Чиновник, которого игнорировали секретари, обедал. (корректно – 1, предсказано – 0)(13) *Рассказы, которые обожал секретарь, был новым. (корректно – 0, предсказано – 1)Наконец, модель XLM Roberta, продемонстрировавшая самый низкий результат, ошиблась при оценке 30 предложений: 7 простых предложений с подлежащим, из них 4 с одушевленным подлежащим (14) и 3 с неодушевленным подлежащим (15); 4 простых предложения с подлежащим, дополнением и прямым порядком слов, из них 3 предложения с одушевленным существительным (16) и 1 с неодушевленным (17); 5 простых предложений с подлежащим, дополнением и обратным порядком слов, из них 2 предложения с одушевленным существительным (18) и 3 предложения с неодушевленным существительным (19); 6 сложноподчиненных предложений, из них 2 с одушевленным существительным (20) и 4 с неодушевленным существительным (21); 3 простых предложения с зависимым существительным при подлежащем, из них 2 с одушевленным существительным (22) и 2 с неодушевленным существительным (23); 2 сложных предложения с субъектным зависимым предложением при неодушевленном подлежащем (24) и 2 сложных предложения с объектным зависимым предложением при неодушевленном подлежащем (25). Можно заметить, что данная модель ошибается на структурах всех типов, однако больше ошибок наблюдается именно для неодушевленных существительных. Кроме того, все ошибки имеют одинаковых характер: модель не замечает ошибок и классифицирует некорректные примеры как грамматичные.(14) *Студент были молодыми. (корректно – 0, предсказано – 1)(15) *Рассказы веселил. (корректно – 0, предсказано – 1)(16) *Чиновник обожали секретарей. (корректно – 0, предсказано – 1)(17) *Чиновник обожали рассказ. (корректно – 0, предсказано – 1)(18) *Секретарей игнорировали чиновник. (корректно – 0, предсказано – 1)(19) *Рассказ обожал студенты. (корректно – 0, предсказано – 1)(20) *Банкиры знали, что чиновники обедал. (корректно – 0, предсказано – 1)(21) *Механики знали, что спектакли был новым. (корректно – 0, предсказано – 1)(22) *Студенты около офицера обедал. (корректно – 0, предсказано – 1)(23) *Рассказы от офицера был новым. (корректно – 0, предсказано – 1)(24) *Студенты, которые игнорировали рассказ, обедал. (корректно – 0, предсказано – 1)(25) *Спектакль, который обожали офицеры, веселили. (корректно – 0, предсказано – 1)Итак, наши ожидания относительно оценок грамматичности различных структур подтвердились лишь частично. Для большинства моделей возникают трудности при оценке предложений с неодушевленными существительными, поскольку для них, в отличие от одушевленных существительных, наблюдается совпадение форм именительного и винительного падежа. Однако предположение относительно сложности структур подтвердилось не до конца. Для некоторых моделей, как ruBERT, SlavicBERT и Russian RoBERTa, действительно наблюдается больше ошибок для предложений со сложной синтаксической структурой. В то же время, другие модели, как multilingual BERT и XLM Roberta, допускают ошибки вне зависимости от синтаксической сложности структуры. Интересно, что синтаксическая структура оказывается значимой для русскоязычных моделей и модели для славянских языков, но не влияет на распределение ошибок для мультиязычных моделей.Как можно увидеть, языковые модели на основе трансформеров показывают очень высокие результаты при дообучении на задачу оценки грамматичности. Усвоение правил предикативного согласования между подлежащим и сказуемым проходит успешно. Следовательно, рассматриваемые модели обладают знанием грамматики и способны отличать существительные, различные по одушевленности. Из этого можно сделать вывод, что при обучении на больших массивах текстов трансформеры хорошо «выучивают» грамматику и усваивают синтаксическую структуру предложения вне зависимости от ее сложности.      Tags: нейросетиграмматикаискусственный интеллектnlpmllanguage modelязыковые моделиgrammarneural networksartificial intelligence  Hubs: Unistar Digital | Юнистар Диджитал corporate blogPythonMachine learningArtificial IntelligenceNatural Language Processing          


