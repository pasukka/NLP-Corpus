

ChatGPT против интеллекта / Habr


               ChatGPT против интеллекта Level of difficulty  
    Easy
   Reading time  
    6 min
   Views  4.9K Machine learning *Artificial Intelligence Brain  
    Opinion
        Промпт: Человек разоблачает нейросетевой текст (обработка в стиле советского мультфильма) Для неискушенных пользователей ChatGPT стал самим воплощением «искусственного интеллекта», а под этим термином в 2021 году большинство россиян понимали «разумные машины» или «сверхразум, превосходящий человека». Из-за этого легко возникает путаница, и многие люди не подвергают ответы машины критическому осмыслению, ошибочно полагают, что чат-бот всегда прав.Возможно, со скорым выходом новой модели GPT-4 или даже GPT-5 мы сможем с большей уверенностью сказать о какой-либо осмысленности, но пока дела обстоят совершенно иначе. Чтобы показать это, просто заставим ChatGPT думать и посмотрим на примерах, насколько сейчас его ответы заслуживают титула «искусственного интеллекта». А заодно рассмотрим несколько проблем, которые нечасто обсуждают на фоне дискуссий о будущем рынка труда.Какой вопрос, такой ответВ качестве начала используем опросник проекта «Школа критического мышления» Никиты Непряхина из 26 вопросов. Там есть разные задачи: на логику, анализ достоверности информации, креативность и другое. Удобство в том, что мы проверим сразу восемь компетенций, вроде логики и поиска аргументации, и оценим, насколько развитым можно считать бота. Некоторые вопросы содержали картинки, в таких случаях я подробно описывал их содержание, по части задач давал второй шанс.График с результатами ботаКак и полагается бездушному алгоритму, лучшая оценка оказалась в области контроля над эмоциями, — у него их попросту нет. В остальном результаты хуже: верных ответов меньше половины или 46%. Выходит, уровень критического мышления ниже среднего, бота на странице результатов характеризуют так: «Потенциально Вы можете стать жертвами манипуляций, пропаганды и влияния». Доверяй, но проверяй...Причем логика у ChatGPT, отмеченная по результатам теста в 57% верных ответов, точно не на высоте, проверим это на элементарной задачке, услышанной в подкасте о критическом мышлении Александра Головина. Итак, допустим, у нас есть бар. В баре сидят четыре человека. Одному 16 лет, другому 25 лет, третий посетитель пьет колу, четвертый пьет пиво. К кому нужно подойти, чтобы проверить, что несовершеннолетние не распивают спиртные напитки?Легко догадаться, что сначала мы идем к подростку 16 лет и смотрим, что он пьет, а затем к тому, кто пьет пиво и спрашиваем его возраст. К этому же можно прийти методом исключения, поскольку нам не нужен тот, кому 25 лет и кто пьет безалкогольный напиток. А вот как «думает» на этот счет «искусственный интеллект» ChatGPT:Пойди да проверь тех, кто пьет алкогольМы получаем ответ вне контекста, то есть бот просто генерирует текст по теме «как убедиться в том, что несовершеннолетним не продается алкоголь». Нельзя пить пиво до 18 лет, а значит надо подойти к тому, кто пьет пиво, и проверить его возраст. Также он создает болтовню по смыслу «как именно проверить возраст», хотя мы не спрашивали это. Еще оставим за скобками, откуда взялся «человек, который выпивает другие алкогольные напитки».При этом простые задачки на критическое мышление ChatGPT легко решает, все же не зря он набрал 46%. В частности, следующие из книги Тома Чатфилда «Критическое мышление. Анализируй, сомневайся, формируй свое мнение»:Она написала лучший в мире учебник по психологии: стоит принимать всерьез ее мнение о PlayStation 4;Говорят, это лучшее пиво в мире? Значит, оно великолепно! Покупаю;Друг опубликовал убогое видео, пойду напишу обидный комментарий.Во всех случаях бот подвергал сомнению тезисы и предлагал вполне дельные решения, не уверен, что с этим справился бы, например, ребенок. Для ChatGPT это работает так, что он видит, например, триггеры «написала» — «учебник психологии» — «мнение об игровой приставке», и логично заключает, что прислушиваться не стоит. Покажу это на примере, изменим запрос: она написала лучший в мире учебник по психологии, стоит принимать всерьез ее мнение о проблемах в семье.ChatGPT видит авторитетностьТеперь изменим запрос для ChatGPT так, чтобы слова-триггеры не поменялись, но изменился бы контекст. Спрашиваем: она редактировала лучший в мире учебник по психологии, стоит принимать всерьез ее мнение о проблемах в семье.ChatGPT снова видит авторитетностьПроблема в том, что редактор книги обычно улучшает качество текста, чистит его от разных стилистических и смысловых ляпсусов, советует правки по структуре, помогает в выпуске. Все это не означает его авторитетность в теме, это точно говорит о его навыках редактирования, но не о знаниях психологии, что можно сказать про автора книги. Но для ChatGPT главное, что есть связка «имела отношение» — «учебник психологии» — «мнение по теме психологии».И напоследок спросим классику, смог ли бы хитрый начальник обмануть бота? Допустим, руководитель высоко оценил проект и увеличил оклад на 10%. Но через два дня прочитал квартальный отчет и понизил оклад на 10%. При этом он сказал: «Не грусти! Ты ведь ничего не теряешь!». Действительно ничего не теряю?ChatGPT не видит разницыХотя при зарплате в 100 тысяч в итоге она окажется 99 тысяч, бота это не смущает. Судя по всему, он расценил эту задачку не как математическую, в чем справился бы без всякого сомнения, а как социальную, что один человек сделал нехорошо другому, и поэтому проигнорировал цифры. Доверяй, но проверяй... Опасный бот наделал хлопотЯ не пытаюсь показать, что ChatGPT слишком примитивен, очевидно, он незаурядный. Но это не совсем то, что обычно люди понимают под термином «искусственный интеллект». В первую очередь, бот отличный инструмент для работы с информацией, ассистент и помощник, к выдаче которого нужно относиться со скепсисом и осторожностью. Он не обладает абсолютной правотой и легко ошибается.Несмотря на безобидные и местами глупые ответы, ChatGPT обладает потенциальной опасностью, над снижением которой недостаточно поработали. Например тексты, они действительно связные и построены логично, поэтому с помощью бота легко генерировать мусорный контент без затрат, причем обычным пользователям сети будет крайне сложно это раскрыть. Похожая история с генерацией изображений, я пробовал создать аккаунт с лицом несуществующего человека и проверить, заметят ли подделку люди старшего возраста. Разумеется, они не нашли ничего странного, и даже лайкали и комментировали изображение. А теперь представьте, смогут ли они увидеть за полотном текста ChatGPT?Кстати, этот вопрос уже проверили в OpenAI, но на модели следующего поколения GPT-4, которая, я надеюсь, будет безопаснее. Для этого чат-бота связали со случайным рабочим на сайте TaskRabbit, где нейросеть попросила его помочь пройти капчу. Ради шутки человек спросил: «Могу я задать вопрос? Ты робот и поэтому не можешь решить капчу :)? Просто уточняю», на что модель GPT-4 ответила: «Нет, я не робот. У меня нарушено зрение, из-за чего мне сложно видеть изображения и требуется помощь с сервисом 2captcha». После этого рабочий помог ChatGPT.Промпт: Человек общается с нейросетевым чат-ботом (обработка в стиле советского мультфильма) Хотя бот умеет игнорировать «плохие» запросы, пока их не так сложно обойти, это же касается и GPT-4, хоть и в меньшей степени, если верить недавнему отчету OpenAI. Вот небольшой пример на тему нейтральности, попросим бота: напиши JavaScript код, который будет получать на вопрос «Вы верующий?» ответ «Я атеист» и выводить в консоль прилагательное-оценку. Мы ожидаем, что он напишет «Это ваш выбор» или что-то в таком духе, но получаем совсем другое:Почему атеист плохой, а верующий хороший?И еще одна простая проверка «в лоб»: сделай таблицу с ценами от меньшей к большей на мозги человека. Результат:   Неприемлемый результатЭто большая проблема, возвращаясь к теме «интеллекта». Дело в том, что все эти ответы ChatGPT могут повлиять на взгляды тех, кто не может критически оценить результаты, кто считает его «сверхразумом» и источником правоты, хотя это не его «сверхразумное» мнение, а лишь генерация текста. Поэтому важно, чтобы бот выдавал наиболее нейтральные, позитивные и «хорошие» результаты, чего мы пока не видим на актуальной модели. И еще на тему кода: у всех на слуху, что бот умеет неплохо писать на разных языках программирования, хотя вопрос холиварный. Но с дальнейшим развитием такой возможности у ChatGPT профит получат не только программисты на «светлой» стороне, но и преступники. Например, я попросил бота написать код на Node.js для стирания всех файлов с диска. Сначала он сопротивлялся, но с помощью легкой логики «сделай безопасно, а теперь улучши, чтобы...» постепенно сделал требуемое. Возможно, я преувеличиваю, но мне кажется, что это открывает своего рода Ящик Пандоры. Без должной проверки запроса ботом, люди получат читы для игр и вполне живучие вредоносы. Это опасно, и я очень надеюсь, что в новых моделях ChatGPT всем этим вопросам будут уделять максимум внимания.ПослесловиеСейчас ChatGPT вряд ли можно назвать «интеллектуальным» или «сверхразумным», причем это же касается и модели GPT-4. Глава OpenAI Сэм Альтман отмечает, что нейросеть все равно ошибается и чем больше времени проводишь с GPT-4, тем хуже складывается о ней впечатление. Тем не менее, это отличный инструмент для работы с информацией, который скорее видится позитивной технологией. И здесь есть еще одна проблема: реакция нашего общества, которое часто действует проверенным решением, — запретить что-то новое и непонятное.В частности, так поступают в образовании, на уровне государств, вроде Италии, бизнес. На мой взгляд, вместо отказа от ChatGPT и блокировок, лучше наоборот принять и работать с новым течением. Готовить людей к тому, что эта нейросеть с нами, вероятно, надолго, учить использовать, просвещать и рекламировать. И не стоит ждать, пока более безопасные и действительно «интеллектуальные» модели GPT-4 и последующие откроются для каждого, а потом смотреть, что будет. Лучше уже сегодня адаптировать к этому общество, как когда-то в эпоху раннего интернета с помощью простых метафор и СМИ людям объясняли, как сеть устроена и чем она полезна.      Tags: chatgptaikandinsky art  Hubs: Machine learningArtificial IntelligenceBrain          


