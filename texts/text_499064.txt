

Альтернативное понимание контекста с помощью статистической языковой модели / Habr


              26  April  2020 at 21:23  Альтернативное понимание контекста с помощью статистической языковой модели Algorithms *Machine learning *Artificial Intelligence Learning languages Natural Language Processing * 
        Tutorial
           


В интернете полно статей на тему основанных на N-граммах языковых моделей. При этом, готовых для работы библиотек довольно мало.


Есть KenLM, SriLM и IRSTLM. Они популярны и используются во многих крупных проектах. Но есть проблемы:


Библиотеки старые, не развиваются.
Плохо поддерживают русский язык.
Работают только с чистым, специально подготовленным, текстом
Плохо поддерживают UTF-8. Например, SriLM с флагом tolower ломает кодировку.


Из списка немного выделяется KenLM. Регулярно поддерживается и не имеет проблем с UTF-8, но она также требовательна к качеству текста.


Когда-то мне потребовалась библиотека для сборки языковой модели. После многих проб и ошибок пришёл к выводу, что подготовка датасета для обучения языковой модели — слишком сложный и долгий процесс. Особенно, если это русский язык! А ведь хотелось как-то всё автоматизировать.


В своих исследованиях отталкивался от библиотеки SriLM. Сразу отмечу, что это не заимствование кода и не fork SriLM. Весь код написан полностью с нуля.

Небольшой текстовый пример:
Неожиданно из подворотни в Олега ударил яркий прожектор патрульный трактор!С лязгом выкатился и остановился возле мальчика.


Отсутствие пробела между предложениями — довольно частая опечатка. Такую ошибку сложно найти в большом объеме данных, при этом она ломает токенизатор.

После обработки, в языковой модели появится такая N-грамма:
-0.3009452 трактор!С лязгом выкатился

Разумеется, существует множество других проблем, опечаток, спецсимволов, аббревиатур, различных математических формул… Всё это нужно правильно обрабатывать.

ANYKS LM (ALM)

Библиотека поддерживает только операционные системы Linux, MacOS X и FreeBSD. Windows у меня нет и поддержка не планируется.

Краткое описание функционала

Поддержка UTF-8 без сторонних зависимостей.
Поддержка форматов данных: Arpa, Vocab, Map Sequence, N-grams, Binary alm dictionary.
Поддержка алгоритмов сглаживания: Kneser-Nay, Modified Kneser-Nay, Witten-Bell, Additive, Good-Turing, Absolute discounting.
Нормализация входных корпусов, приведение слов к нижнему регистру, умная токенизация, поддержка чёрного и белого списков.
Замена частот, замена N-грамм, добавление новых N-грамм с частотами, удаление N-грамм.
Прунинг — сокращение числа N-грамм, которые не соответствуют указанным критериям качества.
Смешивание языковых моделей: статическое, алгоритмом Байеса и линейно-логарифмическое.
Чистка плохих N-грамм — удаление N-грамм, у которых обратная частота backoff выше основной частоты.
Восстановление повреждённых N-грамм в языковой модели с последующим перерасчётом их backoff-частот.
Поддержка специализированных токенов слов, таких как: числа, римские числа, диапазоны чисел, аббревиатуры, любые другие пользовательские токены с помощью скриптов написанных на языке Python3.
Обработка «грязных текстов», извлечение правильного контекста из текстовых файлов.
Переопределение 