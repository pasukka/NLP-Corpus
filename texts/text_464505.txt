

Открытый проект Google помогает распознавать язык жестов с помощью смартфона / Habr


              21  August  2019 at 11:55  Открытый проект Google помогает распознавать язык жестов с помощью смартфона Machine learning *Smartphones Artificial Intelligence The future is here       


Миллионы людей общаются с помощью языка жестов, но до сих пор проекты по захвату сложных жестов и переводу их в устную речь не имели особого успеха. Новая методика отслеживания движений рук в реальном времени, разработанная лабораторией искусственного интеллекта Google и использующая фреймворк MediaPipe, может стать прорывом в этой сфере.


Методика использует машинное обучение для создания в реальном времени высокоточной карты руки и всех ее пальцев при помощи только смартфона и камеры.


«Современные подходы основаны, в первую очередь, на мощных десктопных средах. Наш метод работает в реальном времени на мобильном телефоне и даже масштабируется до передачи жестов нескольких рук», — пишут исследователи Google Валентин Базаревский и Фан Чжан. 




Машине может быть непросто распознать жесты. Руки часто закрывают друг друга, их движения могут быть слишком быстрыми. При разработке своей методики исследователи стремились хотя бы частично сократить объем данных, которые должен проанализировать искусственный интеллект. 


Во-первых, они отказались от идеи, чтобы система определяла положение и размер всей руки. Вместо этого в систему внедрена только функция поиска ладони. Когда ладонь распознана, движения пальцев могут анализироваться отдельно. Алгоритм распознаёт изображение руки и присваивает 21 координату, соответствующую расположению суставов и пальцев. Чтобы выполнить эту часть распознавания жестов, исследователям сначала пришлось вручную добавить эти точки к примерно 30 тысячам изображений рук в различных позах и ситуациях освещения, чтобы система машинного обучения могла воспринимать их и учиться.


Как только положение руки и пальцев определено, жест сравнивается с базой языка жестов. В результате получается быстрый алгоритм отслеживания, который работает на обычном смартфоне, а не на десктопе или в облаке. Все это проходит через кроссплатформенную среду MediaPipe.


Тем не менее, до настоящего понимания языка жестов машине ещё далеко, потому что жестовый язык использует обе руки, а также выражение лица и другие сигналы, которые искусственному интеллекту пока трудно распознавать. Проект находится в открытом доступе, чтобы другие разработчики могли работать с ним.    Tags: машинное обучениеискусственный интеллектязык жестовраспознавание жестовgoogle Hubs: Machine learningSmartphonesArtificial IntelligenceThe future is here          


