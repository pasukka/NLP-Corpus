

Эволюция метрик качества машинного перевода — Часть 1 / Habr


               Эволюция метрик качества машинного перевода — Часть 1 Level of difficulty  
    Easy
   Reading time  
    5 min
   Views  1.7K Machine learning *Natural Language Processing * 
    Review
        Заинтересовавшись задачами NLP (Natural Language Processing), в особенности FAHQMT (Fully Automatic High Quality Machine Translation), я решила разобраться, а как правильнее всего измерять качество машинного перевода. Разнообразных метрик очень много – какая среди них лучшая?В этой статье расскажу об итогах своего погружения в тему: какие существуют метрики качества машинного перевода, как они эволюционировали и какие из них на сегодняшний день наиболее адекватны. Часть 1 будет посвящена логике развития метрик и обзору основных традиционных метрик. В Части 2 подробнее остановимся на референсных нейросетевых метриках, а в Части 3 расскажем о безреференсных метриках и посмотрим на сравнительную эффективность различных метрик.Логика развития метрикОбычно о качестве машинного перевода судят, сравнивая его с неким эталоном (reference) – как правило, с переводом, выполненным человеком-переводчиком. На таком сравнении построено большинство существующих метрик, хотя и не все.Глобально метрики качества машинного перевода можно подразделить на традиционные и нейросетевые.1) Традиционные метрики сравнительно просты в расчете и прозрачны, наиболее известные из них разработаны до бума нейросетей. Чаще всего такие метрики основаны на подсчете числа совпадений символов / слов / cловосочетаний – их называют «lexic overlap metrics». 2) Большинство метрик, предложенных после 2016 года – нейросетевые. Первым шагом в применении нейросетей в расчете метрик стало использование векторных представлений слов (embeddings).Сначала близость embeddings машинного и эталонного переводов оценивалась  эвристическими методами (например, для метрик WMD, BERTScore, YiSi).Далее появились нейросети, последние слои которых принимают на вход embeddings машинного и эталонного переводов, а на выходе дают оценку качества перевода (такие как BLEURT, Prism).Затем возникли модели, на вход которых, помимо машинного и эталонного перевода, также может подаваться первоисточник – оригинал переводимого текста (COMET, UniTE).В параллель в рамках решения задачи Quality Estimation развивались модели, сравнивающие напрямую машинный перевод и первоисточник, без эталонного перевода. Так появилось то, что можно назвать безреференсными метриками (reference-free metrics).Сегодня наиболее используемые – метрики, предложенные до 2010 года, причем в 99% это BLEU.Источник: Marie et al., 2021При этом только за период с 2010 по 2020 было предложено более 100 метрик качества машинного перевода. Новые метрики лучше коррелируют с человеческой оценкой качества перевода, чем BLEU, и эксперты призывают исследователей наконец обратить на них внимание. Например, результаты воркшопа WMT Metrics Shared Task, ежегодно проводимого в рамках Conference on Machine Translation, в 2022 году были озаглавлены так: «Stop Using BLEU – Neural Metrics Are Better and More Robust» (Прекратите использовать BLEU – нейросетевые метрики лучше и надежней).Традиционные метрикиНаиболее известны и употребимы такие традиционные метрики как: BLEU, NIST, ROUGE, METEOR, TER, chrF, chrF++, RIBES. Рассмотрим их подробнее.BLEUBLEU (BiLingual Evaluation Understudy) — метрика, разработанная в IBM (Papineni et al.) в 2001. Основана на подсчете слов (unigrams) и словосочетаний (n