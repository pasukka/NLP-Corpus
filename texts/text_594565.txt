

Восстановление знаков пунктуации и заглавных букв — теперь и на длинных текстах / Habr


               9  December  2021 at 20:06  Восстановление знаков пунктуации и заглавных букв — теперь и на длинных текстах Python *Big Data *Machine learning *Natural Language Processing *      

После релиза нашей первой модели, расставляющей знаки препинания и большие буквы, было много пожеланий доработать её, чтобы она могла обрабатывать тексты целиком, а не отдельные предложения. Это коллективное пожелание и было осуществлено в нашей новой версии модели.

В целом, архитектура и датасеты остались прежними. Что изменилось:

обучение теперь производилось не на отдельных предложениях, а на нескольких последовательных предложениях (принимаем во внимание, что конструктивное ограничение модели при обучении — 512 токенов на вход, что позволяет свободно подавать ~150 слов на любом из четырех поддерживаемых языков)
для ускорения обучения модели сокращение словаря теперь проводилось не только на инференсе, но и на трейне, что позволило увелить размер батча

Размер модели и ее сжатие
Первая версия модели на момент релиза уже весила меньше 100 мегабайт. После этого мы выбросили еще 20 тысяч токенов (размер токена, напомним, 768) — токенов с большой буквой в начале, про которые мы забыли в тот раз, и которые модель, очевидно, не использует. Так модель еще немного ужалась до 85 мегабайт.
Как и раньше, основным секретом такого удобного размера выступает статическая и динамическая квантизация.
Что мы еще попробовали:

прунинг — с помощью кода из оригинального репо базовой модели действительно удалось проанализировать головы и подрезать лишние, но это, во-первых, резко ухудшило качество модели, во-вторых, из-за особенностей архитектуры модели, головы — не единственные тяжеловесные ее части, и выигрыш по размеру составил только 10 мегабайт, что вообще не имеет смысла при ухудшении метрик;

факторизацию — вывод примерно аналогичный, хоть выигрыш и составил здесь около 20 мегабайт, эмбеддинг стал работать сильно менее успешно и вероятно требовал очень длительного дообучения, что тоже выходило бы не вполне рационально.


В итоге от обеих перечисленных техник было разумнее отказаться.
Результаты
Напомним, что для этой задачи мы снимаем метрики на валидационных сабсетах наших приватных текстовых корпусов (5,000 предложений на каждый язык) и на текстах caito (20,000 случайных предложений на каждый язык). Более подробно про снятие метрик — в нашей статье про первую версию модели.
В этот раз для краткости приведем только WER (word error rate) в процентах, причем отдельно рассчитанный для пунктуации (и предсказание, и оригинал при этом приведены к строчному виду) — WER_p и для расставления заглавных букв (а здесь выбрасываем всю пунтуацию) — WER_c.
Мы посчитали метрики как для входных данных, представляющих из себя блоки из нескольких последовательных предложений, так и на отдельных предложениях, чтобы удостовериться, что новая версия модели действительно включает в себя функционал старой. 
В ячейках указан WER_p / WER_c, а наивный бейзлайн состоит в постановке заглавной буквы в начале текста и точки в конце.
WER — работа модели на блоках из нескольких предложений
Домен — валидационные данные:






Языки






en
de
ru
es


бейзлайн
14 / 19
13 / 41
17 / 20
10 / 16


модель
6 / 6
5 / 5
7 / 7
5 / 5



Домен — книги:






Языки






en
de
ru
es


бейзлайн
14 / 13
15 / 26
23 / 14
13 / 8


модель
12 / 7
11 / 8
18 / 10
12 / 6



WER — работа модели отдельных предложениях
Домен — валидационные данные:






Языки






en
de
ru
es


бейзлайн
12 / 18
10 / 33
13 / 12
8 / 11


модель
5 / 4
5 / 4
7 / 4
5 / 4



Домен — книги:






Языки






en
de
ru
es


бейзлайн
12 / 10
12 / 22
19 / 9
15 / 7


модель
12 / 6
10 / 6
17 / 7
13 / 5



Впрочем, еще работая с текстами caito в первый раз, мы заметили, что они далеки от идеала — нередко предложения будто обрезаны или перемешаны, внутри предложения вклинивается другое, начинающееся с большой буквы, но без точки до этого, — что, конечно, на блоках предложений становится еще более заметным. Вероятно, таковы издержки предобработки текстов книг. Тем не менее, решили уже не переходить на другие датасеты для удобства сравнения метрик — понятно, что полученные числа скорее коррелируют с реальным качеством работы модели на произвольных данных.
Примеры работы модели
Как и раньше, приведем непосредственные примеры работы модели — в этот раз поможем Агенту Смиту с пунктуацией и заглавными буквами на трех оставшихся языках:



Оригинал
Модель




Why, Mr. Anderson? Why, why, why? Why do you do it? Why get up? Why keep fighting? Do you believe you're fighting for something? For more than your survival? Can you tell me what it is? Do you even know? Is it freedom? Or truth? Perhaps peace? Could it be for love?
Why Mr. Anderson, Why why why why do you do it? Why get up? Why keep fighting? Do you believe youre fighting for something for more than your survival? Can you tell me what it is? Do you even know is it freedom or truth? Perhaps peace could it be for love?


--
--


Wieso Mr. Anderson? Wieso, wieso? Wieso tun sie das? Wieso? Warum aufstehen? Warum weiterk