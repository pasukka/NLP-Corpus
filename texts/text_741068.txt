

Как считать токены для GPT-3/GPT-4 / Habr


               Как считать токены для GPT-3/GPT-4  Reading time  
    2 min
   Views  4.6K C++ *Artificial Intelligence       Как считать токены для GPT-3/GPT-4 : GPT-TokenatorOpenAI предоставляет мощные инструменты для работы с GPT-3 и GPT-4. Однако возможность подсчёта токенов реализована только для JavaScript и Python, что не покрывает всех возможных вариантов использования. В связи с этим я разработал универсальную библиотеку GPT-Tokenator для подсчёта токенов на C++, экспортировал функцию подсчёта токенов в C, что даёт возможность использовать её во многих языках программирования.Необходимость подсчёта токенов возникает во множестве прикладных задач.Вот лишь несколько очевидных примеров:При анализе большого текста разбивать текст на части оптимальным образом, чтобы за один раз отправить на обработку максимально большой фрагмент текста.Оценивать превышение лимита токенов до отправки запроса к API.Оптимально передавать параметр max_tokens.Кажется, что подсчёт токенов настолько базовая функциональность, что выглядит очень странным, что OpenAI не предоставил средства для этого.Основные особенности и преимущества GPT-TokenatorGPT-Tokenator предлагает следующие ключевые особенности и преимущества:Поддержка C++ и экспорт в C для использования во многих языках программирования.Простые и легко используемые функции для подсчёта токенов.Примеры использования библиотеки на разных языках программирования.Отсутствие необходимости использовать словари преобразования. Всё необходимое встроено в саму библиотеку.Я специально не стал включать функции кодирования и декодирования токенов, чтобы сделать бинарный файл библиотеки настолько лёгким, насколько это возможно. По сути, в версии на C имеется только одна простая функция:size_t tokenator_count(const char* data, size_t len);Выбор C очевиден, потому что API C в том или ином виде поддерживается всеми языками программирования.Примеры использования GPT-TokenatorЯ подготовил несколько примеров использования GPT-Tokenator на разных языках программирования:C++CDGoC#Эти примеры помогут вам легко понять, как использовать библиотеку в ваших проектах. Также я надеюсь, они помогут понять, как подключать библиотеку к проектам на языках программирования, не перечисленных в списке выше.Если возникнут вопросы, не стесняйтесь писать мне. Постараюсь помочь.Буду очень признателен, если пришлёте PR с примерами кода на языках, не перечисленных в этом списке. Разумеется, можете рассчитывать на мою помощь. Интерфейс самой функции подсчёта токенов очень простой, и единственная сложность, которая может у вас возникнуть - это линковка.Обратите внимание, что во всех примерах D, Go, C# линковка осуществляется похожим образом.Установка и компиляция GPT-TokenatorДля установки и компиляции GPT-Tokenator выполните следующие шаги:Установите зависимости:sudo apt-get install libicu-devПерейдите в каталог с исходными кодами и выполните команду:cd src
makeКомпиляция может занять некоторое время, поэтому для вашего удобства я добавил сжатые предварительно скомпилированные файлы в каталог libs:libtokenator.alibtokenator_cpp.aФайлы заголовков находятся в каталоге include.GPT-Tokenator - это универсальная библиотека для подсчёта токенов в GPT-3 и GPT-4 на C/C++, которая может быть полезна для разработчиков, использующих разные языки программирования. Попробуйте GPT-Tokenator в своих проектах и не стесняйтесь отправлять отзывы, предложения по улучшению и сообщения об ошибках через GitHub.Readme на русскомИсходный код проекта GPT-Tokenator на GitHub      Tags: gptgpt-3gpt-4openaiии  Hubs: C++Artificial Intelligence          


