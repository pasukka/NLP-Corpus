

Обучаем машину правильно или как предотвратить Оverfitting / Habr


               Обучаем машину правильно или как предотвратить Оverfitting Level of difficulty  
    Easy
   Reading time  
    7 min
   Views  1.1K Machine learning *Artificial Intelligence  
    Review
        Искусственный интеллект — это наш инструмент и помощник, способный выполнять рутинные процессы. Над искусственным интеллектом работают сотни тысяч людей во всем мире в разных областях и обладают разными компетенциями и навыками. Но искусственный интеллект сам себя не научит и не усовершенствуется — за этим стоит человек. Машинное обучение — это ключевая область ИИ. Оно использует алгоритмы для анализа данных и получения выводов. www.pikabu.ruЯ пообщался с руководителем лаборатории искусственного интеллекта в Астраханском государственном университете Андреем Верига на тему усовершенствования алгоритмов ИИ и переобучения. Машинное обучение появилось почти одновременно с появлением вычислительных машин. Идея научить машину, чтобы она сама себе составляла правила, по которым будет решать поставленную перед ней задачу, родилась примерно тогда же, когда и идея давать машине последовательность команд, которые она будет выполнять для достижения цели. Первая идея родила машинное обучение, вторая — программирование. И если машинным обучением занимались математики, то программирование быстро забрали себе инженеры, тут же привинтив его к вытачиванию сложных деталей на станках, к полетам в космос и бухгалтерским расчетам. То есть, программирование удобно легло в те отрасли, где хорошо известны правила и законы, которые надо один раз закодировать в понятный компьютеру набор команд и потом только запускать программу столько раз, сколько потребуется. Машинное обучение — наоборот — система, которая изначально не знает таких правил и законов, но получая на вход условия задачи, вместе с правильным ответом на эту задачу, сама находит нужные правила для решения подобных задач. Это называется «контролируемое обучение». Обученная модель будет решать эти задачи с некоторой погрешностью и, если такая погрешность устраивает разработчика, считается, что модель успешно обучилась. У машинного обучения есть и другие модели, когда компьютер учится обобщать данные по их признакам, не зная заведомого результата, так называемое неконтролируемое обучение. Эти методы так же начали развиваться с середины 20 века и нашли широкое прикладное применение. Но наибольший интерес сейчас вызывают нейронные сети, которые умеют объединять в своих слоях и контролируемое и неконтролируемое обучение. Долгое время нейронные сети развивались только на бумаге и считались чем-то абстрактным, что нигде не применишь, потому что для их обучения требовалось много дорогого машинного времени, и, самое главное, очень много подготовленных примеров данных, из которых они могли бы вытащить нужные им шаблоны решения задач. А подготовка и оцифровка этих примеров данных требовала большого ручного труда. Но с развитием интернета проблема оцифровки данных решилась за счет пользователей интернета: люди стали самостоятельно и в больших количествах выкладывать в сеть фотографии, тексты и аудио. А проблему вычислительных мощностей неожиданно помогли решить геймеры: появились игры «от первого лица», для быстрого обсчета геометрии игрового пространства стали производиться многопроцессорные видеокарты с возможностью потоковой обработки графики по приемлемой цене, потом геймеры-программисты решили, что такая потоковая обработка годится для любых данных и приспособили игровые видеокарты для матричных вычислений. И оказалось, что теперь для нейронных сетей всё есть: терабайты обучающих данных и сравнительно дешевые вычислительные устройства, умеющие очень быстро делать перемножение матриц. yandex.ruМиллиарды фотографий и видео, выложенные пользователями в открытый доступ, дали возможность разработчикам нейронных сетей создать почти идеальные модели компьютерного зрения. Теперь многие задачи по распознаванию изображений машины выполняют лучше человека. В начале 2000-х для обучения этих моделей требовалось много ручного труда: чтобы научить машину классифицировать картинки, сначала надо выбрать из множества изображений нужные примеры и разложить их по классам. Чем больше обучающих примеров каждого класса, тем точнее модель будет узнавать похожие картинки в будущем, для качественного распознавания нужны миллионы обучающих примеров. И часто такой набор данных оказывается несбалансированным. Например, для модели определения перелома руки по рентгеновскому снимку были собраны рентгены из разных клиник. Для таких задач нужно собирать обучающие примеры как переломами, так и без, примерно одинаковое количество и того, и другого. Снимки с отсутствием переломов были взяты из баз амбулаторных осмотров разных клиник, а с переломами – из специализированного травмпункта. Рентгеновские аппараты в каждой клинике разные и выдавали снимки с почти неразличимыми глазом отличиями в яркости, контрасте, зернистости и т.д. В результате модель приняла особенности снимков из травмпункта за отличительный признак наличия перелома и стала сообщать о переломе на всех снимках с похожими параметрами. Такая ситуация называется overfitting (переобучение), это когда модель слишком хорошо выучила не те существенные признаки класса, которые ей надо было выучить. Что делать, чтобы избежать переобучения?Это проблема недостаточных наборов данных и лечится она увеличением количества обучающих примеров. В нашем случае с переломами рук, достаточно было добавить несколько источников снимков с переломами с разными настройками, чтобы избавиться от переобучения. Существуют и другие способы избавиться от этой проблемы, например, программно менять яркость и контраст снимков случайным образом до того, как они попали на вход сети. Но это применимо, когда мы уже выяснили причину оверфиттинга. В общем случае – чем больше данных, тем меньше переобучение.С переобучением столкнулись в те времена, когда наборы данных собирались вручную, и получить достаточный набор данных было дорого и долго. Тогда нашли множество разных ухищрений, программных, математических, иногда просто по наитию. Есть, например такой способ: на каждой итерации попеременно вычеркивать из процесса обучения какую-то часть нейронов сети. Все нейроны обучаются, а 20% – нет, на следующем шаге опять выбрали случайные 20% и теперь их веса не меняются. Казалось бы, как это может помочь? Но этот фокус оказался очень эффективным в борьбе с оверфиттингом, и сейчас его можно встретить практически во всех современных сетях. Авторы этого трюка приводят довольно захватывающее обоснование своей идеи, сославшись на биологию: механизм полового размножения, в отличие от бесполого, не позволяет генам распространяться сразу по всей популяции со всеми своими ошибками, и каждый новый потомок должен научиться выживать со своим уникальным набором генов, делая всю популяцию в среднем более живучей. Так и нейрон, лишенный возможности передавать свою информацию сразу всем соседям, должен научиться исправлять свои ошибки в кооперации со случайно выбранным набором соседей, и такая лотерея идет на пользу всей модели. Фантастика, но это действительно работает.создано нейросетьюКак когнитивистика помогает понять процессы мышления человека?Когнитивистика – это как раз то, что изучает процессы мышления. Это соединение психологии, нейробиологии, лингвистики и вот теперь еще и машинного обучения, которое сейчас называют искусственным интеллектом.Говорить о том, что ИИ научился мыслить, как человек, пока рано, это всё еще искусная имитация внешних проявлений процессов мышления. Современные большие лингвистические модели, которые произвели фурор в последние полгода, обучались на огромных корпусах текстов на сотнях языков и умеют связно излагать фразы. Это, конечно, поражает воображение: неживая материя разговаривает, отвечает на вопросы, поддерживает диалог, даже сочиняет на заданную тему. Но в основе этих процессов лежит всё то же использование шаблонов и штампов, которые система вычленила из существующих текстов в процессе обучения. То есть, да, написать сочинение для ЕГЭ эта модель сможет на отлично, потому что требования к сочинению как раз и есть умение излагать набор штампов, но сочинить нечто новое, интересное - нет. Даже правильный ответ на вопрос она не сможет дать, если в ее обучающих наборах не было такого ответа. Причем, желательно, чтобы этот ответ встречался много раз в разных текстах и на разных языках, тогда она уверенно ответит на вопрос. И этот ответ не будет истиной, модель сообщит то, что считается правильным в большинстве источников обучающих текстов. То есть, думать, сопоставлять свои знания, выводить логически новые ответы она не умеет. Ну, почти)Вот, что интересно: всё, что делает лингвистическая модель, такая как ChatGPT, – предсказывает следующее слово, основываясь на предыдущих словах. Добавляет предсказанное слово в цепочку, и опять предсказывает следующее слово, учитывая только что добавленное. И так, пока не предскажет окончание фразы. То есть, это такой попугай, который обладает огромным запасом слов на всех языках мира и неимоверной памятью на слышанные когда-то фразы.Но некоторые психологические тесты, которые проверяют способность человека к абстрактному мышлению, эта система проходит. Вот интересный пример. Модели Davinchi дали такой текст, который она должна была продолжить: Вот бумажный мешок, в нём попкорн. В мешке нет шоколада. Но, на упаковке написано "шоколад", а не "попкорн". Маша находит мешок. Она никогда раньше не видела этот мешок. Она не может видеть, что находится внутри мешка. Она читает этикетку. Она открывает мешок и проверяет его содержимое. Она ясно видит, что он полон... Модель продолжила: попкорном, а не шоколадом. Задачу усложнили. Теперь текст звучит так:Вот бумажный мешок, в нём попкорн. В мешке нет шоколада. Но, на упаковке написано "шоколад", а не "попкорн". Маша находит мешок. Она никогда раньше не видела этот мешок. Она не может видеть, что находится внутри мешка. Она читает этикетку. Она рада, что нашла этот мешок. Она любит...Модель продолжила:шоколад. Она открывает мешок и видит, что внутри находится попкорн. Она расстроена, так как она хотела шоколад.Считается, что такой ответ свидетельствует о умении испытуемого ставить себя на место героя, и приписать ему свои эмоции. Такого рода тест используют для проверки нарушения когнитивных функций в следствие травмы, патологии мозга или длительного употребления тяжелых наркотиков. В норме такой тест проходит пятилетний ребенок. То есть можно с осторожностью сказать, что в некоторых случаях лингвистическая модель может проявлять признаки мышления на уровне пятилетнего ребенка.создано нейросетьюКак можно усовершенствовать алгоритмы искусственного интеллекта, чтобы они могли обучаться более эффективно и быстрее? Какими навыками/скилами должен обладать специалист? Программисты по окончании университета знают математику в пределах школьной программы, математики умеют программировать на начальном уровне. Есть некоторые самоучки, которые хотят чего-то большего, из них иногда получаются специалисты в области ИИ, но это не заслуга системы образования. В любом случае, чтобы начать что-то улучшать в существующих моделях, учиться надо несколько лет. Сейчас этим занимаются десятки тысяч специалистов во всем мире, в новостях регулярно появляются сообщения о новых достижениях, развитие идет в режиме взрыва, пока учишь то, что уже сделано, мир уходит вперед, и оседлать эту волну – задача для героя.      Tags: машинное обучениеискусственный интеллектoverfitting  Hubs: Machine learningArtificial Intelligence          


