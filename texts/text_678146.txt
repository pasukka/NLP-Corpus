

По ту сторону генерации текста: языковые модели, которые действуют, а не просто говорят / Habr


              21  July   at 23:08  По ту сторону генерации текста: языковые модели, которые действуют, а не просто говорят SkillFactory corporate blog Artificial Intelligence Natural Language Processing * 
        Translation
         
                Original author:
                
                  Iulia Turc
                  Minerva от Google обещает будущее, в котором машины смогут действоватьIulia TurcИнженер-программист, исследователь обработки естественного языка в Google ResearchБольшие языковые модели, например GPT-3, в основном использовались для генерации текста, но язык — лишь средство достижения цели. В ближайшие годы модели станут не просто говорить, а действовать. Подробности — к старту нашего флагманского курса по Data Science.Изображение создано генеративным ИИ MidJourneyБольшие языковые модели (далее — LLM), например GPT-3, в основном использовались для генерации текста. В конце концов, их учили прогнозировать продолжение текста по его фрагменту. При этом за последние два года резко выросло число стартапов, использующих LLM в творческих отраслях: в рекламе и контент-маркетинге (copy.ai, frase.io), в написании художественных текстов, в создании игр (latitude.io). Эти отрасли — благоприятная среда для развития генеративного ИИ до того, как он появится в мире коммерции. Вот почему:Хлеб этих отраслей — текст в произвольной форме, то есть именно то, что GPT-3 выдаёт «из коробки». Разработчики просто вызывают API вывода OpenAI, они практически ничего не знают о работе модели изнутри.Творческий характер этих индустрий позволяет им закрывать глаза на «галлюцинации» — известное ограничение современных моделей, из-за которого генерируется правдоподобный, но ошибочный текст.LLM умеют генерировать текст, но это не всё, для чего они будут применяться. Для людей естественный язык, — это средство достижения цели, а не конечная цель, за исключением, наверное, поэзии. А значит, ИИ, способный понимать и генерировать текст, — это канал связи с машиной посредством естественного языка. Этот канал давно развивается, используются всё более абстрактные строительные блоки: от перфокарт и языков низкого уровня, например ассемблера, до языков уровня выше (Python)  и естественного языка, то есть языка высшего уровня. Теперь, когда этот канал взаимодействия почти построен, внимание переключается на обучение ИИ действиям.Шаг первый: рассуждениеПромежуточный этап между говорением и действием — рассуждение. Интенсивные дебаты о способности LLM к рассуждению велись в последние два года. Известные исследователи утверждали, что LLM — стохастические попугаи, изучающие распределения вероятностей по языковым токенам и, таким образом, выдающие некоторые вариации обучающих данных без способности к настоящим рассуждениям. Другая исследовательская школа утверждает, что LLM способны к некоторым рассуждениям, поскольку соблюдают логические правила, например причинно-следственную связь. При запросе «Поскольку игрок сильно ударил по мячу» GPT-3 генерирует «мяч ушёл очень далеко». Это продолжение соответствует нашим представлениям о причинно-следственных связях в физическом мире.С появлением новой модели Google Minerva (30 июня 2022 года) аргумент стохастических попугаев теряет силу. Minerva убедительно демонстрирует пошаговые количественные рассуждения: при представлении вопроса из области STEM (связанного с наукой, технологиями, инженерией или математикой) модель может дать ответ и объяснить, как он был получен:Вопрос по алгебре и образец ответа в Minerva Sample ExplorerХотя вопросы из области STEM требуют понимания естественного языка, они подразумевают символические и числовые манипуляции, а особенно сложный тип токена — это числа: Их буквально бесконечное количество — в тренировочный набор можно добавить большинство пород собак, но уж точно не большинство чисел.Они, как правило, встречаются в меньшем количестве сочетаний, чем обычные слова; например, документов, содержащих одновременно «собаку» и «кошку», гораздо больше, чем документов, содержащих одновременно «520» и «17» или любую другую произвольную пару чисел.Вот почему аргумент «стохастических попугаев» правдоподобно звучит в оценке утверждения от GPT-3, например «собака погналась за кошкой». Модель просто воспроизводит изученное типичное взаимодействие двух животных. Но, когда Минерва утверждает, что «520/30 будет 17r10», тот же аргумент выглядит не так убедительно.Ещё один стоящий внимания аспект: при предоставлении доказательства или обосновании числового ответа Minerva выполняет многоэтапное рассуждение. Кроме окончательного ответа, она даёт упорядоченную последовательность шагов к нему. В отличие от заучивания ответа или выбора в качестве ответа маркера высокой вероятности, это — явный признак количественного мышления. Тот же принцип используется при оценивании учеников: если они могут объяснить результат, то, наверное, не списывали.Многоэтапное рассуждение в типовом ответе, из Minerva Sample ExplorerСтоит отметить, что Minerva не использует никаких внешних инструментов, например калькулятор или интерпретатор Python. Все количественные рассуждения закодированы в её весах. А в предыдущей работе[2] LLM использовались для простого преобразования естественных высказываний в формальный язык — код, который затем выполняется на традиционной машине, а результат из калькулятора, наконец, интегрировался в вывод модели на естественном языке.Minerva имеет свои ограничения (некоторые ответы неверны, другие —  ложноотрицательны, то есть правильный вывод она делает из неверных предположений; тем не менее, в сравнении с генерирующими текст моделями она делает огромный шаг вперед. Количественные рассуждения в LLM открывает двери многим приложениям, включая образование. При соответствии опредёленной планке качества учащиеся могут нанять личного ИИ-репетитора, который поможет им решить проблемы из области STEM (… или списать домашнюю работу). Эту технологию можно использовать и в автоматизированных системах оценки.По ту сторону генерации текста, шаг № 2: действиеКак только мы создадим разумные машины, понимающие, чего мы хотим, следующий шаг — дать им возможность действовать. Не то чтобы это совершенно новая задача — в конце концов, голосовые ассистенты включают и выключают свет, но изменяется реализация: традиционные конвейеры из нескольких компонентов NLP заменяют всё более функциональными LLM. Этот переход откроет больше вариантов применения и сделает общение человека и компьютера ещё комфортнее.Традиционная конвейерная архитектура от MindMeld, диалоговой платформы искусственного интеллекта, созданной в 2011 году и приобретённой Cisco в 2017 годуКак показано выше, традиционные платформы диалогового ИИ, такие как MindMeld, связывают несколько компонентов NLP: классификатор предметной области, за которым следует классификатор намерений, за которым — другие компоненты, и так далее вплоть до окончательного  анализатора языка. Последний, как я предполагаю, переводит ввод пользователя в код, который выполняется машиной. Но в свете недавних исследований становится всё более вероятным, что такие компоненты будут скрыто, без участия инженеров изучаться самими LLM и кодироваться в их весах. В конце концов, Minerva от Google уже содержит нечто вроде калькулятора.Исследователи уже довольно давно изучают LLM в контексте семантического анализа — преобразования естественного языка в формальный. Во многих публикациях целевой формальный язык — SQL (язык структурированных запросов), который облегчает взаимодействие с базами данных. В то время как LLM довольно хорошо учатся преобразовывать естественный язык в запросы для конкретной схемы базы данных, встречающейся во время обучения, обобщение остается проблемой[3]. Другими словами, модель, обученная взаимодействию с базой данных American Airlines, может не работать с базой данных Delta. Точно так же модель, обученная включать и выключать свет, может не знать, как включать и выключать музыку, если API-интерфейсы источников света и умных колонок различаются. Это представляет значительные трудности при масштабировании технологий для других вариантов применения: для каждого из них требуются свои обучающие данные.Логично задать вопрос: как можно ожидать, что LLM будут понимать незнакомый им формальный язык (например, API колонок)? Есть надежда, что эту проблему можно решить, поскольку ранее мы были приятно удивлены впечатляющими возможностями  многоязычных моделей, обученных без попыток. Фактически, несколько недавних стартапов взялись решить эту проблему. В апреле 2022 года группа бывших сотрудников Google (включая Васвани, первого автора Transformer) анонсировала AdeptAI — новый стартап, который направлен на то, чтобы позволить ИИ действовать в ответ на команды на естественном языке:Настоящий искусственный интеллект подразумевает существование моделей, которые могут не только читать и писать, но и действовать так, чтобы это было полезно для пользователей. Вот почему мы запускаем Adept: мы обучаем нейронную сеть использовать все программные инструменты и API в мире, опираясь на огромное количество существующих возможностей. Отрывок вступительного поста в блоге AdeptВ мае 2022 года компания InflectionAI привлекла 225 миллионов долларов, чтобы выполнить свою миссию по предоставлению людям возможности общаться с машинами на естественном языке:Недавние достижения в области искусственного интеллекта обещают фундаментально переосмыслить взаимодействие человека и машины. Вскоре мы сможем передавать мысли и идеи компьютерам разговорным языком, на котором общаемся с людьми. Эти возможности произведут революцию в цифровом опыте человека.InflectionAIЗаключениеГенерация текста с помощью больших языковых моделей, таких как GPT-3, привлекла наше внимание из-за их жутковатой способности подражать человеческой речи. Хотя это может заставить нас думать, что генеративные технологии достигли потолка, язык — это просто средство для достижения цели. Следующая задача — продвигаться дальше в говорении учить машины, как действовать. Minerva от Google уже научилась выполнять символьные манипуляции и вычисления, и всё больше усилий направлено на то, чтобы научить LLM подавать команды в базовые среды выполнения.Изображение создано генеративным ИИ MidJourneyЛитература[1] Lewkowycz et al., 2022: Solving Quantitative Reasoning Problems with Language Models[2] Andor et al., 2019: Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension[3] Suhr et al., 2020: Exploring Unexplored Generalization Challenges for Cross-Database Semantic ParsingА пока ИИ продолжает развиваться, мы поможем прокачать ваши навыки или с самого начала освоить профессию, актуальную в любое время:Профессия Data ScientistПрофессия Fullstack-разработчик на PythonВыбрать другую востребованную профессию.     Tags: skillfactoryииискусственный интеллектробототехникароботымоделидействиястохастические процессыпопугаиинтеллект Hubs: SkillFactory corporate blogArtificial IntelligenceNatural Language Processing          


