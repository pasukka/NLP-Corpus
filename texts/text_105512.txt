

Эффект коартикуляции речи и его преодоление при распознавании. Пособие для нейроспецназа / Habr


               4  October  2010 at 18:37  Эффект коартикуляции речи и его преодоление при распознавании. Пособие для нейроспецназа Artificial Intelligence  
        Sandbox
           Что такое коартикуляция

Жуткий зверь по имени «аллофон»


Произнося слова и составляющие их звуки, мы никогда не задумываемся о том, что физически они из себя представляют. Сколько из говорящих на разных языках разумных земных существ пытались записать свою речь и исследовать её на графиках, спектрограммах? Понять и изучить её особенности, выделить закономерности и вообще, узнать о речи больше? Думаю, совсем немногие — в процентном отношении.


Мы просто пользуемся! Причём пользуемся неосознанно.


Мы интуитивно делим речь на звуки, которые записываем буквами, и нам кажется, что звук «а» — это всегда «а», а в слово «мама» есть два абсолютно одинаковых звука «а».


А вот и нет!!! Проведите эксперимент: запишите слово «мама», а потом, с помощью средств обработки аудиозаписи поменяйте слоги местами... То, что получится, словом «мама» назвать вельми трудно. Я долго вслушивался в запись, пытался подобрать речевой эквивалент, но это трудно. Ближе всего на мой вкус наверное «мо-ха»


То есть вообще получилось слово из другого языка! Неведомого и неизобретённого…


Именно поэтому речь трудно синтезировать, и компьютеры при загрузке нас ещё не приветствуют словами на чистейшем русском языке: «Доброго Вам утра, Хозяин!»…


Ну так вот. То, что мы называем звуками, большелобые профессора лингвистики называют «фонемами». Понятное дело, звук может быть разным — от скрипа двери до мяуканья кошки, а надо как-то называть звуки речи Хомо Разумного (хотя насчёт разумности хомо сапиенс у меня всегда были некоторые сомнения… )


Ну так вот, фонемы, как уже было показано на примере слова «мама», могут значительно отличаться друг от друга, и на спектрограмме выглядеть, мягко говоря, по разному.


И вот тут нам пригодится хитрый зверь под названием «аллофон».


Аллофон — это и есть конкретная фонема в данном месте. То есть, возвращаясь к слову «мама», второй и четвёртый звук здесь будет — одна и та же фонема «а», но аллофоны разные. Второй звук — это фонема «а» под ударением в окружении фонем «м». Четвёртый звук — это безударная «а» после фонемы «м» и перед концом слова (короткой паузой, тишиной).


То есть аллофон — это реализация фонемы в конкретном звуковом окружении.

Так что же всё таки коартикуляция?


Так вот, причина, почему фонема в разных местах слова не похожа сама на себя, проста и банальна.


У звуков нет чётких границ, и нельзя определить — вот здесь кончается фонема «а», а здесь начинается фонема «м».


Фонемы речи переходят друг в друга плавно, при этом звуковое окружение сильно искажает форму фонемы.


Например, на спектрограмму второго звука «а» в слове «мама» серьёзно влияют две буквы «м» по соседству, и она отличается от четвёртой фонемы «а», у которой с одной стороны «м», а с другой — ничего.


Рис. 1. Спектрограмма слова мама с разбивкой на звуки


На рисунке видно, что спектрограммы одной и той же фонемы значительно отличаются.


Как уже говорилось, фонема, покорёженная жизнью изменённая данным звуковым окружением, называется аллофоном.

Большой босс — основной аллофон


Среди всего разнообразия аллофонов для одной фонемы один из вариантов берётся за эталон. Этот эталон называется «основным аллофоном».


Для гласных таким эталоном является изолированное произнесение.


Для согласных — перед ударным «а».

И как ЭТО распознавать?


А теперь ставим задачу: автоматически (то есть без участия человека) распознать некоторое слово, причём сделать это пофонемно.


Только как мы будем делать это, если аллофоны одной фонемы отличаются друг от друга?


Стандартный метод следующий:

вместо фонем берутся пары и тройки фонем, называемые «дифонами» (пара фонем) и «трифонами» (тройка фонем).


Трифоны лучше, поэтому их использование предпочтительнее.


При этом разбивка на трифоны идёт с наложением, так, чтобы каждая фонема была в центре трифона хотя бы один раз.


Например, уже указанное слово «МАМА» на трифоны разобьётся следующим образом:


sil М A

М А М

А М А

М А sil


Здесь sil означает начало или конец слова (от "silence" — тишина).


Иногда встречается следущая запись: М(sil, А). Обозначает она трифон, в центре которого «М», в начале — тишина (sil), а в конце — «А».

Так в чём проблема?


Проблем нет никаких. Только замечание: этот «дизайн» борьбы с коартикуляцией разрабатывался для Скрытых Моделей Маркова и вводился «не от хорошей жизни».


Мы же постараемся использовать более продвинутые технологии распознавания речи — нейронные сети.


А для нейронных сетей данный «дизайн» подходит хуже, так как у нейронных сетей есть «проклятье размерности».


Нейронная сеть учится на примерах, поэтому чем больше размерность данных, тем больше примеров надо для обучения. При этом возрастает число примеров очень быстро, намного быстрее, чем размерность :)


Ну так вот, фонем существуют десятки, аллофонов — сотни, а трифонов — только основных около 6000.


Нейронная сеть это выучить теоретически может, только трудно это и база обучающих данных должна быть велика, и время на обучение будет огромным.


Можно ли это как нибудь обойти?


Я предлагаю следующий метод:


Ввести некоторую функцию, которая будет мерять схожесть данного звука основному аллофону.

Тогда ИНС может находить только степень подобия поданного на вход участка основному аллофону. И число выходов ИНС будет равнятся не числу возможных сочетаний аллофонов, а просто числу фонем.


Это позволит разделить распознавание слова на небольшое количество фонем (на каждую, если надо, можно выделить по одной нейросети).


Такой подход так же позволяет сделать высококлассный контекстный анализ (для тех, кто не в курсе — это анализ на основе частоты тех или иных комбинаций фонем в языке, позволяет исправлять ошибки распознавания).


Итак, от рекламы — к объяснениям. Как это выглядит? На практике? Посмотрите на следующий рисунок.


Рис. 2. Функции подобия для фонем Б, А, К на примере фонограммы слова бак


Как уже говорилось, фонемы взаимопроникают друг в друга, влияют. И это влияние убывает к центру фонемы и возрастает ближе к её условным краям. Таким образом, центр любого аллофона почти полностью совпадает с основным аллофоном (и центрами всех других аллофонов), в тоже время, благодаря влиянию соседних звуков, степень подобия основному аллофону падает ближе к зонам стыков фонем. Что прекрасно видно на приведённом выше рисунке.


Теперь осталось дело за малым: разбить эту функцию на произвольное число отсчётов (рекомендую от 1 до 32) и «скормить» нейронной сети.


При этом совсем не обязательно делать хитрый алгоритм сравнения звуков с эталонными «основными аллофонами», достаточно нарисовать «на коленке» произвольную функцию, единичную в центре нужного аллофона, убывающую к его краям и нулевую для всех остальных фонем и звуков.

P.S.


Критика не только ожидается, но и приветствуется.

Особенно буду благодарен за замечания:


1. По логике изложения и её улучшению

2. По существу :)


Большое деятельное спасибо — если что-то подобное или близкое найдёте в литературе — но только за ссылку (не обязательно электронную) :)    Tags: распознавание речираспознавание изображенийнейронные сетикоартикуляцияаллофонСММспектрограмма Hubs: Artificial Intelligence          


