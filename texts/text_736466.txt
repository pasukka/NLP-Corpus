

Нейросеть, что это такое и как создать свою? Детальная инструкция / Habr


               Нейросеть, что это такое и как создать свою? Детальная инструкция  Reading time  
    21 min
   Views  29K Algorithms *Mathematics *Machine learning *Artificial Intelligence  
    Tutorial
        Что такое нейросеть? В базовом понимании, нейросеть – это совокупность связанных нейронных блоков, выполняющих обработку информации. ОбучениеДо 1-го года:Deep Learning.Профессия Machine Learning Engineer.Machine Learning с нуля до Junior.Курс по нейронным сетям.Курс по машинному обучению.Курс Machine Learning и Deep Learning.Математика и Machine Learning для Data Science.Свыше 1-го года:Онлайн-бакалавриат: Data Science & Machine Learning: Российская академия народного хозяйства и государственной службы при Президенте РФ занимает 9-е место в российском рейтинге Forbes и 2-е место в рейтинге самых влиятельных вузов страны, по версии рейтингового агентства RAEX.Московский Физико-Технический Институт (МФТИ): Один из ведущих российских университетов в области естественных наук и технологий. У них есть несколько курсов по нейросетям и искусственному интеллекту.Санкт-Петербургский государственный университет (СПбГУ): Они также предлагают различные курсы по машинному обучению и нейросетям.Высшая Школа Экономики (ВШЭ): Их факультет компьютерных наук предлагает несколько программ, связанных с искусственным интеллектом и машинным обучением.Университет Иннополис: Иннополис – это технологический университет в России, который также предлагает программы по искусственному интеллекту.I. Основы нейросетейВ поисковых системах ежедневно растет количество запросов, что такое нейросеть (далее — НС). Прежде всего это связано с растущим интересом к технологиям на базе искусственного интеллекта (далее — ИИ). Многие из нас даже не подозревают, что мы практически ежедневно используем модели глубокого обучения. Запросы Siri или взаимодействие с чат-ботами в мессенджерах — один из ярких примеров использования НС. Мало кто из нас знает, что нейронки существуют уже 80 лет. Первая НС была представлена в 1943 году Уорреном Маккалоу и Уолтером Питтсом. В ее основе лежала пороговая логика для построения вычислительных моделей. Но с годами подходы к реализации нейронных сетей изменились, как и технологии, которые используются для их разработки. Углубимся в основы НС и разберемся с ключевыми вопросами. Сегодня это неотъемлемая часть искусственного интеллекта (далее — ИИ) и в области глубокого обучения. В фундаментальном виде НС обладают нелинейными свойствами, которые могут быть применены как для контролируемого, так и для неконтролируемого обучения. Более того, нейронные сети можно рассматривать как совокупность алгоритмов, основанных на функционировании человеческого мозга и предназначенных для выявления закономерностей.Таким образом, нейронки базируются на алгоритмах глубокого обучения и сегодня они широко используются в решении многих задач: от классификации данных, обработки изображений до распознавания речи. Сегодня существует большое разнообразие НЧ, включая сверточные и рекуррентные структуры. При этом, их разработка представляет собой достаточно сложный процесс, но благодаря прогрессу технологий и наличию готовых фреймворков, создание и использование таких моделей стало более доступным даже для обычных пользователей.A. Основные типы нейросетейСуществует множество типов нейронок, которые классифицируются в зависимости от структуры, потока данных, используемых нейронов и их плотности, слоев и их фильтров активации глубины и прочее. ПерцептронПерсептрон — это алгоритм обучения с учителем, который классифицирует данные по двум категориям, поэтому он является бинарным классификатором. Концепция персептрона была впервые введена Фрэнком Розенблаттом в 1957 году. В основе лежит искусственный нейрон с регулируемыми весами и порогом. Персептрон разделяет входное пространство на две категории с помощью гиперплоскости, представленной следующим уравнением:Персептроны могут реализовывать логические элементы, такие как И, ИЛИ или НЕ-И. Но их проблема в том, что они могут изучать только линейно разделимые задачи, такие как логическая задача И. А для нелинейных задач, таких как логическое XOR, это не работает.Сверточные нейросети (CNN)Эта концепция содержит трехмерное расположение нейронов вместо стандартного двумерного массива. Первый слой называется свёрточным. Каждый нейрон в сверточном слое обрабатывает информацию только из небольшой части поля. Входные функции берутся в пакетном режиме как фильтр. Архитектура искусственных НС, предложенная Яном Лекуном в 1988 году используется для эффективного распознавания образов. В этом случае сеть понимает образ частично и может выполнять операции несколько раз, чтобы завершить полную обработку. Эта модель НС используется для разработки следующих типов приложений: обработка изображений;компьютерное зрение;распознавание речи;машинный перевод.Например, в программах обработки происходит преобразование изображения из шкалы RGB или HSI в шкалу серого. Дальнейшие изменения значения пикселя помогут обнаружить края, и изображения можно будет классифицировать по разным категориям. Эта модель используется для глубокого обучения с несколькими параметрами, которых меньше, чем в случае с полносвязным слоем. Но есть пару недостатков этого типа НС, которые связаны со сложностью проектирования и обслуживания, а также с невысокой скоростью обработки.Рекуррентные нейросети (RNN)Стоит обратить внимание на еще одну достаточно распространенную архитектуру, которая нашла свое применение в обработке естественного языка (NLP). Принцип работы рекуррентной нейросети основан на оценивании произвольных предложений на основании того, как часто они встречались в текстах. Такой подход дает представление о грамматической и семантической корректности. Данная модель используется в машинном переводе и для генерации новых текстов. То есть, обучаясь, например, на произведениях Ремарка, нейронка сможет генерировать новый текст, похожий на Ремарка. Исходя из этого, мы пониманием, что в этой архитектуре используются прошлые выходные данные в качестве входных, имея при этом скрытые состояния. Recurrent Neural Networks используются для решения целого ряда задач: Обработка текста, например, проверка грамматики.Преобразование текста в речь.Анализ настроений.Преимущества такой архитектуры в модели последовательных данных, в которой можно предположить, что каждая выборка зависит от исторических данных. Но обучать такую НС крайне сложно. Генеративно-состязательные нейросети (GAN)А это уже подход к генеративному моделированию, который генерирует новый набор данных на основе данных для обучения. У GAN есть 2 основных блока — генератор и дискриминатор, которые конкурируют друг с другом и могут захватывать, копировать и анализировать вариации в наборе данных. Чтобы лучше понять, что собой представляет GAN, стоит разбить этот термин на три отдельные части:Генеративная — для изучения генеративной модели, которая описывает, как генерируются данные с точки зрения вероятностной модели. Простыми словами, в этой части объясняется, как данные генерируются визуально.Состязательная — обучение модели проводится в состязательной обстановке.Сеть — для обучения используются глубокие нейронные сети.B. Принципы работы нейросетейАлгоритм работы НС следующий: 1. На входной слой поступают данные.2. Синапсы передают данные на следующий слой. Каждому синапсу присвоен определенный коэффициент веса и у каждого последующего нейрона может быть несколько входных синапсов.3. Данные, которые передаются следующему нейрону — это сумма всех данных в нейронке, умноженных на соответствующие коэффициенты веса.4. Полученные значения подставляются в функцию активации, что приводит к формированию выходных данных. 5. Передача данных будет продолжаться, пока она не достигнет конечного выхода.Известно, что при первом запуске нейронной сети результаты могут быть неточными, так как сеть еще не обучена. Для обучения нейронки и последующей обработки данных потребуются тренировочные сеты.Процесс обученияОдной из особенностей нейронок является способность к обучению и совершенствованию. Для этого используется среднеквадратичная ошибка потерь. Небольшое напоминание, что такое потеря: это когда вы находите способ количественно оценить усилия НС и пытаетесь ее улучшить. В приведенной выше формуле:N - количество входовY - переменная, используемая для прогнозаY_true — истинное значение переменной-предиктора.Y_pred — прогнозируемое значение переменной или выходных данных.Здесь (y_true - y_pred)^2 — квадрат ошибки. Общий квадрат ошибки можно получить с помощью функции потерь. Стоит рассматривать потери как функцию веса и чем лучше прогноз, тем меньше потери. Таким образом, цель состоит в обучении сети для минимизации потерь. Теперь у вас есть возможность изменить веса сети, чтобы повлиять на прогнозы. Отметьте каждый вес в сети, а затем запишите потери как многомерную функцию.В свою очередь, стохастический градиентный спуск показывает, как изменить веса, чтобы минимизировать потери. Это представлено в виде уравнения: