

Как мы генерили генератор скриптов / Habr


               Как мы генерили генератор скриптов  Reading time  
    5 min
   Views  1.5K VS Robotics corporate blog Artificial Intelligence   
    Technotext 2022
       Привет, Хабр! На связи VS Robotics. Мы по–прежнему занимаемся машинным обучением и автоматизацией решений на базе речевых технологий. И мы по-прежнему верим в светлое будущее в то, что в скором времени роботизированные системы будут внедрены повсеместно, помогая человеку в любой сфере. Сегодня один из трендов по делегированию задач искусственному интеллекту – это… сам процесс программирования. Но мы имеем ввиду не те инструменты, коих множество в любой среде разработки, а те, что создаются компаниями под собственные нужды. И это поистине одна из самых увлекательных головоломок, предоставляющая айтишнику возможность наконец-то проявить свою творческую сущность.  Так уж сложилось в нашей компании, что мы не раз создавали собственные автоматизированные системы и программное обеспечение для своих продуктов и сервисов.А совсем недавно мы запустили собственный AI-генератор скриптов, ну, и решили рассказать вам об этом инструменте, который сокращает ручной труд при создании скриптов для голосовых роботов.  Это будет большая статья, как и та работа, которую мы проделали.Для чего нам потребовался АI-генератор скриптов    Наш голосовой робот умеет синтезировать или воспроизводить записанную речь, трансформировать человеческую речь в текст или сущности, выполнять логические операции, фиксировать значения данных и «общается» с другим системами. Но так или иначе, вся работа робота описывается скриптом, то есть определенным сценарием действий. Ниже на рисунке 1 мы изобразили, как выглядит часть скрипта робота. Слева пример алгоритма работы робота в виде блок-схемы (пошаговой инструкции), а справа сценарий в виде кода.рис. 1Создание блок-схемы и написание ее в виде кода - это монотонная и кропотливая работа, которая проводилась вручную несколькими специалистами. Происходил этот процесс следующим образом: сначала методолог должен был прослушать сотни аудиозаписей и выписать типовые фразы, ответы, возражения и реакции абонентов. После чего методолог вручную формировал схему основных узлов скрипта робота в виде блок-схемы в стороннем приложении. А вот на этом этапе к работе уже подключался другой специалист - скриптолог. Он «переводил» созданный методологом скрипт на язык робота.  рис. 2Сами понимаете, что процесс этот был не быстрый и мог длиться от нескольких дней до месяца. Очевидно, что такую работу можно и нужно автоматизировать, что мы и сделали. Эту задачу мы для себя сформулировали так: сократить время создания скрипта для робота за счет автоматизации создания графа диалогов на основе базы аудиозаписей реальных разговоров между оператором и абонентом. Нам предстояло исключить стороннее приложение из процесса подготовки алгоритма, но при этом получить заготовку в виде скрипта, написанного на языке робота.Общая схема работы AI-генератора   Самый простой шаг - получение расшифровки диалогов. Для эго мы используем собственный сервис речевой аналитики, который транскрибирует устную речь в текст.  Дальнейшие шаги потребовали от нас креативного подхода.Итак, основную задачу, которую решает AI-генератор можно сформулировать так: поиск структуры диалога как последовательности определенных состояний (или этапов) в речи инициатора этого диалога, в нашем случае – оператора.Транскрипции проходят 6 этапов прежде чем превратиться в скрипт и отправиться на финальную доработку в визуальный редактор (другой продукт компании).Архитектуру решения схематично можно представить так.рис. 3MVP AI-генератора скриптов оформлен как Python веб-приложение, упакованное в контейнер, который развернут в kubernetes. Теперь подробнее расскажем, что происходит на каждом шаге.Этапы 1-2: составление лога и очистка фраз  На первом шаге мы объединяем все тексты диалогов в формате «оператор» - «абонент» в одну большую таблицу – общий лог. Каждому диалогу присваивается id, а реплики внутри каждого диалога упорядочиваются по хронологии. Каждая строка в общем логе содержит в себе id диалога, сторону диалога, фразу и время высказывания. рис. 4Стоит отметить, что поиск структуры может быть выполнен на основе как одного диалога, так и большего их количества.В качестве второго этапа мы очищаем фразы от слов и фраз - «паразитов», таких как: «имею в виду», «проще говоря», «типа» и т.д. Предложения, избавленные от этих конструкций, удается более точно отделять друг от друга на этапе 4 – «Кластеризация».Этап 3: векторизацияЗдесь мы векторизуем, то есть превращаем текстовые фразы в числовой вид – векторы. Делаем это при помощи предобученной модели language-agnostic BERT. Мы используем урезанную версию модели - Подаем модели на вход по очереди фразы из общего лога, а на выходе получаем 768-мерный вектор (CLS-эмбеддинг), отражающий смысл целого предложения. В текущей версии AI-генератора мы используем именно модель LaBSE, так как полученные от нее векторы давали лучшие для нас результаты на последующих этапах. рис. 5Этап 4: кластеризацияПоскольку в начале мы сказали, что будем искать структуру диалога как последовательность этапов в речи оператора, то здесь сначала нужно прийти к логу оператора, временно отбросив реплики абонента из общего лога.Затем мы непосредственно проводим кластеризацию, то есть группировку похожих по смыслу фраз при помощи реализации алгоритма community detection из библиотеки sentence_transformers.Фразам присваивается метка в зависимости от принадлежности к группе, а в качестве результата мы получаем размеченный лог оператора. Стоит сказать, что не все фразы находят принадлежность к группам, например, из-за своей редкости. В таком случае мы считаем их шумом и отбрасываем из лога. Оцениваем качество кластеризации через коэффициент «силуэт».Мы тестировали разные алгоритмы кластеризации и остановились на выбранном не сразу. Сначала нам показался недостатком тот факт, что не все фразы могут получить метку кластера, однако затем трактовка таких фраз как шума и их игнорирование позволило получить гораздо более четкую структура диалога.рис. 6Этап 5: Process MiningПятый этап – Process Mining – или исследование процессов. На этом этапе наша задача отыскать генерализованную структуру диалога на основе различных вариантов этих диалогов из лога оператора.Мы рассматриваем диалог как процесс. Это последовательность размеченных высказываний оператора (или этапов). Для формирования генерализованной структуры мы отбираем только наиболее частотные и строгие последовательности высказываний, применяя алгоритм heuristic miner.На выходе получаем визуальное представление диалога как процесса – граф реплик оператора. И в данном примере мы видим, что в логе есть последовательность AD, но в итоговую схему она не попала как редкая.Успешность визуального представления мы измеряем четырьмя метриками.Интересно, что совершить переход от кластеризации к Process Mining нам удалось благодаря совету, полученному в NLP-коммьюнити. Обсуждая задачу в одном из профессиональных сообществ, мы получили рекомендацию. Высказанное предположение у нас получилось реализовать.рис. 7Этап 6: Создание заготовки скриптаНа следующем этапе мы превращаем визуальное представление процесса диалога в заготовку скрипта.Скрипт робота-оператора – это главным образом, последовательность состояний произнесения (speech_state) и слушания (listening_state). Поскольку полученный на предыдущем этапе граф – это последовательность только speech_state’ов, то мы смотрим, является ли какой-либо speech_state исходным состоянием для двух и более других speech_state’ов. Если да, то в таком случае добавляем состояние слушания.Условия переходов из состояния слушания в последующие состояния произнесения получаются из обращения к общему логу – мы узнаем, что говорил абонент между выбранными speech_state’ами оператора и создаем правила переходов.рис. 8Результат работыНа этапе MVP, мы примерно оценили КПД от нашего AI-генератора скриптов.  Здесь должна звучать барабанная дробь…Нам удалось сократить время разработки скрипта в 12 (!) раз. Мы продолжаем работать над AI-генератором скриптов. Например, создаем интерфейсы для работы в нем. Но основная задача - автоматизировать "дообучение робота". Мы хотим, чтобы модель самостоятельно анализировала базу звонков, совершенных по созданным скриптам, и совершенствовалась.Но это будет уже совсем другая история…      Tags: речевые технологииnlpкластеризацияprocess mining  Hubs: VS Robotics corporate blogArtificial Intelligence          


