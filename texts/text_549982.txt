

Честные глаза плагиатора, или еще один взгляд на будущее систем обнаружения заимствований / Habr


               1  April  2021 at 09:50  Честные глаза плагиатора, или еще один взгляд на будущее систем обнаружения заимствований «Антиплагиат» corporate blog Programming *Machine learning *Microservices *Natural Language Processing *      Развивать систему, созданную 16 лет назад, «конечно, не подвиг, но вообще что-то героическое в этом есть» (с). От пользователей регулярно прилетают вопросы: что будете делать дальше? Каким будет Антиплагиат через несколько лет? Все правильно, все верно – нельзя позволять рутине себя засасывать настолько, чтобы не оставалось времени подумать о далеком…, о жестоком…, ну вы поняли… о будущем.
Действительно, начало весны (отчетность закончилась, а сессия еще не началась) – самое удобное время для стратегических планов. Ну а заодно и для удовлетворения любопытства наших пользователей.
Не могу сказать, что описываю совсем уж ближайшее будущее. Какие-то идеи пока находятся в обработке у наших исследователей, какие-то и вовсе пока еще «варятся в головах». Но тем не менее, описанный ниже сценарий развития системы «Антиплагиат» сейчас наиболее вероятен.

Картинку даю, слегка опережая события. Она имеет непосредственное отношение к теме статьи, но, чтобы обо всем рассказать, нужно чуть больше места.

Кадр из а/ф «Шрек 2» (англ. « Shrek 2»), DreamWorks Pictures, 2004 год

Нам хотелось бы решить проблему «подстройки пользователей под систему» если не раз и навсегда, то, по крайней мере, надолго. Нужно сделать так, чтобы мы были готовы к любым новым хитростям со стороны тех, кому потенциально интересно выдать чужой текст за свой. Для того, чтобы изложить суть моей идеи, нужно для начала изложить три предпосылки.
Предпосылка первая
Любая контролирующая система будет оставаться эффективной только в случае непрерывного развития. Должно быть что-то, в чем она опережает тех, кто пытается ее обмануть. Иначе окружающая среда, мотивированная на преодоление системы «Антиплагиат», сожрет ее с потрохами найдет слабые места и придумает, как эти слабые места эксплуатировать. Информация и о том, и о другом становится достоянием общественности очень быстро.
До определенной степени можно продержаться, используя принцип Security through obscurity, то есть скрывая архитектуру и детали алгоритмов. Но, как показывает практика, принцип хорошо работает в том случае, если вы никому_не_нужный_неуловимый_Джо. Если же (как в нашем случае) систему ежедневно используют десятки или сотни тысяч пользователей, то ваша таинственность идет вам, как Соеву – пенсе  помогает очень ограничено.
Предпосылка вторая
Если рассматривать обнаружение заимствований как задачу информационного поиска, то не покидает ощущение легкой нечестности происходящего. В классическом поиске субъект (т.е. пользователь) заинтересован в получении хорошего результата. Он может не иметь нужного навыка, но уж если он ищет, допустим, «пластиковые окна» или «рефераты по экономике», то рассчитывает получить максимально полезные для себя результаты. В ситуации с заимствованиями же можно уверенно говорить, что большая часть пользователей хотела бы, чтобы вне зависимости от объективной реальности не было найдено…ничего. И очень многие из этих пользователей готовы прикладывать те или иные усилия, чтобы приблизиться к такому «идеальному» результату. Перефразировка, перевод, скрытый текст, незаметные пробелы, встроенные объекты, – миллион вариантов «повышения оригинальности». Естественно, мы совершенствуем систему и чем дальше идем в этом направлении, тем сложнее становится именно повышать. Но между изобретением нового способа «улучшения результата» и изменением в системе (будь то хотфикс или новая функциональность) всегда проходит время и иногда достаточно большое.
Предпосылка третья
Качество работы поиска – это всегда баланс. Во-первых, это баланс между тем, чтобы не сигнализировать о проблемах тогда, когда их нет, и тем, чтобы упустить явное заимствование, когда оно есть. Как говорится, и овцы целы, и волки сыты, что бы это ни значило. Во-вторых, это баланс затрачиваемых ресурсов на обработку документа. Мы не должны потратить слишком много (времени, процессорного времени, памяти, трафика), если нет дополнительных предпосылок к тому, что нужно поискать повнимательнее. Дополнительные ресурсы лягут на пользователей увеличением стоимости использования сервиса, а деньги все считать умеют.
А теперь, собственно, Идея
Идея, если коротко, состоит в следующем: использовать априорную информацию об учебной работе, чтобы помочь системе «Антиплагиат» выбрать нужную степень паранойи при анализе конкретной работы.
То есть, если система будет знать, что к той или иной работе нужно «присмотреться повнимательнее», то это позволит анализировать «зону риска» более тщательно, не затрачивая ресурсы на проверку других работ.

Кадр из к/ф «Место встречи изменить нельзя», Одесская киностудия, 1979 год
Иначе говоря, нужен предсказательный «сервис подозрительности проверяемых работ».

Какими способами можно предсказывать? Предлагаем несколько вариантов.
Способ первый – спросить преподавателя
В системе «Антиплагиат.ВУЗ» преподаватель при создании задания сразу может отметить тех студентов, чьим работам следует уделить внимание. Примерно так:

Источник картинки: компания Антиплагиат
У этого способа есть несколько особенностей. Во-первых, очевидно, что преподаватели не будут использовать его массово. Слишком много отклонений от простого варианта: «Next, Next, Next, Finish». 
Во-вторых, этот способ может нести риски стимулирования коррупции. Для нейтрализации этого риска необходимо будет использовать перекрестный контроль.
Наконец, в-третьих, накапливаемые данные можно будет использовать для обучения классификатора. Чтобы преподаватели «не жестили», будет введено ограничение на количество и долю студентов, которых можно подозревать в рамках одного задания.
Способ второй – API
Второй способ является упрощенным вариантом первого. Нужно отдать во внешние системы возможность управления уровнем паранойи. Типичная внешняя система – СДО Moodle, для которой уже есть сертифицированная интеграция с Антиплагиат.ВУЗ.
Реализация этого способа проста до невозможности. Расширяем параметр CheckDocParams метода CheckDocument:

параметром паранойи системы:

Остальное остается на откуп партнерам, которые реализовали интеграцию.
В чем проблема этих двух способов? В том, что они не работают «без человека», который может быть предвзят, которому может быть просто лень или некогда, который, наконец, может просто ошибаться. 
Конечно, можно было бы организовать предсказательную систему так, как, например, было предложено в фильме «Особое мнение».

Кадр из к/ф «Особое мнение» (англ. «Minority Report»), 20th Century Fox, DreamWorks Pictures, Amblin Entertainment, Blue Tulip Productions, 2002 год
Но до тех пор, пока наш HR занимается заполнением открывшихся вакансий провидцев, нам придется полагаться на возможности AI.
Способ третий – искусственный интеллект
Итак, о третьем способе на основе машинного обучения. Нужно оценить априорную склонность студента к использованию чужого текста. В современных условиях всеохватывающей дистанционки этот способ отлично работает в условиях видео- и аудиопотока. Каждый студент так или иначе взаимодействует со своим вузом онлайн. Самый распространенный вариант – это Zoom. Звучит слегка безумно, но нам нужно оценить шансы на то, что студент прибегает к плагиату, посредством видеочата с этим самым студентом.
Первым для оценки склонности к плагиату будет использован анализ движения зрачков студента на онлайн занятиях. По этой теме, есть как научные работы с анализом методов извлечения и анализа траектории движения зрачка (например, Christian Hirt et al, Maria K. Eckstein et al, Yujin Jung et al), так и готовые библиотеки (тот же PyGaze), которые можно использовать для промышленных задач.
Таким образом, перед нами обычная задача классификации с двумя классами. Этапы решения задачи вполне традиционные:

Предобработка видеопотока
Получение трека движения взгляда
Выделение признаков
Решение задачи классификации

Примечательно то, что данные для обучения классификатора можно собирать на действующей системе: нам достаточно сделать программного агента, собирающего признаки через Zoom API, после чего сопоставить результаты сбора признаков с результатами проверки документов этого пользователя в режиме максимальной паранойи.
Дополнительно планируется использовать данные:

о положении тела (движения головы, рук, позы), 
мимике, 
наличии в кадре посторонних объектов (графин с водой, булочка), 
речи (в тех случаях, когда у студента включен микрофон).

Проведенные нами предварительные эксперименты показывают, что можно рассчитывать на достаточно высокое качество решения задачи. Оценочно количество работ, которые отклоняются из-за плагиата, может вырасти на несколько процентов. Такой вклад существенно превышает разовое влияние на качество поиска других способов.
У использования такого метода, конечно, есть свои нюансы. Первый – это возможность не включать камеру на занятия, ссылаясь на различные обстоятельства: отсутствует/сломалась камера, не убрана комната, небритое лицо, шастающий кот. Но уже сейчас во многих учебных заведениях включение камеры является обязательным, и при выключенной камере может быть просто засчитана неявка на занятие.
Вторая – это использование студентами различных техник, позволяющих обмануть AI по примеру обмана полиграфа («детектора лжи»). Здесь важны два момента: обманывать полиграф «на потоке» могут разве что тренированные сотрудники спецслужб; в нашей ситуации будет трудно разработать типичные паттерны обмана и обучиться, так как результаты оценивания скрыты внутри сервиса и студенту не предъявляются.

Кадр из фильма «День, когда Земля остановилась» (англ. «The Day the Earth Stood Still»), 20th Century Fox, 2008 год
Кроме того, есть еще один важный фактор. Сначала технология априорного оценивания склонности к плагиату будет применяться для выделения «зоны риска», и по умолчанию уровень чувствительности алгоритма проверки будет сохраняться на обычном уровне. Но с определенного момента уровень «по умолчанию» будет изменен на параноидальный, а вот положительные оценки технологии априорного оценивания станут основанием для использования обычного поискового алгоритма.
Но и это еще не все. Сейчас обсуждаются идеи по обогащению широко распространенных стилометрических методов поиска плагиата (см. например, методы выявления внутреннего плагиата и авторской диаризации) информацией, снимаемой при наборе текста. 
Наконец, самый серьезный шаг, который, вероятно, решит проблему комплексно – это предварительное тестирование общей склонности студента к обману. Само собой, что это сложный и ответственный шаг, к которому нужно подходить с особой подготовкой. Мы ожидаем, что подготовка к данному этапу займет два-три года. Но уже сейчас очевидно, что он неизбежен.

Кадр из фильма «Матрица» (англ. «The Matrix»), Warner Bros., Village Roadshow Pictures, 1999 год
Поверили?
Расслабьтесь! Шутим мы. Мы не планируем реализацию описанной выше технологии, а решили развлечь вас описанием не такого уж невозможного будущего, как, например, мы делали в прошлом году. Большое спасибо, что дочитали до этого момента. Интересно, удалось ли вам сохранить веру в описываемое до сих пор, или в какой-то момент подавление недоверия перестало работать? Напишите в комментариях.
Огромное спасибо коллегам, которые приняли участие в подготовке статьи: Олегу Бахтееву (Oleg_Bakhteev), Андрею Ивахненко (andyray), Александру Кильдякову (vainah76), Анастасии Чернышовой (chernnasty).
Всех с праздником! На всякий случай повторю, что реализация описанного метода не планируется.
Пока.    Tags: праздникразработкаантиплагиатпозитивобработка текстовинформационный поискмашинное обучение. нейросетиалгоритмы Hubs: «Антиплагиат» corporate blogProgrammingMachine learningMicroservicesNatural Language Processing          


