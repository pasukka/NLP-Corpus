

Инструменты Дата-сайнтиста. Универсальная база / Habr


               Инструменты Дата-сайнтиста. Универсальная база  Reading time  
    4 min
   Views  6.9K Инфосистемы Джет corporate blog Python *Machine learning *Studying in IT Artificial Intelligence  
    Review
        Специалисты по анализу данных используют много разных инструментов, причем новые технологии (фреймворки, библиотеки и т.д.) появляются так часто, что у начинающих  постоянно возникает вопрос, что им нужно изучать в первую очередь. Здесь вы найдете обзор базовых инструментов. Мы используем эти инструменты в проектах, связанных с прогнозированием и видеоаналитикой для промышленности, сельского хозяйства, ритейла и других отраслей. Языки программированияКакие же инструменты нужны специалисту, который занимается анализом данных? Это, конечно, зависит от того, что входит в его обязанности. У нас в центре машинного обучения достаточно часто возникает ситуация, когда одному и тому же сотруднику приходится и работать с источниками данных, и анализировать эти данные, и обучать модели машинного обучения, и реализовывать прототипы сервисов.В любом случае основой является язык программирования, и без его хорошего знания двигаться дальше будет сложно. Сейчас самый распространенный язык — это Python, в нашем центре мы специализируемся именно на нем. Есть ли альтернативы Python? Да, но они достаточно нишевые. В таблице 1 я представил основные языки программирования и их особенности:Табл 1. Особенности языков программирования при их использовании для анализа данных Среда разработкиСреда разработки (IDE) — ПО, предназначенное для написания, тестирования и отладки программного кода. В Data Science есть нюансы в сравнении с чистой разработкой кода: специалисту нужен не столько код, сколько сами результаты анализа данных. Для анализа очень подходят Jupyter-ноутбуки. Они позволяют писать код, загружать и визуализировать данные, добавлять поясняющие комментарии, формулы, таблицы, причем делать все это можно в одной интерактивной среде. Есть много инструментов для работы с Jupyter-ноутбуками — начиная с классических Jupyter Notebook и JupyterLab и заканчивая облачными и коммерческими инструментами (Google Colaboratory, Yandex DataSphere, Amazon SageMaker, JetBrains Datalore и другие реализации, заложенные в проприетарные инструменты).Табл. 2. Особенности Jupyter Notebook и JupyterLab Всё это веб-инструменты — удобные, интерактивные и не требующие вспомогательного ПО на вашем компьютере, кроме браузера. Однако для профессиональной работы с кодом (в том числе для анализа данных) мы рекомендуем использовать полноценную среду разработки. Ее применение позволяет повысить эффективность работы и качество кода. Какая среда подойдет для анализа данных? На данный момент JetBrains PyCharm и Visual Studio Code являются универсальными IDE в профессиональной разработке на Python. Табл. 3. Особенности JetBrains PyCharm и Visual Studio CodeVSCode и PyCharm сейчас очень популярны, но мир не стоит на месте и уже появляются среды, адаптированные именно для задач анализа данных (например, Spyder IDE или JetBrains DataSpell). Нельзя сказать, что эти инструменты прямо must have, но нужно держать руку на пульсе и наблюдать за тем, какие полезные функции в них появляются.Версионирование кода и данныхВажный навык для эксперта по анализу данных — умение работать с системами контроля версий. Особенно когда в сложном проекте задействованы несколько специалистов и им нужно делиться друг с другом результатами экспериментов.Инструменты для работы с кодом более или менее стандартные: наиболее популярны система контроля версий Git и инструмент GitLab для управления жизненным циклом кода.  Вопросы версионирования не менее важны и в работе с данными и моделями. Здесь на помощь приходит DVC — один из наиболее известных инструментов версионирования данных. Он помогает не только версионировать датасеты, но и автоматизировать пайплайны обработки данных и управлять проведением экспериментов.Табл. 4. Особенности Git, GitLab и DVCУправление экспериментамиВ последнее время отслеживание результатов экспериментов становится неотъемлемой частью работы дата-сайентиста. Сюда также входит ведение реестра экспериментов, сравнение гиперпараметров, метрик и других результатов, возникающих в процессе работы с данными и ML-моделями. Инструменты для управления экспериментами (experiment tracking) позволяют хранить их результаты и сравнивать их. Примеры таких решений — MLflow, ClearML, Weights & Biases и др.Табл 5. Особенности инструментов для управления экспериментамиВсе указанные нами инструменты — это универсальная база. Практика неизменно требует многочисленных дополнительных решений: фреймворков, библиотек анализа данных и машинного обучения. И здесь буквально разверзается бездна, потому что разные библиотеки предназначены для разных задач: одни подходят для работы с таблицами и массивами чисел (Pandas, NumPy), другие содержат базовые реализации алгоритмов (Scikit-learn, SciPy), третьи являются фреймворками для построения и обучения моделей нейронных сетей (Torch, TensorFlow), четвертые содержат реализации готовых архитектур (Timm, Transformers), пятые подходят для визуализации данных. Также есть специализированные инструменты для статистического анализа, работы с разными источниками данных, трансформации данных, работы с классическими алгоритмами компьютерного зрения, анализа временных рядов и т.д. В следующих постах мы продолжим тему и расскажем об инструментах, не вошедших в этот базовый обзор.В качестве заключения отмечу, что инструментов много, поскольку повышается уровень специализации и появляется много новых задач. Для успешной работы не требуется детально изучать все существующие в мире инструменты. Специалисту по анализу данных нужно ведь не так уж и много. Достаточно постановки реалистичной задачи и данных. Если все это есть, то остальные проблемы так или иначе решаемы.Автор: Антон Чикин, руководитель отдела интеллектуального анализа центра машинного обучения "Инфосистемы Джет"      Tags: машинное обучениеidepythonинструментыдата сайнсjupyter notebookdvcvisual studio codejetbrainspycharm  Hubs: Инфосистемы Джет corporate blogPythonMachine learningStudying in ITArtificial Intelligence          


