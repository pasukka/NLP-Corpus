

Что такое алгоритм… Часть [05:00] «Искусственный интеллект» / Habr


              22  December  2021 at 03:12  Что такое алгоритм… Часть [05:00] «Искусственный интеллект» Algorithms *Artificial Intelligence Brain       На алгоритмической арене будет дано новое представление. Под куполом "Искусственного интеллекта" покажут потолок своих возможностей "Языки программирования" в столкновении с ограничениями, унаследованными от естественных языков. Будут продемонстрированы особенности использования структуры, контролирующей последовательность исполнения алгоритма. Мы приоткроем секреты фокуса "Китайская комната". Выясним на какой алгоритмический путь вступила технология искусственных нейронных сетей (ИНС). А самое главное подготовим почву для заключительной статьи, призванной зафиксировать единственно возможный способ синтеза информации.
Итак, время пришло. Мы начинаем...

Осторожно. Под катом много перегруженных предложений, а главная функция иллюстраций — задавать повествованию ритм.
Простите мне это цирковой конферанс над катом. Никак не могу разделаться с нотками восторга, находясь в предвосхищении разговора, который является целью каждой опубликованной мной статьи. Текущая статья — продолжение игры с термином "Алгоритм". Эта игра начата здесь совсем не для состязания, но ради изучения. Совсем как в детстве, когда мы, играясь, с нуля познавали этот мир, подобно игре с порядковым номером [05:00] в заголовке. И как в любой игре мешают правила, запомненные в игре предыдущей, так и последующем разговоре мешают многие устоявшиеся термины. И потому читать дальше будет интереснее тому, кто на время готов забыть привычное, способен поиграться увиденным и уцепить за хвост закономерное...

Задача
Предыдущая статья серии была о философии. С одной стороны это не самая уместная тема на Хабр. Но, статья-жертва оказалась необходима. В ней состоялся обзор закономерностей, существующих в естественном языке, которые являются важными предпосылками для разговора текущего. Совсем странно было бы размещать лишь предыдущую статью отдельно на философском форуме, и здесь ссылаться на сформулированные в ней положения.
Но и все остальные статьи серии не окажутся в стороне. На основе выводов, зафиксированных в них, мы попробуем собрать несколько необычное средство анализа развивающихся систем. Это средство необходимо, потому что оно формирует важное дополнение к существующему арсеналу математических инструментов, показывая, как выстроить мост между формальной системой и прикладной областью, в которой она используется.

Главной опорой при построении обозначенного "моста" является автоматизация способов формирования аксиом и правил вывода для прикладной области, заданной извне. Конечно, предлагаемое средство является лишь дополнением к старому и проверенному способу аксиоматизации, задачами которой практически всегда за редкими исключениями занимался человек. Но это дополнение необходимо. Потому что абсолютизация человеческого участия в построении теорий является существенным ограничением для одной очень важной области. Аксиоматическая "изоляция смысла", тщательно выполняемая человеком, неизбежно ограничивает развитие возможностей наших вычислителей, устанавливая непреодолимые барьеры, проистекающие из ограничений формальных систем (аксиоматических теорий), в них закладываемых.
Предположение об ограниченности возможностей естественного языка, сформированное на основе математически доказанных ограничений формальных систем, завершило главную содержательную линию предыдущей статьи. В текущей статье запланировано развитие этого направления, но на этот раз целью выбрана не теоретическая, а практическая область задач. В статье нам необходимо:

оценить насколько критичными для развития вычислительной системы являются ограничения формальных систем, самое существенное из которых — теорема о неполноте Гёделя;
узнать на примере существующих языков программирования, какого способа не хватает языковым средствам для преодоления ограничения, обозначенного в предыдущем пункте;
и порадоваться тому факту, что "прорывной" способ на самом деле уже нами реализован и успешно используется, но без должной оценки его значимости. А без осознания его реального значения упускается важный вектор развития, который уже давно может быть "позаимствован" у живых организмов.


Для решения поставленной задачи нам необходимо выполнить перекрестный анализ на стыке странного сочетания из следующих четырех технологий:

разработка аксиоматической теории,
синтез организмом алгоритма своего поведения,
использование языков программирования,
создание системы Искусственного интеллекта (ИИ).

Давайте начнем с последнего пункта, указывающего на противоречивую технологию ИИ. Словом "противоречивый" здесь хочется зафиксировать отсутствие на текущий момент единого мнения, определяющего конечный набор демонстрируемых системой функциональных возможностей, которые однозначно позволяют отнести её к классу ИИ. Есть очень разнородный список функций характерных ИИ. В этом списке с течением времени появляются завоёванные позиции:

распознавание образов (изображений, речи, видео),
генерация содержания (графика, музыка, новости, стихотворения),
стратегические способности (финансы, человеческие игры)...

Но есть в списке и пока непокоренные рубежи. Среди них выделим функцию, которая выполняет "манипуляции" с человеческими знаниями. Одним из способов реализации такой функции для знаний, представленных текстом, являются системы, создаваемые для прохождения Теста Тьюринга. Такие системы являются яркой демонстрацией "противоречия" в области ИИ, потому что пока существует сомнение в их полезности для чего-нибудь кроме прохождения самого теста. Примером формулировки этих сомнений является мысленный эксперимент Джона Сёрла "Китайская комната". Чуть позже в статье нам пригодится структура этого эксперимента.

Для борьбы с выявляемыми противоречиями области предпринимаются попытки систематизировать существенные признаки ИИ. И уже на их основе классифицировать существующее множество функции. В процессе такой систематизации на текущий момент сформирована договоренность, выделяющая слабый и сильный ИИ. Но поиск значимых признаков в области ИИ по-прежнему сложен. Крайне необходим прорыв, позволяющий устранить сложившиеся противоречия. Многие согласны, что для прорыва необходимо сформировать описание структуры процессов мозга, которое объяснит все внешне наблюдаемые признаки, делающие демонстрируемое человеком поведение таким уникальным. Но по состоянию на момент публикации или никто не знает приёмов позволяющих создать такое описание, или кто-то знает, но никому о них не рассказывает, или верен пессимистический вариант — и такие приёмы просто невозможны.
Предлагаю все же не впадать в агностическое отчаянье, а вместо этого немного поупражняться в анализе и оценить возможности одного любопытного приёма. Для этого рассмотрим "человеческую уникальность", обратив внимание на первый пункт списка терзаемых в этой статье технологий.
Предположим, что разбор этапов создания человеком аксиоматической теории демонстрирует почти все ключевые отличительные моменты человеческого мышления.

Тут справедливо можно указать на необоснованность и странную однобокость этого утверждения. Думаю, время рассудит и взвесит приведенную здесь формулировку. А пока попробуем не заострять на этом внимание и приведем общепринятое значение слова "Аксиома" (википедия):
Аксиома — исходное положение какой-либо теории, принимаемое в рамках данной теории истинным без требования доказательства и используемое при доказательстве других её положений, которые, в свою очередь, называются теоремами.Обозначив термин "Аксиома", стоит оценить остальные три пункта указанного в начале списка технологий. В рамках текущей статьи нам необходимо поиграться несколькими терминами и, скрестив "трех ежей с удавом", попробовать выяснить:

чему соответствует аксиома: в области языков программирования, во множестве алгоритмов человеческого поведения и в процессе обучения ИНС;
каковы требования к "структурной мощности" системы описания алгоритма для возможности формирования аксиомы в этой системе;
какие процессы в построении структуры описания алгоритма разрешают вопрос "Китайской комнаты";
в чём отличие обучения структуры ИНС и обучения структуры, формирующей поведение человека.

Но для начала необходимо ответить на следующий вопрос.
Что есть Язык программирования?
Можно сразу указать ответ со страницы Википедии:
Язык программирования — это формальный язык, предназначенный для записи компьютерных программ.Для дальнейших задач необходимо дополнить его следующим определением (стандарт ISO/IEC/IEEE 24765:2010):
Компьютерная программа — комбинация компьютерных инструкций и данных, позволяющая аппаратному обеспечению вычислительной системы выполнять вычисления или функции управления.
После подстановки значения второго термина попробуем немного переформулировать, подмечая, что "вычисления или функции управления" являются задачей из определения термина "Алгоритм". Итак:
Язык программирования — это формальный язык, предназначенный для формирования структур алгоритмов и данных, с использованием которых контролируется работа вычислительной системы.Возможно, Вас тоже несколько смущает упомянутое словосочетание "структура алгоритма". Оно отсутствует в Википедии. В поисковике такой запрос выводит список ссылок на кусочки, посвященные условиям и циклам, из книг и лекций по программированию. Это кардинально отличается от результатов совсем другого качества, формируемых запросом "Структура данных". Для него отыскиваются ссылки на статьи и книги, всецело посвященные только этой теме. О чем это может говорить? Все просто: человек или меньше работает со "структурами алгоритма", или ему не нужны в этом подсказки.
Из личного опыта могу подтвердить, что и в моей профессиональной практике слово "структура" чаще всего указывает на сложно организованные данные. Для таких данных все время приходится создавать алгоритмы анализа и трансформации. Технологии обработки структурированных данных постоянно и повсеместно используются в нашей отрасли. Совсем иначе обстоят дела со "структурой алгоритма". После работы Эдсгера Дейкстры «О вреде оператора goto», давшей отправную точку парадигмы "структурного программирования", было немало работ, посвященных "структуре алгоритма": методология ООП, функциональное программирование, паттерны проектирования, принципы SOLID… Но исключительно малое количество этих работ говорит об этом как о структуре. Получается, что "структуры алгоритма" — это узконаправленная область знаний, автоматизация в которой по-настоящему интересна только ограниченному кругу специалистов, разрабатывающих компиляторы, языки программирования и среды для написания программного обеспечения.

Слово "структура" настолько приросло к слову "данные", что недавно, рассчитывая довольно древнюю, но еще живую метрику кода, полчаса не мог понять, что имеется в виду под количеством "основных логических структур". Возможно так происходит с легкой подачи того множества книг по программированию, которые находятся в активном использовании. А еще по образцу из классической и любимой книги Н.Вирта "Алгоритмы и структуры данных".
К чему весь этот разговор о "структуре алгоритма"? Он здесь появился, потому что, разбираясь с определениями слова "Алгоритм", со временем пришёл к заключению, что самым расстраивающим меня местом во всех предлагаемых формулировках является отсутствие конкретных указаний на доступные программисту способы "описания порядка действий":
Алгоритм — конечная совокупность точно заданных правил решения некоторого класса задач или набор инструкций, описывающих порядок действий исполнителя для решения определённой задачи. (Википедия).Да, сложно описать все возможные задачи. Пусть, не перечислить типов существующих действий. Но ведь можно как-то систематизировать, какие доступны "правила"? Какими способами можно "описать порядок"? За этой систематизацией отправился на специальность "Программное обеспечение". Но в ВУЗе никто так и не дал прямого ответа на эти странные вопросы. Именно поэтому в первой статье серии описано наблюдение, что каждый программист вынужден на личном опыте постигать программирование. Но, правильно поставленные вопросы — это почти пол-успеха в поиске ответа. И опыт программирования с попутным анализом используемых способов "описания порядка" добавил вторую половину. Теперь я знаю, что способом описания порядка и правил в алгоритме всегда является структура. Для языков программирования этой структурой является записанный текст алгоритма. Структура текста алгоритма транслируется в бинарную структуру машинных кодов, которая описывает и контролирует порядок действий исполнителя (например, ЭВМ). Вроде здесь всё тривиально? Зачем вообще было заострять на этом внимание? Это необходимо только потому, что структура контролирующая исполнение может быть много сложнее текста программы. И с усложнением структуры появляются достойные внимания результаты. К этому нужно будет вернуться чуть позже. А сейчас попробуем разобрать, что есть общего и чем все же различаются текст на языке программирования и текст на естественном языке.

При сравнении формального и "естественного" текста нам поможет то, что обнаруживается сходство между процессами развития языков программирования и описанными в предыдущей статье процессами развития естественного языка. В естественный язык для работы с высказываниями целенаправленно вводились ограничения на формулирование (борьба с парадоксальными утверждениями) и фиксировались корректные трансформации (силлогизмы, логика высказываний). В программировании с целью повышения эффективности работы с текстом алгоритма шёл аналогичный процесс. В ходе этого процесса последовательно вводились ограничения, закрепляющие успешные формы развития кода и оберегающие программиста от совершения ошибок. Наиболее важные решения, послужившие развитию систем разработки кода, мы теперь называем парадигмами программирования: структурное программирование, объектно-ориентированное программирование… История появления этих шаблонов формирования и развития кода, сопровождаемая аналогиями, существующими в биологических системах, и объясняемая с точки зрения необходимости эволюционного развития алгоритмической системы, пока только тезисно прописана в теоретической книге ОТА. Для желающих освежить в памяти главные события этого развития могу порекомендовать статью "Сказка о парадигмах программирования". Думаю, используемое в указанной статье сказочное повествование должно порадовать тех, кто смог пробраться через "сложноязычие" предыдущих статей моей серии.
Вспомним и зафиксируем: "Компьютерная программа" — это некоторая структура алгоритма и данных, используемая вычислителем. В тексте на естественном языке, разбираемом в прошлой статье, тоже была структура из слов, используемая человеком при коммуникации. При этом мы отметили, что некоторые слова в тексте на естественном языке являются глаголами, а некоторые указывают на признаки объектов или состояний. Очевидно, что некоторые тексты на естественном языке являются описанием алгоритма. Сложнее заметить, что описанием алгоритма поведения (или его части) являются все существующие осмысленные тексты, даже текст текущей статьи. Выполненная человеком формализация языка: перевод глаголов в идентификаторы машинных операций; перевод признаков в условные операторы, оценивающие данные; введение ограничений на возможные последовательности ключевых слов — все это не изменило главного. Общее для текста на естественном языке и компьютерной программы сводится к наличию в них структуры, описывающей некоторый алгоритм. Отличие же этих двух форм только в исполнителе, который контролируется этим описанием.
Путь к аксиоме
Чтобы продвинуться в наших рассуждения дальше, нам придётся использовать множество утверждений, которые описывают закономерности, обнаруженные в естественном языке. Каждое из этих утверждений на текущий момент является только гипотезой. Все они требуют обсуждения и проверки. Для каждого утверждения ранее была сформирована отдельная статья этой серии. Но их обсуждения почти не было. Объясняю это тем, что не была видна общая картина, в которую эти утверждения встраиваются. В текущей статье картина будет представлена полностью, а потому надеюсь, что аргументированная критика всех предпосылок состоится. Для продолжения чтения этой статьи попробуем принять их на веру. Да, у нас получается немного затейливо: на пути к аксиоме нам нужно некоторые положения принять как аксиомы. Но тут ничего не поделать. Рекурсивность терминов, пожалуй, главная особенность работы с понятием "Алгоритм".

Итак, основываясь на гипотезе эволюции текста в компьютерную программу, можно предположить, что язык программирования унаследовал все ограничения, существующие в процессе синтеза алгоритма на естественном языке. Эти ограничения обусловлены способом формирования естественного языка, появившегося из-за необходимости взаимодействия организмов для исполнения коллективных алгоритмов выживания ("Язык" статья 3.25). Уже потом для выживания стала необходима передача важных алгоритмов поведения от взрослой особи её потомкам. Это породило специализацию коллективного алгоритма ("Обучение" статья 3.14), в совершенствовании которой стали оттачиваться текстовые структуры оптимальные для описания и копирования алгоритмов поведения. Способы синтеза алгоритмов поведения изначально не были текстовыми ("Эволюция памяти" статья 3.1), и уже потому многие из процессов изучения среды и создания нового алгоритма поведения не сводятся к трансформациям текста. Невозможно свести к операциям, выполняемым только над текстом, интерполяционные способы синтеза (пример в статье 5.0). Их назначение сформировать описание закономерности выполняемых действий и признаков в среде, чтобы дать человеку возможность использовать описанный процесс в виде элементарного алгоритма (или "действия" в терминах статьи 1). Именно такие алгоритмы, найденные в среде, мы называем аксиомами. Для них не существует языкового доказательства исполнимости, потому что они — замеченная однородность среды, описанная в некоторой структуре мозга ("Память и мозг" статья 3). Единственным критерием их истинности является то, что они продолжают наблюдаться в среде, а значит на их основе можно строить более сложные алгоритмы.
Используя описанное выше, мы можем сделать первый шаг в построении аксиоматической теории. Для этого необходимо использовать интерполяционный синтез алгоритма и наблюдать за средой, обнаруживая аксиомы. Второй шаг, формирующий правила вывода, тоже основан на интерполяционном синтезе. На этом этапе синтезируются алгоритмы, фиксирующие доступные в среде способы трансформации и группировки имеющихся аксиом. Оставшиеся шаги на пути к теории являются способами проверки и огранки обнаруженного интерполяцией алмаза. И, как показал нам пример перехода от персонажа Тор к электро-магнитному объяснению молнии ("Философия" статья 5.0), этот путь тернист. "Огранка" заключается в оценке полезности и повышении эффективности системы выявленных аксиом и правил. При этом необходимо отсеять несостоятельные аксиомы и проверить границы их применимости. Для повышения эффективности целесообразно уменьшать количество аксиом и правил вывода с устранением их взаимозависимостей.
Описанная выше последовательность является лишь планом, но не полноценным описанием. Однако реальные примеры (из математики, физики, биологии...) демонстрируют, что способы формирования эффективной и непротиворечивой формальной теории для разных прикладных областей "придерживаются" этого плана. Общим для них является и то, что в рамках готовой формальной теории вычислительно (без контакта со средой) на основе существующих аксиом и правил вывода появляется возможность "выводить новые истинные высказывания". Опираясь на такие "высказывания", человек формирует алгоритмы решения новых задач, например, таких, как разделение прямоугольного поля на две равные части, нахождение площади круга с известным радиусом, выведение сорта тюльпана требуемого цвета, определения времени падения яблока, указания массы для бозона Хиггса...

Но весь путь формирования теории слишком велик для одной статьи. Поэтому сосредоточимся на его первом шаге. Факт зарождения аксиомы очень примечателен. Как выполнить обещанную автоматизацию этого действия? В какой структуре кроме человеческой памяти аксиома может быть зафиксирована? Есть ли в существующих языках программирования подобные структуры? Ведь эта структура должна выявлять закономерность, фиксировать её и потом обеспечивать исполнение зафиксированного. Вам ничего не напоминает последовательность этих мероприятий? Они очень похожи на задачи решаемые ИНС.
Почему ИНС близка ИИ?
Давайте попробуем посмотреть на ИНС с точки зрения алгоритмов, которые она исполняет. Как мы помним из выше приведенного определения: алгоритм является решением определённой задачи или некоторого класса задач. Перечислим какие задачи стоят перед ИНС.
Перед еще не тренированной ИНС стоит одна задача. И алгоритм тоже один — по обучающей выборке данных натренироваться на распознавание (признаковую трансформацию) некоторых данных. В результате решения этой задачи происходит фиксация полученных весовых коэффициентов расчетной структуры слоев ИНС, первая задача забывается, но появляется возможность выполнить решение новой задачи. Новая задача может быть вполне конкретной, например, узнать есть ли на изображении кот. Для других обучающих данных, используемых в решении первой задачи, фиксация может произойти на задаче обнаружения пчелы или, возможно, классификации изображений по временам года. Но, где есть автоматическое решение задачи, там есть и алгоритм?
Значит, в процессе обучения ИНС выполняется синтез нового алгоритма. Но для указанного алгоритма распознавания образа можно сказать, что результирующие разные алгоритмы ("кот", "пчела", "сезоны") — занимаются выполнением одной и той же вычислительной задачи отождествления данных, сходных с обучающим набором. При этом они выполняют заданную и одинаковую для каждого варианта последовательность операций пересчета и трансформации некоторого массива данных. Да, конечно, при этом решаются задачи несколько отличные в плане практического использования.
Но это был простой вариант.

А если взять два экземпляра еще не тренированной ИНС посложнее (AlphaGo). И натренировать один экземпляр для игры "Го", а второй заставить узнавать изображения пчелы, которые выложены камешками на игровом поле. Конечно, указанный пример достаточно условен, но не думаю, что это совсем неразрешимая задача для обозначенной ИНС. Синтезированные в результате тренировок алгоритмы очень различаются. Пчелок как в прежнем варианте узнают-распознают. А вот в "игроке Го" ситуация посложнее: наблюдаются последовательности действий, стратегические композиции.
Здесь уже достаточно сложно сказать, что эти две обученные ИНС решают одну задачу. Но после обучения ИНС порядок действий исполнителя одинаков для каждого из обученных вариантов. Структура вычислительного алгоритма неизменна и зависит только от топологии сети. Различаются весовые коэффициенты. И от этого различия меняется выполняемая после обучения Задача.
Конечно, это не делает сложный вариант ИНС совсем невписывающимся в определение алгоритма. Просто задача у алгоритма ИНС не тривиальная — это алгоритм создания алгоритма решения другой задачи и алгоритм исполнения созданного алгоритма. Например, если это будет алгоритм сборки "Кубика-Рубика" (DeepCubeA Forest Agostinelli), то синхронно будут исполняться два алгоритма (вычислительный и синтезированный сборочный). Какой-то из них, конечно, будет соответствовать терзаемому в этой серии статей определению "Алгоритма". Но какой? И знают ли элементы исполняющие вычислительный алгоритм что-нибудь о том, что они собирают Кубик-Рубика?
Тут самое место вспомнить "Китайскую комнату". Два одновременно исполняющихся алгоритма — это ответ на незнание Джоном Сёрлом китайских символов. Машине, реализующей алгоритм решения Кубика-Рубика, тоже известен только вычислительный алгоритм ИНС, и заранее не известен алгоритм сборки. Имея опыт работы с ИНС, мы понимаем, что готовый алгоритм сборки Кубика не является необходимым знанием, вкладываемым в алгоритм обучения и использования ИНС DeepCubeA. А есть ли возможность для человека понять суть алгоритма решения синтезированного в ИНС DeepCubeA и использовать этот алгоритм для решения в "ручном режиме"?

И тут можно перейти к мозгу. Является ли знание алгоритма сборки Кубика-Рубика методом Джессики Фридрих необходимым при формировании алгоритмов работы нейронов нашего мозга? Есть ли возможность по алгоритмам работы нейронов нашего мозга определить, что человек знает алгоритм сборки Кубика? Необходимо ли Джону Сёрлу знать языковые алгоритмы работы с китайскими символами, если у него есть пусть и непонятное ему, но строгое описание требуемых "вычислительных" операций для имитации собеседника, владеющего китайским языком, в прохождении Теста Тьюринга? Очень похоже, что иногда для исполнения алгоритма не требуется его "понимание". А на основе этого можно предположить, что сеть нейронов, составляющая наш мозг, является лишь структурой способной синтезировать некоторый алгоритм. Что в частном случае позволяет этой сети, основываясь на анализе сигналов рецепторов сетчатки и управляя сигналами для движения рук, разработать и исполнить алгоритм решения головоломки.

Но ведь очевидно, что при отмеченной схожести работы структуры ИНС и структуры человеческой памяти у них есть и существенные отличия? Лучше всего эти отличия можно оценить, если экстраполировать найденную выше закономерность в виде утверждения:
Основная деятельность мозга — это синтез и исполнение алгоритмов поведения.Это утверждение многогранно в силу огромного разнообразия используемых человеком алгоритмов поведения. Но атака на это высказывание проста. Потому что это утверждение должно удовлетворять любому демонстрируемому человеком поведению. И поведению, опирающемуся на простой условный рефлекс, и поведению, синтезирующему кварковую модель.
Проверка работоспособности приведенного выше утверждения стала целью формирования теоретической книги ОТА. В статьях «Эволюция памяти» (3.1) и "Эволюция поведения" (5) зафиксированы результаты, наиболее важные в описании работы мозга. В ходе анализа развития алгоритмов поведения разной сложности не раз подтверждено, что интерполяция алгоритма, выполняемая мозгом, использует совсем иной способ регистрации повторимости признаков наблюдаемой закономерности по сравнению со способом ИНС. Для технологии ИНС, которая является наследницей методов кластерного анализа, интерполяции и оптимизации по массиву известных данных, для выявления алгоритмической повторимости требуется статистическая обработка. Для расчета статистики необходимы большие массивы обучающих данных. В то время как для памяти организма основой способа выявления алгоритмической повторимости является запоминание прецедента и повторное его обнаружение. Как мы зафиксировали в статье 1 признак повторимость "подсказывает", что обнаружен алгоритм. Каждый из этих методов (ИНС и память) имеет и достоинства, и недостатки. Память человека скорее представляет эвристический подход к исследованию среды, в то время как ИНС является методом статистической оптимизации. При недостатке обучающих данных эвристика в отличие от ИНС уже может дать решение, но при проверке на большом количестве тестовых данных это решение, вероятно, окажется лишь локальным оптимумом. Конечно, это различие полезно использовать. И, уверен, наиболее эффективные системы ИИ будут использовать симбиоз этих двух подходов. Но вернёмся к языкам программирования.
Так почему языки программирования не стали ИИ?
А почему они должны были им стать? Наверно, спросите Вы. Например, потому что, обобщая, предыдущий раздел можно переформулировать: "Мозг должен уметь синтезировать алгоритм, хранить полученное описание и по необходимости его исполнять". Вероятно, ИИ тоже должен выполнять подобную работу. А какие средства на текущий момент мы используем, чтобы хранить описание создаваемых алгоритмов? Наиболее общеупотребительным средством является именно язык программирования.

И, конечно, не нова идея получения ИИ с использованием возможности создания нового алгоритма путем трансформации алгоритма, записанного на языке программирования. Специально для реализации этой возможности было разработано множество особенных языков программирования. Пожалуй, самый известный из них Lisp. В этом языке текст алгоритма не отличается по структуре от текста, представляющего данные. И существует возможность модификации этой общей структуры в момент исполнения. Казалось бы, вот то, что нужно. Почему же язык с такой возможностью так и не стал системой ИИ? Ответ уже дан чуть раньше. Его только необходимо скомпоновать.
Язык Lisp пока не стал системой ИИ, потому что в нём не реализован достаточно универсальный метод синтеза нового алгоритма, который основывался бы не на уже существующих и описанных алгоритмах, а на выявляемой закономерности внешней среды. При этом даже если мы сейчас добавим в Lisp возможность синтеза аксиомы, например, в виде внешнего модуля ИНС, то всё равно систему ИИ ещё не получим. Потому что сразу появится еще один вопрос. Как преобразовать алгоритм, синтезированный внутри ИНС, в структуру языка Lisp для выполнения впоследствии доступных языку трансформаций? На этот вопрос можно ответить, если получится понять, как алгоритм сборки DeepCubeA объяснить человеку. Для формальной системы, это тождественно решению задачи по переформулированию аксиомы, выявленной в параметрах сложной структуры (например, ИНС), в язык этой формальной системы. Не самая простая задача?
Но способ её решения есть. И с его использованием преодолевается ограничение неполноты формальной системы, доказанное Гёделем. Конечно, мало сказать, что способ существует. А если к этому добавить, что ключевые моменты способа уже описаны? И детали этого описания разбросаны по предыдущим статьям. Нет, они еще не доказательство и не реализация. Здесь каждый волен оценить, есть ли смысл тратить усилия, чтобы попытаться понять и попробовать осуществить описанное. Тот, кому эта затея кажется хоть немного полезной, в комментариях найдет место для критики и вопросов.
Выводы
Да, окончание статьи вышло неожиданным. Головоломка, "родившаяся" из-за резкой остановки повествования в последнем абзаце, показалась мне занятным инструментом. Посмотрим насколько этот инструмент будет полезен для ОТА. Но это не помешает нам вознаградить себя за проделанную в чтении статьи работу. Пусть даже наградой будет лишь похвала и перечисление значимых свершений.
В этой статье мы:

разобрались, как можно сопоставить формулирование аксиом и правил вывода с интерполяционным синтезом алгоритма;
указали на структуру как единственный способ описания алгоритма;
обнаружили, что структура алгоритма может быть сформирована не только языком программирования;
выяснили почему алгоритм, синтезирующий и исполняющий новый алгоритм, плохо соответствует текущему определению термина "Алгоритм";
установили, что, не понимая алгоритма, можно выполнить его исполнение;
сформулировали гипотезу "Об основной функции мозга";
добавили заключительную деталь головоломки "Ограничение Гёделя" к деталям, уже описанным в предыдущих статьях серии.

Было ли перечисленное и на этот раз только игрой?

Спасибо Вам за внимание.
Отзывы
Буду очень благодарен за критику, отзывы, пожелания и предложения, так как они помогают мне скорректировать направление развития работы.
Отдельное волнение у меня есть по стилю повествования и форматированию, используемым в статье (кавычки, абзацы, курсив...). Напишите, пожалуйста, если у Вас есть конструктивные замечания к ним. Можно личным сообщением.
Ссылки

Главная страница и теория работы (GitLab GPL): Проект "Общая теория алгоритмов" (ОТА)
Вводная статья работы "Разрабатываем теорию алгоритмов как проект с открытым исходным кодом". Пожалуйста, не судите строго эту наивную публикацию "сверх-идеи" устаревшей версии 2019 года.
Статьи серии "Что такое алгоритм?!"

№1 "Действие",
№2 "Жизнь",
№3 "Синтез алгоритма запоминанием"
№3.1 "Эволюция памяти"
№3.14 "Обучение"
№5 "Эволюция поведения"
№4 "Математика"
№4.0 "Физика"
№3.25 "Язык"
№5.0 "Философия"

Статьи в хабе "Программирование":

Детская сказка программисту на ночь
Эволюция программного проекта и ООП
Как не понимать принципы развития архитектуры SOLID

Рисунок яблока в статье сформирован сообществом Wikipedia. Лицензия (Creative Commons Attribution-Share Alike 4.0 International)
Иллюстрация "Приглашение к игре". Отсылка к внешнему виду визитки из сериала "Игра в кальмара". Студия Siren Pictures Inc. 2021 г.
Иллюстрация "Строительство моста". Фотография номера Cirque Shanghai: Bai Xi
Иллюстрация "А кролика мы не заметили". Изображение раздела "Фокусы" с сайта kartinkin.net
Иллюстрация "Китайские львы". Фотография программы "Китайского цирка" Фотограф Alenik
Иллюстрация "Аксима — взляд со стороны". Фотография программы Cirque du Soleil (Цирк Солнца).
Иллюстрация "Программа". Фотография программы цирка Чинизелл. Начало 20-го века.
Иллюстрация "Структура". Фотография акробатической пирамиды на репетиции Le Grand Cirque в Sydney Opera House, 2009. (Getty Images)
Видеоиллюстрация "Естественный язык". Видеозапись номера Вячеслава Полунина ("Асисяй") "Телефон". 1981 г
Иллюстрация "Картина сложилась". Картина "Цирк". Художник Сальвадор Дали. 1921 г.
Иллюстрация "Подтверждение абстрактному выводу". Моделирование, показывающее появление бозона Хиггса при столкновении двух протонов.
Иллюстрация "ИНС AlphaGo". Схема партии Го, в которой соревновались AlphaGo и Фань Хуэй (трехкратный чемпион европы). ИНС одержала победу после 165 ходов.
Видеоиллюстрация "Суть алгоритма". Видеозапись кальциевой активности нейронов мозга личинки Danio rerio. Описание эксперимента. Источник Daniil A. Markov, Luigi Petrucco, Andreas M. Kist & Ruben Portugues. A cerebellar internal model calibrates a feedback controller involved in sensorimotor control // Nature Communications. 2021. DOI: 10.1038/s41467-021-26988-0.
Видеоиллюстрация "Алгоритм сборки Кубика-Рубика". Видеозапись телепрограммы «Удивительные люди». Цюэ Цзяньюй. Спидкубер-жонглер.
Видеоиллюстрация "История Lisp и ИИ". Англоязычный авторский youtube канал cryoCode
    Tags: искусственный интеллекттеорема гёделяязыки программированияструктура кодаискусственные нейронные сетиlispаксиомыформальная теория Hubs: AlgorithmsArtificial IntelligenceBrain          


