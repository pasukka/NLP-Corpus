

OpenAI согласна с необходимостью законодательно регулировать развитие ИИ / Habr


               OpenAI согласна с необходимостью законодательно регулировать развитие ИИ  Reading time  
    3 min
   Views  1K Information Security *Cloud services *Artificial Intelligence Social networks and communities IT-companies       Генеральный директор OpenAI Сэм Альтман на слушаниях в Сенате США заявил, что развитие искусственного интеллекта необходимо регулировать законодательно. Он предложил создать агентство, которое будет лицензировать инструменты для ИИ и ограничивать возможность чат-ботов типа ChatGPT.«С развитием технологии мы понимаем, что люди взволнованы тем, как она может изменить наш образ жизни. Мы тоже взволнованы. Если эта технология пойдёт по неверному пути, она может пойти совсем не так», — пояснил Альтман. Он добавил, что, по его мнению, индустрия ИИ может нанести «существенный вред миру».Глава OpenAI отметил, что, по мнению разработчиков, преимущества, которые дает ИИ, превышают риски, но обеспечение безопасности важно и для деятельности разработчиков.Альтман предложил создать американское или глобальное агентство, у которого были бы полномочия лицензировать самые продвинутые системы ИИ. По его мнению, эта организация могла бы обеспечивать соответствие стандартам безопасности, а также отзывать лицензии в случае необходимости.Альтман считает, что подобный регулятор обязательно должен ввести определённые ограничения на развитие ИИ-систем и чат-ботов на их основе. Например, требовать немедленной блокировки моделей ИИ, которые способны «самовоспроизводиться и самоэксфильтрироваться в дикой природе». В начале апреля власти США заявили, что опасаются массового использования чат-ботов с ИИ типа ChatGPT для совершения преступлений и распространения ложной информации. Администрация президента США рассматривает с регуляторами возможность ограничения работы систем, основанных на искусственном интеллекте, в рамках выпуска на открытый рынок только сертифицированных чат-ботов. Национальное управление по телекоммуникациям и информации при Министерстве торговли США направило официальный публичный запрос по поводу так называемых «мер подотчётности», включающих вопрос о том, должны ли потенциально опасные новые модели ИИ проходить сертификацию перед выходом на рынок. 13 апреля глава OpenAI сообщил, что инженеры компании разрабатывают языковую модель GPT-5, но пока ещё не начинали обучение и не планируют приступать к этому в ближайшее время. При этом глава компании обратил внимание на то, что продолжаются улучшения GPT-4. В частности, сотрудники OpenAI работают над безопасностью. 14 апреля Европейский совет по защите данных (European Data Protection Board, EDPB) организовал рабочую группу, которая будет заниматься вопросами использования чат-бота ChatGPT. Ожидается, что она разработает политику конфиденциальности для систем искусственного интеллекта.Ограничения в развитии чат-ботов с ИИ 14 марта OpenAI представила новую модель ИИ интерпретации изображений и текста GPT-4, которую компания назвала «последней вехой в своих усилиях по расширению масштабов глубокого обучения». GPT-4 создала за несколько десятков секунд по короткому ТЗ рабочую версию Pong, Asteroids, Breakout и Pac-Man, а также написала простую игру на JavaScript, в которой можно «играть лесными эльфами, охраной дворца и злодеями» и «грабить корованы» и даже помогла «превратить» $100 в $25 тыс. В конце марта некоммерческая организация Future of Life опубликовала письмо, в котором глава SpaceX Илон Маск, соучредитель Apple Стив Возняк, филантроп Эндрю Янг и ещё около тысячи исследователей искусственного интеллекта призвали «немедленно приостановить» обучение систем ИИ «более мощных, чем GPT-4». Организация проблем этики в IT Center for Artificial Intelligence and Digital Policy направила жалобу против OpenAI в Федеральную торговую комиссию США. Она потребовала запретить компании развёртывать новые модели GPT, а также попросила регулятора начать расследование в отношении OpenAI из-за выпуска GPT-4, чтобы выяснить, не нарушает ли он законы США и других стран. В начале апреля группа специалистов по этике AI выступила с ответом на письмо Future of Life. Они скептически отнеслись к призыву взять шестимесячную «паузу» в развитии AI и обучении систем, «более мощных, чем GPT-4», раскритиковали текст письма за акцент на гипотетических будущих угрозах, связанных с развитием искусственного интеллекта. По их мнению, реальный вред может принести использование AI-технологий уже сегодня. Билл Гейтс считает, что призыв приостановить работу над нейросетями мощнее GPT-4 на полгода не решит проблемы. По его мнению, вместо ввода моратория необходимо определить проблемные области и заняться ими.      Tags: иичат-ботограничениерегулированиезапретchatgptopenaiАльтман  Hubs: Information SecurityCloud servicesArtificial IntelligenceSocial networks and communitiesIT-companies          


