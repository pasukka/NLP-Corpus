

Понимание компьютером текста: действительно ли всё так плохо? / Habr


               25  August  2011 at 17:04  Понимание компьютером текста: действительно ли всё так плохо? Artificial Intelligence  
        Sandbox
           Совсем недавно на Хабре появился пост, в котором автор уверенно заявляет о том, что компьютер никогда не сможет понимать текст так, как его понимает человек. В доказательство он приводит ряд непосильных для машины задач, делая упор на отсутствие эффективных алгоритмов и невозможность моделирования полноценной системы, в которой были бы учтены все возможные варианты построения текста. Однако действительно ли всё так плохо? Правда ли, что для решения подобных задач нужны невероятные вычислительные мощности? И в каком вообще состоянии находится область обработки текстов на естественных языках? 

А что вообще значит «понимать»?

Первое, что меня смутило, — это сам вопрос — сможет ли компьютер когда-нибудь понимать текст так, как его понимает человек. А что, собственно, значит «понимать как человек»? Или даже не так, что вообще значит «понимать»? В книге Data Mining: Practical Machine Learning Tools and Techniques авторы задаются схожим вопросом — что значит «быть обученным». Допустим, что мы применили к «интерпретатору» некоторую технику обучения. Как проверить, обучился он или нет? Если студент ходил на все лекции по предмету, это ещё не значит, что он его выучил и понял. Чтобы проверить это, вводят экзамены, где студента просят решить некоторые задачи по теме предмета. То же самое и с компьютером — узнать обучился ли он (понял ли он текст) можно только проверив, как он решает конкретные прикладные задачи — переводит текст, выделяет факты, выдаёт конкретное значение многозначного слова и т.д. В таком ракурсе понятие смысла вообще теряет первостепенное значение — смыслом можно считать просто какое-то состояние интерпретатора, в соответствии с которым он обрабатывает текст. 

Многозначные слова

Далее автор оригинальной статьи приводит пример перевода предложения «Первым Николай распечатал письмо от Сони», указывая на несколько возможных вариантов перевода слова «распечатал» с совершенно разными значениями. Человек может легко понять, о чём идёт речь, но может ли машина? 

Для того, чтобы ответить на этот вопрос, рассмотрим, как сам человек принимает решение о том, в каком смысле употреблено данное слово. Думаю, все согласятся, что в первую очередь при решении такого рода задач ориентируемся на контекст. Контекст может быть представлен явно — в виде предложений, обрамляющих данное, либо неявно — в виде совокупности знаний о данном предложении (в нашем случае — знание о том, что предложение взято из романа «Война и Мир», знание о времени, когда происходит сюжет, и знание о состоянии прогресса на тот момент). 


Для начала рассмотрим первый вариант — использование контекстных предложений. Предположим, что у нас есть две пары предложений: «Первым Николай распечатал письмо от Сони. При свете лучины читать его было сложно» и «Первым Николай распечатал письмо от Сони. Принтер барахлил, поэтому местами были понятны не все символы». Во втором предложении каждой пары присутствуют ключевые слова, которые позволяют нам однозначно идентифицировать смысл слова «распечатал» в предыдущем предложени — в первом случае это «лучина», во втором — «принтер». Вопрос: что мешает компьютеру проделать тот же манёвр, чтобы узнать настоящий смысл слова под вопросом? Да ничего. На самом деле системы по определению значения слова уже давно используются на практике. Так, например, индекс tf-idf широко используется в поисковых движках при вычислении релевантности. Как правило, собирается информация о совместной встречаемости слов («распечатывать» и «лучина», «распечатывать» и «принтер») и на её основе выбирается более релевантный документ или более точный вариант перевода слова. 


С неявным контекстом, то есть с набором знаний о обстоятельствах, всё несколько сложней. Простым сбором статистики тут не обойдёшься — нужны именно знания. А что вообще такое знания, как их можно представить? Одним из способов представления являются онтологии. В простейшем случае онтология — это набор фактов вида <Subject, Predicate, Object>, например, <Николай, является, Человек>. Построение самих онтологий даже для конкретной предметной области — это дело, мягко говоря, немаленькое. Немаленькое, но не невыполнимое. Есть ряд инициатив, таких как Linked Data, в рамках которых люди собирают с миру по нитке и строят паутину взаимосвязанных понятий. Более того, существует ряд вполне успешных наработок по автоматическому извлечению фактов из текста. Т.е. из предложения «Первым Николай распечатал письмо от Сони» можно автоматически вывести факты <Николай, распечатал, письмо>, <Письмо, от, Сони> и т.д. В качестве open-source примера таких разработок может служить Stanford Parser, который довольно неплохо понимает структуру предложения на английском языке. А некоторые компании, такие как InventionMachine (ссылку вставлять не буду, ибо и так реклама) вообще строят свой бизнес на системах извлечения фактов. 

Однако я отвлёкся. Итак, будем считать, что у нас уже есть более или менее полная онтология для нашей предметной области. Для простоты также предположим, что собрана она людьми, поэтому слово «распечатать» в ней представлено несколько раз — по одному разу на каждый смысл этого слова. В смысле «открыть» это слово может образовывать факты <[Кто-то], распечатал, посылку>. В смысле «пустить на печать» оно может быть использовано в фактах <распечатать, на чём, принтер>. Наконец, предположим, что в нашей онтологии уже присутствуют знания об обстоятельствах. В таком случае задача определения правильного смысла слова сводится к отображению всех фактов предлжения на онтологию для всех возможных значений слова «распечатать» и выбору того значения, в окружении которого больше всего известных фактов (как фактов об обстоятельствах, так и фактов, извлечённых непосредственно из предложений). 


Перед тем, как идти дальше, сделаю несколько выводов: 


1. Статистика является мощным инструментом анализа текста.

2. Извлечение знаний (фактов) из текста является реальностью.

3. Создание базы знаний о предметной области является сложной, но выполнимой задачей. 

Другие задачи

Далее автор статьи приводит, на мой взгляд довольно сумбурно, ряд конкретных задач, которые компьютеру якобы абсолютно неподвластны. Спорить не буду, некоторые задачи действительно довольно сложны. Сложны, но не неподвластны. Ниже в произвольном порядке будут приведены упомянутые задачи с возможными вариантами их решения, но сначала ещё несколько слов о самой дисциплине обработки естественных языков (natural language processing). 


С точки зрения NLP, текст представляет из себя набор признаков. Этими признаками могут быть слова (корни и формы слов, падеж, регистр букв, часть речи), знаки препинания (особенно те, что ставятся в конце), смайлы, предложения целиком. На основании этих признаков могут строиться и более сложные — n-граммы (последовательности слов), оценочные группы (appraisal groups, те же последовательсности, но с указанием оценки, например, «very good»), слова из заданных словарей. И даже более сложные — аллитерация, антонимия и синонимия, омофоны и т.д. Всё это может быть использовано против вас в суде в качестве индикаторов при решении тех или иных задач обработки текста. 


Итак, сами задачи. 

Определение настроения текста

Вообще автор предложил не совсем понятное деление — текст весёлый и текст грустный. В голову приходят три варианта классификации: 


1. Текст оптимистический/пессимистический. 

2. Положительный/отрицательный (например, отзыв).

3. Юмористический/серьёзный. 


Так или иначе, это задача классификации, а значит для неё могут быть использованы стандартные алгоритмы, такие как Na