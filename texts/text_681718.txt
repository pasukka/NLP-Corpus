

Data Science Pet Projects. FAQ / Habr


              11  August   at 14:00  Data Science Pet Projects. FAQ Open Data Science corporate blog Data Mining *Machine learning *Project management *Artificial Intelligence       Привет! Меня зовут Клоков Алексей, сегодня поговорим о пет-проектах по анализу данных. Идея написать эту статью родилась после многочисленных вопросов о личных проектах в сообществе Open Data Science (ODS). Это моя третья статья на Хабре, до этого делал разбор алгоритма SVM и рассказывал о крутом NLP курсе от ребят из DeepPavlov. В этой статье вы найдете идеи для новых петов и полезный код. Итак, разберем частые вопросы и дадим определение пет-проекта:

Зачем делать пет-проекты?
Из каких этапов может состоять разработка пет-проекта?
Как выбрать тему и найти данные?
Где найти вычислительные ресурсы?
Как завернуть работающие алгоритмы в минимальный прод?
Как оформить презентабельный вид проекта?
Как и зачем искать коллабораторов?
Когда проходит ODS pet project хакатон?
Где посмотреть примеры пет-проектов и истории участников ODS?


Data science pet project – это внерабочая активность, целью которой является решение некоторой задачи с помощью обработки данных, улучшающая ваши профессиональные навыки
1. Пет-проектами стоит заниматься, чтобы

Самостоятельно пройти все этапы разработки DS проекта, от сбора данных – до прода. Так сказать, тренироваться быть пресловутым full stack ml engeener’ом.
Поработать с "плохими" реальными данными, которые могут сильно отличаться от игрушечных датасетов (самый известный пример идеальных данных – Titanic)
Найти работу при отсутствии опыта. Ну вы знаете этот замкнутый круг, когда нужен опыт работы для получения первого места работы.
Перекатиться в новую область DS. Вот надоело скрести ложкой по табличным данным – вы раз, и в computer vision. 
Приобрести широкий ML кругозор, “покрутив” разные домены данных. Часто подходы обработки данных кочуют из одной области в другую. Например, трансформеры из NLP пришли в CV.
Подготовить пайплайны решений для будущих хакатонов и рабочих проектов.
Упростить себе технический собес или получить дополнительные бонусы во время отборочных раундов для получения оффера.
Научиться вкатываться в новый проект за короткий срок.
Подтянуть SoftSkills. Например, научиться грамотно рассказывать другим людям о своих инициативах. В своем проекте вы “и спец, и на дудке игрец”, а также PO, CTO, CEO (и немного HR).
Приобщиться к open-source деятельности или попытать удачу в стартап-деятельности. Может быть, ваш проект окажется полезным для человечества или монетизируемым? Например, подобным образом появились Xgboost, HuggingFace и Albumentations.


2. Этапы разработки проекта

Поиск темы и сбор данных.
Разметка данных под задачу. Можно размечать самостоятельно или обратиться к сторонней помощи. Как мне известно, некоторые CEO компаний-разметчиков предлагали безвозмездную помощь, если вы не преследуете коммерческих целей.
Исследование (aka Research) – включает в себя анализ данных, проверка нескольких гипотез, построение ML моделей. В этом разделе можно было бы говорить о полезных инструментах, таких как DVC, Hydra, MLFlow, WandB – но оставлю это на факультативное изучение читателей.
Внедрение построенных моделей в прод.
Оформление репозитория.
Пиар, сбор фидбека, привлечение коллабораторов, техническое улучшение проекта, углубление/расширение темы.

3. Поиск темы проекта и данных для анализа

В пет-проектах по анализу данных тема неразрывно связана с данными. Эти два объекта (тема и данные) редко лежат вместе “на блюдечке с голубой каемочкой”. На мой взгляд, для успешного самостоятельного поиска необходимо несколько раз повторить следующую процедуру:
Сначала необходимо зафиксировать один из двух объектов: тему или данные. После, на основе зафиксированного объекта, найти второй объект
Сбор данных может принимать разный вид, например: 

самостоятельное накопление;
выгрузка с некоторой платформы;
парсинг интернет-страниц;
объединение существующих датасетов, найденных на kaggle, papers-with-code, github, хабр1, хабр2 и т.д.;
искусственная генерация;
для проектов по компьютерному зрению может пригодиться эта статья.

Поиск темы на основе данных может представлять такие активности, как:

анализ существующей разметки в данных;
тестирование продуктов-конкурентов;
общение с потенциальными пользователями будущего продукта;
“холодные звонки”.

Примеры 1 и 2 демонстрируют фиксирование темы, а после — поиска данных. Примеры 3 и 4 демонстрируют фиксирование данных, а после — поиска темы.

Пример №1: Вы увлекаетесь какой-либо деятельностью, например, бегом (подставить свое), поэтому фиксируем чуть более общую тему – физические упражнения (подставить свое). Какие данные накапливаются в процессе того, как кто-то занимается физическими упражнениями? Если данные будут найдены/собраны – можно сделать предиктивную аналитику или видео-анализ происходящего вокруг.


__поиск данных для примера 1

существуют датчики, которые определяют шаги, пульс, глубину дыхания, частоту сердцебиения, температуру тела. Тогда данными будут являться сигналы с датчиков, табличные данные, временные ряды. Хорошо, обвешиваемся датчиками для записи данных или скачиваем приложение, которое выполняет подобные функции;
кто-то снимает на видеокамеру себя или окружающее пространство во время тренировок. В этом случае данные будут являться видеофрагменты. Окей, для сбора данных вешаем камеру – записываем много видео вашего процесса;
а, собственно, почему нам нужно собирать данные самим? Может быть, уже кто-то сделал это? Поиск показывает, что существует датасет, собранный врачами и пациентами, которые были обвешаны датчиками: A database of physical therapy exercises with variability of execution collected by wearable sensors.



Пример №2: А давайте попытаемся найти нерешенную проблему? – некоторое время назад видел обсуждение, что для распознавания русской речи (ASR/STT) есть открытое решение, но нет хорошего OCR движка (подставить свое). Это нужно исправлять, фиксируем тему – open-source pretrained ruOCR с возможностью легкого дообучения на кастомном датасете (подставить свое). Существующие решения, такие как EasyOCR из OpenCV, teserract, ABBYY, PolyAnalyst, работают не для всех доменов данных, обернуты в неудобный сервис или вообще не являются открытыми и бесплатными. Поиск подходящих данных для русского языка дает ответ, почему эта проблема еще не решена – данных мало, но это не должно нас останавливать:


__поиск данных для примера 2

можно предобучать модель, используя датасеты на других языках или синтетику, а после тюнить на небольших датасетах для русского;
для генерации синтетики можно воспользоваться чужими пет-проектами для генерации русских слов на картинке, например, репо;
для генерации синтетики можно использовать OCR датасеты других языков, заменяя иностранные слова на русские каким-нибудь conditional GAN’ом (этот подпункт тянет на отдельный пет-проект!).



Пример №3: Некоторым случайным образом вам попался датасет – вы поучаствовали в kaggle соревновании с хорошими данными или вы увидели новость, что какая-то группа энтузиастов/компания сделала открытым свой качественный датасет. Например, публичные датасеты Толоки, корпус русского текста Taiga, корпус русской речи. Ок, фиксируем датасет – Тайга (подставить свое). Теперь думаем над темой проекта.


__поиск темы для примера 3

Text classification?
Unsupervized style transfer? – как перефразировал бы один автор цитату другого, используя своих речевые обороты?
Генерация стихов на определенную тему? В корпусе тайги есть много стихов.



Пример №4: Предыдущий пример можно немного изменить: не ждать, когда на вас свалится качественный датасет на какую-нибудь тему, а сразу поискать датасет на интересующую тему. Если вы хотите, например, прокачаться в в компьютерном зрении (подставить свое), то можно найти и зафиксировать данные для задачи распознавания позы человека/предмета (подставить свое). После, придумать тему:


__поиск темы для примера 4

видеоаналитика своих физических тренировок;
взаимодействие с виртуальной клавиатурой через камеру или лидар, вдохновленное этим проектом;
управление компьютером с помощью движений ладонью (2D — туториал; 3D — видео);
язык жестов --> речь\текст; речь\текст --> язык жестов.


4. Где найти вычислительные ресурсы
Если вы "сильный и независимый датасаентист" со своей GPU-картой и 32Гб RAM, то этот раздел не для вас. Но тем, кто не имеет хорошей вычислительной машины, не стоит отчаиваться:

существуют облачные бесплатные (и платные) вычислительные ресурсы, например: kaggle kernel, google colab;
можно найти "сильного и независимого датасаентиста" и объединиться с ним в команду;
для обработки небольших ЧБ-картинок (MNIST-подобные датасеты) можно обойтись без GPU;
для обработки RGB-картинок классическими алгоритмами CV (но не всеми) не требуется GPU;
для обработки табличных данных часто хватает ML алгоритмов (без DL), которые отлично обучаются без GPU;
большой датасет табличных данных не следует пытаться запихнуть целиком в небольшую RAM. В этом случае рекомендуется разбить датасет несколько частей, для каждой части создать модельку. После усреднить предсказания моделей с помощью ансамбля. Существуют и другие подходы/инструменты, например, Dask;
существуют компании, безвозмездно предлагающие вычислительные ресурсы для некоммерческих проектов.


5. Минимальный прод
Если модели построены, то хочется начать ими пользоваться через удобный интерфейс и поделиться созданным продуктом с другими — демонстрация работы вашего проекта очень важна. Огонь, если вы можете показать демку в любой момент, например, другу в лифте или техкоманде на собесе. В идеале рекомендуется довести выкатку в «прод» до приложения, работающего 24/7. Приведу некоторые примеры инструментов:

Telegram bot
Streamlit
Gradio
Heroku
Flask на личном или виртуальном арендованном сервере (VPS)

Преимущество Streamlit/Gradio заключается в многофункциональном UI и бесплатном хостинге от авторов библиотеки или Huggingface. А самый простой и быстрый путь, на мой взгляд, это telegram bot. Библиотека telebot предоставляет очень удобное API для программирования действий бота. Далее приведу python-код, который при получении текстового сообщения пользователя отправляет в чат температуру видеокарт или ядер процессора компьютера, на котором он запущен. Этот шаблон легко переделать под ваши нужды, пользуйтесь и передавайте другим:
import psutil #pip install psutil
import telebot #pip install pyTelegramBotAPI
token = '___your___tg_bot___token___'
bot = telebot.TeleBot(token)
@bot.message_handler(commands=['start'])
def start_message(message):
    bot.send_message(message.chat.id, 'Напиши: gpu или cpu')
@bot.message_handler(content_types=['text'])
def send_text(message):
    action_function(message)
def action_function(message):
    if message.text.lower() == 'gpu':
        comand = !nvidia-settings -q GPUCoreTemp
        output = [str(x).strip() for x in temp if 'gpu:' in x]
        bot.send_message(message.chat.id, output)
    elif message.text.lower() == 'cpu': 
        output = str(psutil.sensors_temperatures()['coretemp'][1:])
        bot.send_message(message.chat.id, output)
    else:
        bot.send_message(message.chat.id, 'unknown command') 
bot.polling()

6. Как оформить презентабельный вид проекта
Рекомендую выложить материалы проекта, которые в будущем могут быть полезны вам и другим людям, в открытый доступ (например, на github) и хорошо задокументировать все наработки и результаты, чтобы:

сохранить код вне вашей вычислительной машины
успешно демонстрировать ваш проект другим людям
освежить в памяти этап, на котором вы остановились (при временной заморозке проекта)

Оформление репозитория делайте таким, чтобы “было не стыдно показать”. Все описания и инструкции должно быть однозначными, полными, воспроизводимыми. Предлагаю список пунктов (некоторые опциональны), которого старался придерживаться для оформления своих проектов: пример1, пример2.

описание задачи;
описание продукта, который решает задачу;
описание окружения (requirements/Docker/etc) с инструкциями установки ;
скрипты для получения данных и ссылка на данные с разметкой;
пайплайны ML экспериментов с инструкциями воспроизведения (работа с данными, обучение, валидация, визуализация графиков/дашбордов);
скрипты продукта с инструкциями полного запуска;
ссылка на веса моделей, которые используются в проде продукта;
демки: схемы, картинки, гифки;
лицензия;
всё, что считаете полезным для вас/других.


7. Как и зачем искать коллабораторов
Бесспорно, можно работать над проектом и одному. Но задача, на которую вы можете замахнуться, может оказаться огромной, неподъемной для одной пары рук. Каждая подзадача может являться отдельным проектом, может бросать вызов вашей мотивации и отнимать несколько недель размеренной работы — в этом случае вам не обойтись без таких же энтузиастов, как и вы. В команде единомышленников работать над проектом получается продуктивней, веселее и динамичней. Совместное обсуждение проблем и разносторонний подход к поиску решений помогает преодолеть любые трудности. В команде появляется ответственность к дедлайнам, так как работа товарища может зависеть от ваших результатов. Во время работы в команде стараюсь придерживаться правила:
Разобрался сам – объясни товарищам
Чтобы привлекать коллабораторов, нужно уметь коротко рассказывать о вашем проекте. В этом очень помогает заранее подготовленная речь, презентация и качественное оформление репозитория (см. прошлый раздел). Подход с поиском сокомандников может работать и в другую сторону: если не удается определиться со своим проектом, то почему бы не присоединиться к другому интересному пету? У меня получалось найти единомышленников:

в slack ODS: #ods_pet_projects (для петов) и #_call_4_collaboration (для коммерческих);
в ods tg чат, посвященный пет проектам;
в tg чатах по интересам, например, NLP, RL_pet и RL;
на ODS pet project хакатоне (см. cледующий раздел).

8. Когда проходит ODS pet project хакатон
Каждый год, в конце зимы мы с друзьями ходим в баню проходит ods pet proj хакатон, посвященный личным проектам. Энтузиасты объединяются в команды, 2 недели активно работают над своими петами, а после – рассказывают друг другу о результатах, делятся наработками, находят с единомышленников и отлично проводят время. Ну а бонусом – организаторы вручают топовый ODS мерч тем, кто хорошо продвинулся в проекте (правила могут меняться, уточняйте). Чтобы не пропустить следующий хакатон – залетайте в tg чат, активно напоминайте о хакатоне, предлагайте свои идеи и помощь в его организации.

9. А теперь примеры пет-проектов, истории от участников ODS

1. Зарождение HuggingFace
Сообщение из чата DL_in_NLP:
Вообще я собственными глазами наблюдал, как появился HF (без иронии). Дело было на EMNLP 2018 в Брюсселе. В чатике конференции то ли Вулф, то ли ещё кто-то, не помню уже, написали что-то вроде "ребята, мы хотим по пиву, а потом есть идеи покодить вечерком, кто с нами?". "Покодить вечерком" – это под впечатлением от доклада гугла с презентацией BERT на этой же конференции попробовать переписать его на PT. Ребята пыхтели пол-ночи и потом ещё пол-дня и появился pytorch-pretrained-bert. Ну а дальше всем известно)


2. ODS ник: yorko
Юрий сначала работал над барометром тональности новостей о криптовалютах, это был первый ML-проект в стартапе. Затем проект превратился в командный пет в рамках курса одс по MLOps. В хабр-статье yorko рассказывает как про технические, так и про организационные аспекты командной работы над пет-проектом.


3. ODS ник: laggg
Летом 2020 в канале петпроетов ods рассказывал о создании ML-агента для игры surviv.io на стыке CV и RL алгоритмов. Тогда я обещал поделиться наработками с сообществом, как только что-то годное получится. Кажется, такой день настал осенью 2021 года. Xочу рассказать о первом релизе нашего ML агента и дать возможность любому человеку запустить нашего бота и понаблюдать за его поведением. Что зарелизили: ML-бот, который умеет передвигаться, основываясь на входящем кадре-картинке и на векторе-состоянии инвентаря. Вот репозиторий с подробными инструкциями и описанием проекта.
Зимой 2022 года поучаствовал в ODS pet proj хакатоне, смог найти классных единомышленников, с которыми провели ресерч и сделали нейронный энвайрмент, в котором обучили RL агента сближаться с предметами в этой же игре. Вот репозиторий проекта с красивыми гифками.


4. ODS ник: copperredpony
Мне мой небольшой пет помог (как мне кажется) устроиться на первую работу. После неудач в прохождении собесов на ML позиции, я решила сделать упор на изучение CV но через pet project. Взять интересную тему и учить только то что понадобиться для его выполнения. В итоге на практике получилось прокачаться лучше чем только по статьям и курсам. А во вторых с пет проджектом на собесах меня больше спрашивали про пет проджект (другого опыта у меня не было) и меньше по техническим вопросам. Я радостно рассказывала как косячила и исправляла свои ошибки, а интервьюеры радостно слушали. У меня был пет про классификацию птичек по фотографиям, обёрнутый в телеграмм бот. Он получился довольно всратый и я его забросила как только нашла работу. Но по хорошему надо вернуться и переделать.


5. ODS ник: ira_krylova
Два года делала ГИС проектики в формате хобби, потом оформила в блог на медиуме и стала всем пихать. Люди действительно на них смотрели, но я отметила, что они запоминали не техническую часть, а тематическую, и вот эти темы оказывались кому-то близкими. Так было несколько раз. Когда подавалась на текущую работу, тоже этот блог все показала, и думаю это сильно помогло — коллеги обсуждали мои проекты между собой и со мной. Оказалось, что несколько из моих проектов совпадают с тем, чем компания занимается. Описание проекта в medium-статье 


6. ODS ник: erqups
Не был никогда в позиции джуна, который ищет работу, как то само срослось, но в целом пет-проекты это хороший способ систематизировать определенные знания у себя в голове и при этом пошарить опыт, авось кому и поможет. При этом любой результат будет полезен — отреспектуют, значит все ок, покритикуют — еще лучше, ты переосмыслишь свой подход, доработаешь и на реальном проекте будет сильно проще. Со всех сторон профит. Например, когда экспериментировал с подходами к инференсу сеток на CPU написал вот эту статью и получил свои первые плюсики на хабре.


7. ODS ник: as_lyutov
В октябре 2021 г. я закончил обучение в онлайн-школе по направлению data science. Уже тогда я четко понимал, что мне нужно хорошее портфолио проектов, чтобы претендовать на позицию джуна. В комьюнити ODS было свое направление по пет-проектам для начинающих специалистов, но идеи не находили отклика.
Осенью я поучаствовал в хакатоне Райфайзен банк по предсказанию цен на недвижимость. Участвовал соло, вошел в топ-50, получил хороший опыт и проект в портфолио. Посмотрел на вакансии банка и увидел привлекательную позицию quantitive research analyst, на которой нужно было создавать рекомендательный сервис на основе сделок клиентов. Так и родилась идея пет-проекта.
С 25 лет я активно инвестировал и тема была для меня близка. Для реализации нужно было собрать два датасета: один из сделок пользователей, второй из фундаментальных показателей ценных бумаг и фичей на их основе. Первый датасет синтетический. Найти приватные данные сделок пользователей сложно, я воспользовался статьей Т-Ж о портрете розничного инвестора в России и составил выборку из рандомных пользователей, которые раз в неделю совершали сделки по бумагам S&P-500 и топ-10 из индекса биржи SPB. Кол-во сделок также было рандомно, но ограничивалось целым числом в диапазоне от 1 до 7 в неделю. Второй датасет из акций S&P-500 собрать оказалось гораздо проще. Я давно пользовался сервисом finviz для оценки акций и спарсить его с помощью паука оказалось несложно. Данные из обоих датасетов я сохранял в Mongo DB. После этого я определил основные метрики, построил основные рекомендательные модели (ALS, Item-Item recommender, Cosine Recommender, Tf-idf) и оценил метрики по бейзлайнам.
Вся работа заняла примерно 1.5-2 месяца. Закончил я примерно к середине февраля. А через неделю наша жизнь изменилась от слова совсем. Поэтому словил 2 фриза от компаний, в которые подавал свой пет-проект. В середине марта я прошел отбор на позицию дата-аналитика. Пет-проект сыграл большую роль на этапе отбора: будущий начальник был приятно удивлен, что я знаком с Mongo, а опыт участия в хакатонах помог с решением тестового задания.
В планах потренировать на пет-проекте навыки MLOps, обогатить его данными из других источников, переделать синтетический датасет со сделками юзеров. Сейчас проект на паузе из-за высокой нагрузке на работе. Такие проекты помогают начинающим специалистам систематизировать свои навыки и обкатать их на реальных задачах. К тому же на интервью не нужно выдумывать повод для разговора, достаточно обсудить свой оригинальный пет-проект.


8. ODS ник: artgor
5 лет назад делал пет-проект, который много раз помогал на собесах. Описание проекта в хабр-статье


9. ODS ник: Sergei
Два года пилил пет-проект про GAN/Deepfake, в процессе хорошо прокачался в в DL, описание проекта в хабр-статье.


10. ODS ник: poxyu_was_here
Демка. Хочу немного рассказать о нашем стартапчике PTF-Lab (previously known as Punch To Face; currently known as Path To Future lab). Наше основное направление это virtual advertising и AR в спортивных и киберспортивных трансляциях. У PTF было очень много pivot'ов, тупок, взлётов, падений, и так далее. Начали мы проект в далёком 2014 году вместе с моим другом детства. Наша история, очень кратко:
1) 2012-2013: а как бы поприкольнее снимать и показывать спортивные мероприятия? (с) мой друг детства и партнёр в ПТФ.

2) 2014: неудачные поиски единомышленников; начало изучения программирования, проектирования; работа над первым прототипом.

3) 2015: первый прототип; неудачные поиски единомышленников; в нас поверил начальник лаборатории робототехники курчатовского института и сказал "а почему бы и нет?"

4) 2016-2017: попытки запартнёриться c чеченцами и дагестанцами; здравствуй machine learning; первый поход к бизнес-ангелу (второй прототип; третий прототип).

5) 2018: впервые в венчурном фонде (without success); вступление в ODS (historic moment); deep learning пошёл в дело.

6) 2019: появляется много желающих поконтрибьютить и посталкерить в нашей команде; много СV&DL экспериментов; выступление на датафесте в Одессе; российские MMA-организации делятся с нами данными и пускают в режиссёрские будки во время мероприятий.

7) 2020: наш Differentiable Mesh Renderer (a.k.a. Wunderwaffe) на pytorch; новая демка-прототип; нам пишут из UFC (крупнейшая организация по смешанным единоборствам) и мы им питчим.

8) 2021: первые небольшие коммерческие проекты; полное выгорание (у меня точно) и тихая смерть команды (но не фаундеров — слабоумие и отвагa); а потом находим коммерческого партнёра и регистрируем компанию на Кипре.

9) 2022: сбор команды, организация процессов, закупка оборудования; новая демка в real-time.

10) P.S. — never give up и только вперёд.
     Tags: open data scienceodsods.aipet projectpet-projectпет проектпет-проектpet-проектыdata sciencedata miningmachine learningмашинное обучение Hubs: Open Data Science corporate blogData MiningMachine learningProject managementArtificial Intelligence          


