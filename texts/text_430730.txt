

Чем занимаются в департаменте R&D ABBYY: NLP Advanced Research Group / Habr


               22  November  2018 at 12:55  Чем занимаются в департаменте R&D ABBYY: NLP Advanced Research Group ABBYY corporate blog Machine learning *Natural Language Processing *      Чем занимаются в департаменте R&D в ABBYY? Чтобы ответить на этот вопрос, мы начинаем серию публикаций о том, как наши разработчики создают новые технологии и совершенствуют существующие решения. Сегодня расскажем про направление Natural Language Processing (NLP). 


Мы в ABBYY занимаемся исследованиями в сфере обработки естественного языка и беремся за сложные научные задачи, для которых пока нет готовых решений. Так мы создаем инновации, которые ложатся в основу продуктов и помогают нашим заказчикам, да и нам двигаться вперед. Кстати, 24 ноября на лекции в Школе глубокого обучения при МФТИ руководитель NLP Advanced Research Group в департаменте R&D ABBYY Иван Смуров расскажет, какие в мире есть задачи по анализу текста и как современные нейросети позволяют их решать. А в этом посте Иван рассказал нам о трех задачах, которыми занимается сейчас. 


Коллегам из NLP Advanced Research Group важно выбирать изолированные задачи, то есть не очень строго связанные с существующими технологиями и решениями ABBYY. Иногда наши сотрудники сами находят такие задачи, иногда о них рассказывает наш R&D и просит помочь с их решением, а затем и с публикацией результатов в научных журналах. Итак, первая задача.

Саммаризация: не сложнее, чем пересказ?

Эта техника анализа текста позволяет превратить его в пересказ или аннотацию. В таком виде люди уже давно используют саммаризацию. Мы в ABBYY пробуем применять техники саммаризации в расширенном смысле: мы пытаемся решить те задачи, которые традиционно с помощью саммаризации не решаются, например, получить интегральные характеристики текста и выделить события, которые происходят в тексте. 


Саммаризация может упростить традиционный pipeline. Например, сейчас, чтобы извлечь из документа названия компаний-сторон договора, традиционно решается много последовательных задач NLP, от выделения сущностей до фильтрации извлеченных фактов. Все эти задачи зависят друг от друга, а главное, каждая из них требует своей эталонной разметки. А создание разметки в машинном обучении – это одна из самых дорогих вещей.


С помощью саммаризации можно сделать извлечение фактов end-to-end, то есть без промежуточных этапов, подзадач и разметок. Причем это будет так же просто и быстро, как пересказ текста. А еще, возможно, дешевле. 


Подробнее о саммаризации можно прочитать в нашей статье:
 Как сделать из нейросети журналиста, или «Секреты сокращения текста на Хабре без лишних слов»

Синтаксический парсинг: в поисках эллипсиса


Помните, в школе мы делали синтаксический разбор предложения: подлежащее, сказуемое, дополнение? В лингвистическом смысле разбор предложения более сложный и подробный. Все можно изобразить как, зависимость, где главное — предикат или глагол, и от него зависят подлежащее, дополнения и др. Таким разбором предложения в современных программах занимается синтаксический парсер. Обычно синтаксический парсер немалую часть времени тратит на создание и отбрасывание синтаксических нулей, которые появляются при эллипсисе. 

Приведем пример: Миша съел грушу, а Маша – яблоко. И в устной, и в письменной речи мы просто пропускаем глагол «съела» и смысл для нас не меняется. Но для компьютерной лингвистики определение синтаксических нулей — это сложная проблема. Типов эллипсиса много, они могут быть в разных местах предложений. В результате парсер вынужден перепроверить много гипотез: а был ли тут нуль, который на самом деле не нуль? 


Такая перепроверка усложняет и замедляет работу парсера, кроме того, на это тратится много вычислительных мощностей. Поэтому мы изобретаем новые способы поиска тех мест, где вероятно появление синтаксических нулей. Это позволит уменьшить время, за которое парсер будет определять эллипсис. 


Кстати, интерес к эллипсису в компьютерной лингвистике в этом году сильно вырос. Вышла исследовательская статья «Sentences with Gapping: Parsing and Reconstructing Elided Predicates» крупнейших компьютерных лингвистов современности Себастиана Шустера, Иоакима Ниврэ и Кристофера Майнинга. Таким образом, исследование эллипсиса — это хорошая задача, решение которой может дать результат и для научного сообщества, и для практического применения.


Узнать больше о том, как научить машину восстанавливать «пропуски» в тексте, можно из нашей статьи:
 Соревнование ML-систем на лингвистическом материале. Как мы учились заполнять пропуски


Снятие лексической неоднозначности

Что такое «остановка»? Это может быть объект, куда приехал автобус, а может быть остановка процесса, а может быть, остановка в речи. Слово одно, а смыслов у него много. 


Во многих компаниях есть тезаурусы, где эти смыслы расписаны. Это удобно, автоматически получать из последовательности слов, словоформ или лексем — последовательность смыслов или семантических классов. В ABBYY мы пробуем делать изолированную модель, которая бы точно определяла смысл слова с хорошим качеством и скоростью. Если быстро снимать лексическую неоднозначность, то можно прилично ускорить работу – будь то синтаксический парсинг или извлечение именованных сущностей/фактов. 

А при чем тут нейросети и Школа глубокого обучения?


Все эти задачи решаются с помощью нейросетей. Не то чтобы их нельзя решать без сеток, но сейчас это самый современный метод. Рекуррентные нейронные сети дают лучшие результаты для задач NLP. Так что это все не просто абстрактное модное явление, а то, что используется на практике для решения самых разных задач NLP. 


Подробнее о том, какие задачи по анализу текста еще есть, как современные нейросети используются для решения таких задач в России и в мире, Иван Смуров расскажет на лекции в Школе глубокого обучения при МФТИ. Лекция пройдет в эту субботу, 24 ноября, в 17:00, по адресу Дмитровское шоссе, 9.    Tags: ABBYYR&DNLPобработка естественного языкамашинное обучениесаммаризациясинтаксический анализэллипсисШкола глубокого обучениялекцияМФТИABBYY_NLP Hubs: ABBYY corporate blogMachine learningNatural Language Processing          


