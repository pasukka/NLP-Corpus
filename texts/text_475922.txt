

Julia NLP. Обрабатываем тексты / Habr


               15  November  2019 at 11:45  Julia NLP. Обрабатываем тексты Programming *Julia *Natural Language Processing * 
        Tutorial
           
Анализ и обработка текстов на естественном языке является постоянно актуальной задачей, которая решалась, решается и будет решаться всеми доступными способами. На сегодня хотелось бы поговорить о средствах решения для решения этой задачи, именно, на языке Julia. Безусловно, в виду молодости языка, здесь нет столь развитых средств анализа, как, например Stanford CoreNLP, Apache OpenNLP, GATE и пр., как, например, для языка Java. Однако, даже уже разработанные библиотеки, вполне могут использоваться как для решения типовых задач, так и быть рекомендованными в качестве точки входа для студентов, которым интересна область обработки текстов. А синтаксическая простота Julia и её развитые математические средства, позволяют с лёгкостью погрузиться в задачи кластеризации и классификации текстов.
Целью данной статьи является обзор средств обработки текстов на языке Julia с небольшими пояснениями об их использовании. Будем балансировать между кратким перечислением возможностей для тех, кто в теме NLP, но хотел бы увидеть именно средства Julia, и более подробными пояснениями и примерами применения для тех, кто решил впервые погрузиться в область NLP (Natural Language Processing) как таковую.
Ну а сейчас, перейдём к обзору пакетов.
TextAnalysis.jl
Пакет TextAnalysis.jl является базовой библиотекой, реализующей минимальный набор типовых функций обработки текста. Именно с неё и начнём. Примеры частично взяты из документации.
Документ
Базовой сущностью является документ. 
Поддерживаются следующие типы:

FileDocument — документ, представленный простым текстовым файлом на диске

julia> pathname = "/usr/share/dict/words"
"/usr/share/dict/words"
julia> fd = FileDocument(pathname)
A FileDocument
 * Language: Languages.English()
 * Title: /usr/share/dict/words
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: A A's AMD AMD's AOL AOL's Aachen Aachen's Aaliyah

StringDocument — документ, представленный UTF-8-строкой и хранимый в оперативной памяти. Структура StringDocument обеспечивает хранение текста в целом.

julia> str = "To be or not to be..."
"To be or not to be..."
julia> sd = StringDocument(str)
A StringDocument{String}
 * Language: Languages.English()
 * Title: Untitled Document
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: To be or not to be...

TokenDocument — документ, представляющий собой последовательность UTF-8-токенов (выделенных слов). Структура TokenDocument хранит набор токенов, однако полный текст не может быть восстановлен без потерь.

julia> my_tokens = String["To", "be", "or", "not", "to", "be..."]
6-element Array{String,1}:
 "To"   
 "be"   
 "or"   
 "not"  
 "to"   
 "be..."
julia> td = TokenDocument(my_tokens)
A TokenDocument{String}
 * Language: Languages.English()
 * Title: Untitled Document
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: ***SAMPLE TEXT NOT AVAILABLE***

NGramDocument — документ, представленный как набор n-грамм в UTF8 представлении, то есть последовательности по n UTF-8 символов, и счётчик их вхождения. Этот вариант представления документа является одним из простейших способов избежать некоторых проблемах морфологии языков, опечаток и особенностей языковых конструкций в анализируемых текстах. Впрочем, плата за это — снижение качества анализа текста по сравнению с методами, где информация о языке учитывается.

julia> my_ngrams = Dict{String, Int}("To" => 1, "be" => 2,
                                    "or" => 1, "not" => 1,
                                    "to" => 1, "be..." => 1)
Dict{String,Int64} with 6 entries:
  "or"    => 1
  "be..." => 1
  "not"   => 1
  "to"    => 1
  "To"    => 1
  "be"    => 2
julia> ngd = NGramDocument(my_ngrams)
A NGramDocument{AbstractString}
 * Language: Languages.English()
 * Title: Untitled Document
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: ***SAMPLE TEXT NOT AVAILABLE***
Или короткий вариант:
julia> str = "To be or not to be..."
"To be or not to be..."
julia> ngd = NGramDocument(str, 2)
NGramDocument{AbstractString}(Dict{AbstractString,Int64}("To be" => 1,"or not" => 1,"be or" => 1,"or" => 1,"not to" => 1,"not" => 1,"to be" => 1,"to" => 1,"To" => 1,"be" => 2…), 2,
TextAnalysis.DocumentMetadata(
Languages.English(),
"Untitled Document",
"Unknown Author",
"Unknown Time"))
Документ, также, можно создать просто при помощи обобщенного конструктора Document, а библиотека найдёт соответствующую реализацию документа.
julia> Document("To be or not to be...")
A StringDocument{String}
 * Language: Languages.English()
 * Title: Untitled Document
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: To be or not to be...
julia> Document("/usr/share/dict/words")
A FileDocument
 * Language: Languages.English()
 * Title: /usr/share/dict/words
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: A A's AMD AMD's AOL AOL's Aachen Aachen's Aaliyah
julia> Document(String["To", "be", "or", "not", "to", "be..."])
A TokenDocument{String}
 * Language: Languages.English()
 * Title: Untitled Document
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: ***SAMPLE TEXT NOT AVAILABLE***
julia> Document(Dict{String, Int}("a" => 1, "b" => 3))
A NGramDocument{AbstractString}
 * Language: Languages.English()
 * Title: Untitled Document
 * Author: Unknown Author
 * Timestamp: Unknown Time
 * Snippet: ***SAMPLE TEXT NOT AVAILABLE***
Как видим, тело документа состоит из текста/токенов и метаданных. Текст документа можно получить при помощи метода text(...):
julia> td = TokenDocument("To be or not to be...")
TokenDocument{String}(["To", "be", "or", "not", "to", "be"],
TextAnalysis.DocumentMetadata(
Languages.English(),
"Untitled Document",
"Unknown Author",
"Unknown Time"))
julia> text(td)
