

Блог за авторством GPT-3 за две недели посетили 26 тысяч человек. Его приняли за блог обычного автора / Habr


              5  August  2020 at 10:42  Блог за авторством GPT-3 за две недели посетили 26 тысяч человек. Его приняли за блог обычного автора Algorithms *Machine learning *Artificial Intelligence       


Блог, который вел новый алгоритм написания текстов GPT-3 от OpenAI под вымышленным именем Liam Porr, за две недели посетили 26 тысяч человек. Никто не догадывался, что блог ведет не человек. В последнем посте интрига была раскрыта. 


«Я думаю, что лучшие варианты использования алгоритмов лежат за пределами технологий. Я считаю, что у GPT-3 есть потенциал, чтобы изменить то, как мы пишем», — обратился к читателям автор эксперимента Мануэль Араос. 


По его словам, за прошедшие две недели блог набрал 60 подписчиков, и только один из них догадался, что посты пишет не человек. 




Самый первый пост из блога попал на первое место в Hacker News. Так вышло благодаря разоблачению от самого Араоса, который показал, что этот текст был написан GPT-3. 

A text-only model trained on the Internet (like GPT-3) can't achieve human-level intelligence because it lacks:- visual understanding (eg: non-verbal communication)- complex motor skills / physical expertise - [controversial] a survival instinct— Manuel Araoz (@maraoz) July 22, 2020


Кроме того, о возможном авторстве блога несколько раз упоминали специализированные порталы.




Комментатора, который предположил, что блог пишет нейросеть, заминусовали.


Араос рассуждает о том, как благодаря GPT-3 может измениться будущее онлайн-медиа. «Все, что мне нужно написать, — это хороший заголовок и вступление. Я мог бы написать пять за час. Другими словами, один хороший автор с помощью GPT-3 теперь может выполнять ту же работу, которую раньше выполняла команда создателей контента», — указывает он.


В блоге говорится, что у алгоритма есть и проблемы с логикой и повторами в тексте. Иногда появлялись и грамматические ошибки, а также алгоритм допускал искажение фактов (неверное авторство цитат). Однако незначительная человеческая правка может сделать такой текст качественным. Кроме того, GPT-3 больше подходит для создания эмоциональных текстов, нежели глубоко исследовательских. Эта технология позволит творческим редакциям сэкономить массу денег, утверждает автор.


В посте приводится простой расчет: в Buzzfeed Inc. работает 1700 сотрудников, а средняя базовая зарплата автора составляет $42 тыс. Всего в компании таких сотрудников может быть несколько сотен, к примеру, 400. Их годовой доход привязан к количеству текстов. GPT-3 может повысить эффективность авторов на 50%. Но при этом его захотят использовать только половина из них. Таким образом, аналогичный объем контента вместо 200 человек будут создавать 133. Команда, поддерживаемая GPT-3, сэкономила бы Buzzfeed около $3 млн в год.


Не исключено, что старые редакции будут сопротивляться такому нововведению, предположил автор. Однако могут появиться медиа нового типа, с небольшим штатом. 


Араос также пояснил, что у него не было доступа к GPT-3, но он нашел аспиранта, который помогал в этой работе, отказавшись при этом передать ключи API. В заключение он попросил гендиректора OpenAI Сэма Альтмана дать ему доступ к GPT-3.


Подробный отчет о проделанной работе есть на GitHub.


OpenAI показала GPT-3, предназначенный для написания текстов на основе всего нескольких примеров, в конце мая. Архитектура алгоритма Transformer аналогична GPT-2, но модель обучали на 175 миллиардов параметрах или 570 гигабайтах текста. GPT-3 может отвечать на вопросы по прочитанному тексту, а также писать стихи, разгадывать анаграммы и осуществлять перевод. Ему достаточно от 10 до 100 примеров для обучения. См. также: 


«GPT-3 от OpenAI может стать величайшей вещью со времён Bitcoin»
«Подвергаем модель GPT-3 тесту Тьюринга»
«Необычное собеседование: GPT-3 в роли кандидата»
    Tags: openaigpt-3алгоритмыблогитекстымедиагенерация текстов Hubs: AlgorithmsMachine learningArtificial Intelligence          


