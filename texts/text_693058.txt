

Автоматическое реферирование научных статей. Обзор работ / Habr


               Автоматическое реферирование научных статей. Обзор работ  Reading time  
    19 min
   Views  1.6K Unistar Digital | Юнистар Диджитал corporate blog Semantics *Natural Language Processing *      Задача автоматического реферирования научного текста формулируется следующим образом: на основе текста научной статьи и, возможно, некоторой другой информации о ней, например цитат и ссылок на эту статью, содержащихся в других работах, требуется породить с помощью алгоритмов автоматической обработки текста небольшой сжатый реферат, который при этом будет максимально точно и полно передавать основные идеи, методы и результаты, описанные в статье.Введение в проблематикуАвтоматическое реферирование текста – одно из классических направлений компьютерной лингвистики. Сейчас в связи с постоянным ростом объёмов информации проблема автоматического создания кратких и содержательных рефератов становится ещё более актуальной. Для решения задач автоматического реферирования проводятся ежегодные открытые тестирования, на которые международные коллективы могут присылать свои системы – о них расскажем чуть позже. Автоматическое реферирование научных статей – одно из активно развивающихся направлений автоматического реферирования текстов. Для исследователей проблема особо актуальна, так как в последнее время появляется всё больше научных статей, и прочитать их все от начала до конца невозможно. Реферат помогает сэкономить время и силы, предоставляет исследователю самую важную, ключевую, информацию, содержащуюся в статье, позволяет определить, релевантна ли эта статья для исследуемого поля деятельности и научных интересов, стоит ли читать её в оригинале. Кроме того, рефераты отдельных статей и сводные рефераты по какой-либо тематике (охватывающие сразу несколько статей - например, все классические работы, или работы, ознаменовавшие определённые вехи в развитии данного направления, или авторитетные работы в хронологическом порядке) становятся незаменимыми помощниками для тех исследователей, которые планируют перейти из одной научной области в другую.Для получения автоматических рефератов научных статей до недавнего времени использовались те же методы, что и для простого автоматического реферирования текста. Однако стоит заметить, что научные статьи – это отдельный жанр со своей спецификой, следовательно, целесообразно развивать методы автоматического реферирования, подходящие именно для научных статей. Так, любой научный труд не находится в вакууме (в принципе, это относится и ко многим другим типам и жанрам текстов: например, твиты всегда сопровождаются большим количеством комментариев и ответных твитов; разные новостные статьи могут описывать одно и то же событие), а связан с другими статьями, в частности с помощью цитат и ссылок. Как правило, цитируются самые важные идеи, методы, результаты. Отсюда возникает идея использовать ссылки для извлечения наиболее релевантных предложений, текстовых отрезков из статьи, подвергающейся цитированию, чтобы в дальнейшем использовать извлечённый материал при создании автоматического реферата.Обзор работ, посвящённых автоматическому реферированию научных статейВ статье [Qazvinian, Radev 2008] (Scientific Paper Summarization Using Citation Summary Networks) для автоматического порождения реферата научной статьи используется набор ссылок на эту статью. Авторы указывают на важность создания такой системы, которая, получив на вход тему исследования, выдавала бы краткое содержание всех работ, касающихся этой темы. Они утверждают, что коллекции цитат могут помочь понять вклад статьи в общий массив научных знаний. Предлагается построить лексическую сеть с узлами, соответствующими предложениям из разных цитат, произвести кластеризацию и извлекать предложения из разных кластеров. Таким образом в реферат попадут наиболее важные и значимые предложения. Следует отметить, что текст статьи-источника при таком подходе не задействуется.Статья [Cohan, Goharian 2018] (Scientific document summarization via citation contextualization and scientific discourse) полностью посвящена использованию набора цитат статьи для задачи порождения её реферата. Авторы указывают на важность извлечения отрезков текста оригинальной статьи для их последующего включения в реферат. Они объясняют это тем, что сами по себе тексты цитат могут неадекватно отражать содержание статьи-источника, например представлять некоторые предположения как доказанный факт. Поэтому имеющиеся цитаты необходимо контекстуализовать (contextualization), то есть подобрать для них соответствующие отрезки текста статьи-источника. Эта задача усложняется возможными различиями в используемой терминологии между статьёй-источником и статьями других авторов, которые её цитируют. Авторы работы предлагают следующие способы решения этой проблемы: переформулировка запроса, использование векторных представлений слов и знаний, специфичных для данной области. В своей более ранней статье [Cohan, Goharian 2017] Scientific Article Summarization Using Citation-Context and Article’s Discourse Structure они применяют метод, основанный на использовании как отрезков текста статьи-источника, соответствующих цитатам, так и дискурсивной структуры самой статьи-источника. Под дискурсивной структурой понимается условная классификация всех предложений/кусков статьи на несколько заранее определённых классов: гипотеза, метод, результаты, импликации, дискуссия и использованные наборы данных. Чтобы отразить все эти аспекты, в итоговый реферат должны быть помещены предложения из всех классов.Авторы [Mohammad et al. 2009] (Using Citations to Generate surveys of Scientific Paradigms) используют предложения, содержащие цитаты на статью-источник, для автоматического создания обзоров технической литературы.В статье [Conroy, Davis 2015] (Vector Space Models for Scientific Document Summarization) сравнивается качество работы трёх подходов к оценке весов токенов для задач автоматического реферирования научных статей, учитывающих глубинную структуру документа. Эти подходы заключаются в моделировании векторного пространства и создании двух разных языковых моделей.В статье [Teufel, Moens 2002] (Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status) авторы представляют новый подход к автоматическому реферированию научных статей, основанный на использовании риторического статуса высказываний исходной статьи, а именно информации о том, что является целью научной работы, каков её вклад, какая информация новая, а что заимствуется из предыдущих исследований, каковы связи рассматриваемой статьи с другими. Авторы убеждены в том, что все эти данные помогут в составлении содержательного и сжатого реферата научной статьи. В своей кандидатской диссертации Тойфель ([Teufel 1999]; Argumentative Zoning: Information Extraction from Scientific Text) впервые описала такой подход к анализу научных статей, который был назван аргументативным зонированием (argumentative zoning). Основная идея заключается в том, что дискурсивный анализ текста может помочь улучшить качество для ряда прикладных задач, в том числе и для задачи автоматического реферирования текста. У Тойфель с соавторами имеется также ряд других работ, посвящённых проблематике реферирования статей (см., например, [Kaplan, Tokunaga, Teufel 2016] Citation Block Determination Using Textual Coherence) и исследованию дискурсивной структуры научных текстов (см., например, [Heffernan, Teufel 2018] Identifying problems and solutions in scientific text).Е.Ю. Дубинина [Дубинина 2018] АВТОМАТИЧЕСКОЕ ВЫДЕЛЕНИЕ КЛЮЧЕВЫХ ЛЕКСИЧЕСКИХ ЕДИНИЦ НАУЧНОГО ТЕКСТА В ПРОЦЕССЕ РЕФЕРИРОВАНИЯ описывает процесс автоматического извлечения из текста ключевых лексических единиц, которые можно в дальнейшем использовать при создании реферата. Используются количественные методы (извлечение наиболее частотных коллокаций, встречающихся как в авторской аннотации, так и в тексте статьи) и методы сопоставительного анализа текстов. Сходной проблеме посвящена также кандидатская диссертация Е.Ю. Дубининой – см. автореферат [Дубинина 2013] – в ней рассматриваются методы и модели компрессии научного текста, в частности использование ключевых лексических единиц, выделяемых при сопоставлении заглавия и авторского реферата в начале статьи с остальным текстом, учёт так называемых «сильных» позиций статьи, к которым автор относит авторский реферат, заглавие, введение и выводы, и исключение основной части, которая может оказаться избыточна. Степень информативности предложений определяется по частоте ключевых лексических единиц и конструкций.Отдельно стоит отметить, что существует ряд работ, посвящённых обработке цитат для других задач (или обработке цитат как таковой):В статье [Kim, Webber 2006] Implicit Reference to Citations: A study of astronomy papers предлагается решение следующей проблемы: автоматической классификации всех вхождений личного местоимения they на те, которые относятся к цитируемому исследованию, и те, которые не относятся. Также рассматривается способ соотнесения тех употреблений they, которые относятся к какой-либо цитате, с этой самой цитатой. В качестве данных используется корпус журналов из области астрономии. В работе [Chen, Cheng L.C., Cheng Y.L. 2007] Using position, fonts and cited references to retrieve scientific documents предлагается использовать набор цитат, тип шрифта и позиционные признаки для задач информационного поиска по научным базам.В статье [Nenkova, McKeown 2012] A Survey of Text Summarization Techniques также кратко освещается проблема автоматического реферирования научных статей. Исследователи указывают на то, что такой реферат должен содержать ту информацию из источника, которая имела наибольшее влияние на последующие исследования. Для этих задач используются языковые модели. Для каждой статьи в корпусе находят ряд других статей, содержащих ссылки на неё. Затем извлекаются те области, в которых появляются отсылки. Далее строится языковая модель с использованием набора всех областей текстов, в которых имеет место цитирование исходной статьи, эта модель задаёт вероятности слов встретиться в области цитаты. С помощью этой языковой модели можно приписывать веса предложениям исходной статьи: наибольший вес получают те предложения, которые содержат информацию, так или иначе «похожую» на ту информацию, которая обсуждается в более поздних статьях, ссылающихся на данную. Мера близости между предложением и языковой моделью вычисляется по формуле расстояния Кульбака-Лейблера (KL-divergence). Также считаются вероятности слов в пределах статьи. Во второй части статьи рассмотрим именно такой подход к задаче.Следует упомянуть  ряд других важных работ по автоматическому реферированию научного текста: [Пачковская 2010] ФОРМИРОВАНИЕ КОНТЕНТА РЕФЕРАТА ПРИ АВТОМАТИЧЕСКОМ РЕФЕРИРОВАНИИ НАУЧНОГО ТЕКСТА, [Yasunaga et al. 2019] ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scientific Paper Summarization with Citation Networks, [Ma, Xu, Zhang 2018] Automatic identification of cited text spans: a multi-classifier approach over imbalanced dataset, [Kurian, Mathew 2020] Survey of scientific document summarization methods – один из довольно свежих обзоров различных подходов к автоматическому реферированию научных статей.Открытое тестирование моделей автоматического реферирования научных статей CL-SciSummОткрытые тестирования (shared task) проводятся для того, чтобы стимулировать интерес разработчиков и исследователей в области компьютерной лингвистики к той или иной области или задаче. Проводятся открытые тестирования в области семантического анализа (Semantic Analysis, SA), синтаксической обработки текста (Syntactic Parsing), извлечения именованных сущностей (Named Entity Extraction, NER), анализа тональности (Sentiment Analysis, SA) и по многим другим задачам. автоматическое реферирование научных статей в данном случае не исключение. Организаторы такого тестирования готовят определённые задания, а также вырабатывают методику оценки их успешного решения. Некоторые примеры задач для открытого тестирования: произвести синтаксический разбор определённого количества предложений (это могут быть как отдельно взятые предложения, так и связные тексты); для набора многозначных слов выбрать то значение, в котором оно употреблено в конкретном тексте; извлечь все именованные сущности (к ним относят имена людей, географические обозначения, названия валют и прочее). Команды-участники, в свою очередь, разрабатывают разные алгоритмы для решения поставленных задач и присылают их организаторам на тестирование в отведённые для этого сроки. Побеждает та команда, чья система покажет наилучший результат в решении поставленных задач на специально подготовленном наборе данных с учётом разработанных организаторами методов и подходов к тестированию. По результатам открытого тестирования, как правило, публикуют статьи, в которых каждая команда описывает свой подход и свою систему.CL-SciSumm (Computational Linguistics Scientific Summarization) (Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2019)) является открытым тестированием систем по автоматическому порождению рефератов для научных работ. Его мы и рассмотрим.Задачи и краткая историяКак заявляют сами организаторы [Chandrasekaran et al. 2019] Overview and results: Cl-SciSumm shared task 2019, открытое тестирование CL-SciSumm является первым открытым тестированием алгоритмов автоматического реферирования научных документов в области компьютерной лингвистики. Проводя данное тестирование, организаторы хотят привлечь внимание научного сообщества к использованию при автоматическом реферировании такой дополнительной информации о научных статьях, как цитаты и ссылки на эту статью, содержащиеся в работах других авторов, а также дискурсивный «фасет» (facet), к которому принадлежит тот отрезок текста, который предполагается включить в реферат, то есть тематику цитат. Впервые тестирование было проведено в 2014 году в рамках BiomedSumm Track на конференции по анализу текста (Text Analysis Conference, TAC) и было посвящено автоматическому реферированию статей из биомедицинской области. Затем, в 2016 году, было организовано отдельное тестирование методов автоматического реферирования статей, относящихся к домену компьютерной лингвистики в рамках воркшопа BIRNDL – Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (CLScisumm-16; Jaidka et al. 2017 Insights from CL-SciSumm 2016: the faceted scientific document summarization Shared Task). Подобные тестирования проводились также в 2017, 2018 ([Jaidka et al. 2018] The CL-Scisumm shared task 2018: Results and key insights) и 2019 ([Chandrasekaran, Mayr 2019] Report on the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries at SIGIR 2019). CL-SciSumm ставит своей целью привлечь внимание специалистов со всего мира к проблеме автоматического реферирования научных статей.Данные тестированияВ распоряжение участников предоставляется коллекция данных, состоящая из топиков – наборов данных, включающих 1) статью-источник (reference paper, RP) и 2) десять или более статей, содержащих ссылки на статью-источник (citing papers, CPs). Также предоставляется список самих цитат. Все статьи относятся к области компьютерной лингвистики.Дано: набор данных (так называемый «топик» (topic)), состоящий из статьи источника (Reference Paper, RP) и десяти или более статей, цитирующих статью-источник (Citing Papers, CPs). Для каждой статьи с цитатами были определены отрезки текста (так называемые «citances»), в которых авторы так или иначе ссылаются на статью-источник. Выборка делится на обучающую и тестовую части. В дополнение выборка данных содержит по три вида рефератов для каждой статьи-источника: аннотация, написанная авторами этой статьи; реферат, созданный научным сообществом, то есть набор отрезков статьи-источника, на которые ссылаются другие статьи; написанный специально обученным аннотатором реферат.Используя эти данные, участникам предлагается выполнить следующие три задания (формулировки тестирования 2018 года).1A: для каждой цитаты подобрать с помощью автоматических методов тот отрезок текста исходной статьи (предложение или цепочка предложений), который максимально близко соответствует цитате.1B: для каждого процитированного отрезка статьи (cited text span, CTS) подобрать наиболее подходящий ему дискурсивный «фасет» из заранее выделенного списка (методы, гипотезы, результаты).2: создать реферат исходной статьи, используя полученные в первом задании CTS. Длина не должна превышать 250 слов. Данное задание было представлено в качестве бонусного.Основная идея, стоящая за таким подходом, состоит в следующем: цитаты, собранные вместе, рассматриваются как «индикаторы» наиболее важных ключевых положений, идей и результатов данной конкретной статьи. Они как бы отобраны научным сообществом из всей информации, содержащейся в статье.Подход к тестированиюПервое задание оценивается с помощью пересечения отрезков текста, измеренное как соотношение числа предложений в выдаче системы и числа предложений в «золотом стандарте». Второе, бонусное, задание оценивается с помощью системы метрик ROUGE (Recall-oriented Understudy for Gisting Evaluation), причём измеряется сходство автоматически порождённого реферата с авторской аннотацией и с набором цитат для реферируемой статьи.Для измерения качества работы систем использовался автоматический скрипт. Мерой качества выполнения задания 1А была степень пересечения ID-номеров предложений (порядковый номер предложения в хml-файле статьи), включённых в выдачу системой, и предложений, входящих в «золотой стандарт», размеченный людьми. «Сырое» число общих предложений использовалось далее при подсчёте точности, полноты и F1-меры для каждой системы.Среднее качество работы системы оценивалось как микро-усреднённое качество на всех «топиках» в слепом тестовом наборе данных. Кроме того, организаторы подсчитали лексическое пересечение в терминах ROUGE-2 и ROUGE-SU4. Также в 2018 году организаторы усредняли качество работы систем на трёх независимых аннотациях для первого задания, а для оценки качества выполнения второго задания автоматически сгенерированный реферат сравнивался с рефератом, который являлся усреднением трёх разных рефератов, написанных людьми.Метрика ROUGE (набор метрик, используемый для автоматического оценивания систем автоматического реферирования; основан на измерении степени пересечения между рефератом, порождённым компьютером, и рефератами, написанными человеком) использовалась при оценке заданий 1А и 2. ROUGE-2 измеряет пересечение в терминах биграмм, ROUGE-N – в терминах энграмм. ROUGE-SU измеряет пересечение в терминах униграмм и скип-биграмм.Качество выполнения задания 1B оценивалось как пропорция дискурсивных «фасетов», которые система классифицировала правильно, с учётом результатов выполнения задания 1А. Также использовались точность, полнота и F1-мера.Задание 2 оценивалось с помощью метрик ROUGE-2 и ROUGE-SU4 между выдачей системы и тремя вариантами «золотого стандарта»: аннотация автора к статье, реферат научного сообщества (набор цитируемых кусков статьи) и рефератом, написанным аннотатором.Какие методы применяли участники тестированияВ 2018 году в выполнении задания 1 приняли участие десять систем, три из них также выполнили бонусное задание 2. Нумерация систем взята из статьи организаторов тестирования [Jaidka et al. 2018: 3 – 5] Insights from CL-SciSumm 2016: the faceted scientific document summarization Shared Task.Система 2 (CIST)В задании 1А участники из Пекинского университета почты и телекоммуникаций и из Центра по изучению интеллекта и технологий (Center for Intelligence Science and Technology, CIST; [Li et al. 2018]; CIST@CLSciSumm-18: Methods for Computational Linguistics Scientific Citation Linkage, Facet Classification and Summarization) применяли алгоритм Word Mover’s Distance (WMD) и улучшенную модель латентного размещения Дирихле, чтобы рассчитать сходство предложений в статье-источнике и в статье, цитирующей её. WMD – это метод подсчёта «расстояния» от одного текста до другого на основе векторов слов и Earth Mover’s Distance (EMD). WMD выступает в качестве меры сходства двух отрезков текста. Также участники извлекали разные признаки, в том числе словарные признаки (словарь наиболее частотных слов, LDA-словарь, словарь совместной встречаемости), контекстные признаки, векторное представление слов, меры сходства слов, основанные на WordNet, и использовали свёрточные нейронные сети.Система 4Исследователи из компании «Thomson Reuters» и Центра когнитивных вычислений (Center for Cognitive Computing; [Davoodi, Madan, Gu 2018] CLSciSumm Shared Task: On the Contribution of Similarity measure and Natural Language Processing Features for Citing Problem) рассматривают задание 1А, как проблему бинарной классификации и используют различные признаки, основанные на сходстве (энграммное сходство, сходство векторных представлений слов - embeddings, коэффициент Жаккара), позиции и частоте.Система 6 (NUDT)Для выполнения задания 1А участники из Оборонного научно-технического университета Народно-освободительной армии Китая (National University of Defense Technology, NUDT; [Wang et al. 2018] NUDT @ CLSciSumm-18) используют модель «случайного леса» (Random Forest) со множественными признаками (коэффициент Жаккара, BM25-сходство, векторизованное TF*IDF-сходство). Кроме того, они интегрируют модель «случайного леса» с функцией ранжирования BM25 и векторной моделью и применяют стратегию голосования, чтобы выбрать наиболее вероятный отрезок текста. Для улучшения качества они также интегрировали языковую модель с векторными представлениями слов (embeddings). В задании 1B команда применяла классификатор «случайный лес» со многими признаками. Также выполнению заданий предшествовал этап предобработки: частеречная разметка с помощью библиотеки NLTK, удаление знаков препинания и стоп-слов, а также удаление предложений с ошибками форматирования.Система 7 (NJUST)Для задания 1А исследователи из Нанкинского университета науки и технологий (Nanjing University of Science and Technology, NJUST; [Ma et al. 2018]; NJUST @ CLSciSumm-18) обучили ансамбль классификаторов: метод опорных векторов (support vector machine, SVM), деревья решений, логистическую регрессию и применили стратегию голосования. Признаки, которые использовались при обучении, таковы: коэффициент Жаккара, сходство, основанное на латентном размещении Дирихле, TF*IDF-сходство, сходство, подсчитанное по тезаурусу WordNet, сходство векторов Word2Vec, Doc2Vec-сходство, позиция в предложении, позиция в разделе.Система 8Задание 1А рассматривалось командой исследователей из Международного института информационных технологий (город Хайдерабад) как проблема соответствия/сопоставления текстов (text-matching problem).Участники построили матрицу соответствия, элементы которой соответствуют значению коэффициента близости слов. Затем они использовали свёрточную нейронную сеть для обобщения паттернов соответствия.Система 9 (Klick Labs)При выполнении задания 1А участники из лаборатории Klick Labs (Торонто; [Baruah, Kolla 2018]; Klick Labs at CL-SciSumm 2018) использовали меры близости, основанные на векторных представлениях (embeddings) слов, для определения отрезков текста, на которые ссылаются другие статьи, а именно косинусная мера близости вектора для цитаты и усреднённого вектора для предложения. В качестве «бэйзлайна» (baseline) использовался алгоритм ранжирования BM25. Также они применили несколько вариантов оптимизации: оптимизация «отрезания» (cutoff optimization), нормализованные векторные представления слов (embeddings), усреднённые векторные представления слов.Система 10 (University of Houston)Команда из Хьюстонского университета в задании 1A применяла Сиамские нейронные сети с глубоким обучением (Siamese Deep Learning Networks) и позиционную языковую модель (positional language model), а также TF*IDF-вектора, вектора сокращённой размерности, WMD. Нейронная сеть имеет следующую архитектуру: две подсети с двунаправленными LSTM-ячейками с 50 нейронами скрытого слоя каждая, слой исключения (дропаута, dropout) и полносвязный выходной слой для каждой подсети. В качестве функции оптимизации используется AdaDelta. За подробностями можно обратиться к статье-источнику - [De Moraes et al. 2018] University of Houston @ CL-SciSumm 2018.Система 11Для заданий 1А и 1B участники из международной команды (Университет Помпеу Фабра, Барселона, и Республиканский университет, Монтевидео; LaSTUS TALN INCO; [AbuRa’ed et al. 2018]; LaSTUS/TALN+INCO @ CL-SciSumm 2018 - Using Regression and Convolutions for Cross-document Semantic Linking and Summarization of Scholarly Literature) предложили модели, которые используют коэффициент Жаккара (Jaccard similarity), векторные представления (embeddings) синсетов BabelNet, косинусную меру близости на этих векторах, свёрточную нейронную сеть на векторах слов.Система 12 (NLP-NITMZ)В задании 1А участники из Национального технологического института, расположенного в северо-восточном индийском штате Мизорам, в городе Аиджал ([Debnath, Achom, Pakray 2018]; NLP-NITMZ @ CLScisumm-18), использовали косинусную меру близости и коэффициент Жаккара для измерения сходства между цитирующей статьёй и статьёй-источником. Извлекались те предложения статьи-источника, которые больше всего походили на предложения, содержащие отсылку, из цитирующей статьи.Система 20Задание 1A рассматривалось командой Magma из компании «Thomson Reuters» (Торонто, Канада; [Alonso et al. 2018]; CL-SciSumm Shared Task - Team Magma) как проблема бинарной классификации. Участники применили несколько разных классификаторов с разными наборами признаков. Они обнаружили, что логистическая регрессия с содержательными признаками (content-based features), полученными на основе близости тем и слов в корпусе ACL (корпусе научных публикаций на английском языке), даёт наилучший результат.Обзор методов, использованных участниками тестирования в 2019 годуДевять систем из семнадцати зарегистрировавшихся изначально приняли участие в выполнении задания 1, пять из них также выполнили задание 2. Далее приводится краткий обзор методов, использованных командами-участниками, а также результаты тестирования. Нумерация команд взята из статьи [Chandrasekaran et al. 2019: 3 – 5] Overview and Results: CL-SciSumm Shared Task 2019.Система 2Команда из Пекинского университета почты и телекоммуникаций (Beijing University of Posts and Telecommunications; CIST; [Li et al. 2019]; CIST@CLSciSumm-19: Automatic Scientific Paper Summarization with Citances and Facets) измеряла сходство предложений статьи-источника с цитатой с помощью векторного представления Word2Vec_H и использовала данный признак при обучении свёрточной нейронной сети.Система 3Исследователи из Манчестерского университета применяли методы машинного обучения с учителем и обучения с частичным привлечением учителя. Так, они использовали двунаправленный трансформер (bidirectional transformer), кроме того участники рассматривали задачу извлечения нужных отрезков статьи-источника как проблему ранжирования по сходству (similarity ranking) и применили двустороннее попарное сопоставление со множественными перспективами (bilateral multi-perspective matching) на предложениях статей.Система 4Команда исследователей из Университета Тулузы в первую очередь сосредоточилась на задании 1А. Они сначала отбирают предложения-кандидаты из статьи-источника, а затем рассчитывают коэффициент их близости с цитатой, используются веса TF-IDF, методы, основанные на векторных представлениях слов (embeddings), а также ряд других, например частеречные метки. Всего данная команда прислала результаты работы 15 различных методов.Система 7Участники из Международного института информационных технологий в городе Хайдарабад и из Исследовательского центра компании Adobe ([Syed et al. 2019] Helium @ CL-SciSumm-19 : Transfer learning for effective scientific research comprehension) применяют метод трансферного обучения (transfer learning) – направления машинного обучения, при котором знания, полученные при решении одной задачи, сохраняются и используются в дальнейшем для решения другой задачи. Они создают попарные репрезентации текстов для предложений статьи-источника и цитаты, а затем применяют библиотеку XGBoost, которая предназначена для повышения градиента, в сочетании с предобученными векторами.Система 8Команда участников из Университета Помпеу Фабра и Республиканского университета в Уругвае ([Chiruzzo et al. 2019]; LaSTUS-TALN+INCO @ CL-SciSumm 2019) предлагает решать задачу 1А с помощью двух методов: один метод относится к разряду методов машинного обучения с учителем (рекуррентные нейронные сети), другой – метод обучения без учителя – берёт за основу меру близости предложений.Система 9Исследователи из Туринского политехнического университета ([La Quatra, Cagliero, Baralis 2019]; Poli2Sum@CL-SciSumm-19: Identify, Classify, and Summarize Cited Text Spans by means of Ensembles of Supervised Models) обучают классификатор – ансамбль и модель регрессии на размеченных парах цитируемых предложений и предложений цитаты.Система 12Исследователи из Нанкинского университета и из Университета имени Ким Ир Сена предлагают новый списочный метод ранжирования для извлечения отрезков статьи-источника, соответствующих цитатам. Обработка происходит в два этапа: 1) ранжирование, основанное на мере близости, (similarity-based ranking) и 2) списочное ранжирование. На первом этапе программа отбирает по пять предложений из статьи-источника для каждой цитаты с наибольшими значениями коэффициента Жаккара. После этого предложения-кандидаты подаются на вход модели CitedListNet (модели списочного ранжирования, основанной на глубоком обучении). В качестве признаков участники отобрали 36 признаков, связанных с измерением близости, и 11 признаков, связанных с информацией о структуре статьи. В конце отбираются по два предложения из каждой пятёрки, помещённые в начало выдачи CitedListNet.Система 17Команда участников из Афинского национального технического университета, Афинского университета экономики и бизнеса и научно-инновационного центра «Афина» ([Fergadis, Pappas, Papageorgiou 2019]; ATHENA@CL-SciSumm 2019: Siamese recurrent bi-directional neural network for identifying cited text spans) разработала метод, подразумевающий также два этапа. На первом этапе производится классификация всех предложений авторской аннотации в начале статьи-источника на определённые классы – так называемые «зоны». Предложения, вошедшие в состав этих «зон», используются для поиска предложений-кандидатов из остальных частей статьи, наиболее похожих на них. На втором этапе предложения цитаты классифицируются либо как цитирующие предложение-кандидат, либо как не-цитирующие данное предложение. Для классификации применяется двунаправленная нейронная сеть с управляемым рекуррентным блоком и со слоем логистической регрессии.Задача автоматического реферирования научных статей представляет собой интересную и перспективную область разработки и исследований. С одной стороны, она востребована и, как кажется, не потеряет своей актуальности в ближайшие годы, так как объёмы информации (в том числе и в научной области) будет только расти. С другой стороны, как видим из обзора, для решения задачи применяются самые разные методы, подходы и алгоритмы, так что каждый найдёт для себя что-то интересное.      Tags: nlpnatural language processingnatural language understandingsummarizationklshared taskоткрытое тестированиереферированиеcitationsцитаты  Hubs: Unistar Digital | Юнистар Диджитал corporate blogSemanticsNatural Language Processing          


