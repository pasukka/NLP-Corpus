

Ваш гений — полный идиот, или Что есть ИИ и грозит ли он кому-либо / Habr


               Ваш гений — полный идиот, или Что есть ИИ и грозит ли он кому-либо  Reading time  
    22 min
   Views  24K Artificial Intelligence The future is here       Дискуссиями о том, насколько прекрасен (опасен, полезен, подчеркните нужное) ChatGPT в частности и искусственный интеллект вообще, полон интернет — на эту тему высказались все, от «песочницы» Хабра до Генри Киссинджера.В принципе, такая громкость хайпа демотивирует говорить что-то своё — всё равно оно потонет в шуме. Однако на этой неделе меня довольно неожиданно попросили прочитать лекцию для студентов-гуманитариев из РГСУ — «Искусственный интеллект нового поколения: изменят ли ChatGPT и Midjourney экономику, политику и социальную сферу», и было бы не меньшим грехом дать подготовленному материалу пропасть, не зафиксировав его письменно.Тем более, что абсолютное большинство уже написанных статей не дают читателям того, что я люблю больше всего — некоей цельной картины происходящего. Это либо частное мнение, либо быстро уходящие в тензорную алгебру описания нейросетей, либо просто узкие демонстрации, что можно сделать (что конкретно сделал автор) в генеративной нейросети.Кандинский 2.1. Победа науки над здравым смыслом. Без указания стиля.О чём же мы будем говорить?Разумеется, о королях и капусте. А также о том, какой бывает искусственный интеллект, можно ли считать его разумным, в чём его главная проблема, спасут ли нас три закона робототехники, на какие профессии он повлияет, а какие — породит (и даже уже породил).Подчеркну, что материал готовился для гуманитариев — социологов, политологов, et cetera — поэтому далее я буду всеми силами избегать погружения в математику, программирование или иные специализированные вещи.Поехали!Немного определенийВ первую очередь, конечно, надо определиться с терминологией — тем более, что в области ИИ она не только до сих пор не всегда конкретна, но и силами журналистов превращается в полный винегрет, в котором путается всё и вся.Итак, давайте условимся, что ИИ у нас может быть представлен в трёх возможных весовых категориях.AI — Artificial Intelligence — узкоспециализированный ИИ, предназначенный для решения одной конкретной задачи. Примером AI являются, например, нейросети распознавания изображений, предназначенные для поиска на них конкретных объектов — скажем, котиков.Этот вид AI является тривиальным и окружает нас уже много лет.AGI — Artificial General Intelligence — ИИ общего назначения, способный эффективно решать любые поставленные перед ним интеллектуальные задачи. Так как «любые задач» — это очень широкое определение (можно поставить, например, задачу проектирования фотонного звездолёта для полёта на Альфу Центавра), то иногда используют более узкое определение «экономически значимые задачи с эффективностью не хуже человека». В любом случае, AGI не требует переобучения с нуля для переключения с одной задачи на другую.Дошли ли мы до стадии AGI — вопрос дискуссионный, однако существуют достаточно много мнений, что GPT-4 уже демонстрирует признаки AGI. Одними из первых такое мнение высказали авторы известной работы «Sparks of Artificial General Intelligence: Early experiments with GPT-4», после чего, разумеется, были немедленно перевраны журналистами, сообщившими миру, что GPT-4 обрёл разум объявил человечество вне закона и в течение пяти минут начнёт бомбардировки.SAI — Strong Artificial Intelligence — ИИ, обладающий сознанием, то есть полностью разумный во всех смыслах этого слова.На данный момент мы не только не достигли этого уровня, но даже приблизительно не представляем, как его достичь. Впрочем, подробнее об этом — и о том, почему ни один из существующих ИИ нельзя считать разумным даже на уровне «зачатков разума» — поговорим ниже.Откуда есть пошёл интеллект искусственныйИИ не свалился на человечество осенью 2022-го года, в день открытия ChatGPT для широкой публики. Если — в широком смысле — мы понимаем ИИ как различные варианты нейросетей, то им уже многие десятилетия. Практические работы в этом направлении начались в 1940-х годах, в 1958-м был изобретён перцептрон — первый нейросетевой классификатор, с конца 1980-х нейросети начали применяться в научных расчётах, в 1990-х благодаря как быстрому росту вычислительных мощностей, так и развитию математического аппарата и архитектурных подходов начался быстрый рост этого направления.Простая нейросеть представляет собой набор блоков, осуществляющих преобразование входного сигнала X в выходной Y посредством некоей функции f(X), и соединённых друг с другом — как показано на рисунке выше синими стрелками. Важных моментов здесь два: во-первых, связи существуют не только линейные, но и перекрёстные, а также каждая связь имеет некоторые вес — который меняется при настройке, то есть обучении нейросети. Вес определяет коэффициент передачи сигнала, то есть, в итоге, пропорцию, в которой каждый блок (нейрон) смешивает приходящие ему на вход сигналы перед их обработкой. В целом — действительно крайне похоже на нейроны головного мозга и коммуникацию между ними.Меняя веса связей, можно получить очень широкий диапазон вариантов отклика нейросети, то есть соответствия между выходным и входным сигналами — например, добиться, что нейросеть будет «реагировать» только на входной сигнал определённого вида.При этом из-за очень большого числа связей — катастрофически растущего с ростом числа блоков — аналитически определить необходимые веса и просто расставить их с первой попытки практически невозможно. Поэтому нейросеть приходится обучать: подавать на её вход некоторый сигнал, сравнивать результат на выходе с желаемым нами, рассчитывать ошибку и подстраивать с целью её устранения веса связей. И если сигнал распространяется слева направо, то направление корректировки связей при подгонке результата — обратное, справа налево. Собственно, такая схема обучения и называется «backpropagation», обратное распространение. Придумана она была в 1960-х, активно применяться начала в 1980-х годах. Обратите внимание на два момента:очеловечевание связанной с нейросетями терминологии часто даёт неверное представление о сути явления. Так, обучение нейросети не имеет ничего общего с обучением человека — если человеку в ходе обучения мы даём новую информацию и объяснение её происхождения, позволяя ему самостоятельно понять и выстроить в логически непротиворечивую систему эту информацию, то в случае нейросетей процедура обучения является математическим алгоритмом настройки сложной системы связей;чем развесистее нейросеть и чем сложнее структура обратываемой ей информации, тем меньше мы понимаем, что именно внутри себя рассчитывает нейросеть — мы лишь добиваемся, чтобы на данных для обучения сигнал на выходе соответствовал желаемому нами. Нейросети этого класса не обладают механизмами внимания, они не выделяют какую-то часть входных данных как важную и другую — как второстепенную, в результате чего легко может оказаться, что они, выдавая желаемый нами ответ, классифицируют на самом деле ту часть входных данных, которую мы, люди, априорно считаем несущественной. Например, есть история про классификацию нейросетью рентгеновских снимков: всё было очень хорошо, пока не оказалось, что ключевым параметром для нейросети стал сам формат снимка: те из них, что приходили из больниц, нейросеть считала снимками больных людей, а те, что приходили из данных плановых обследований — снимками здоровых людей. Ну и в общем действительно в большинстве случаев угадывала. Экспериментаторы же вообще изначально не придали никакого значения тому, что рентгеновские снимки из разных источников отличаются форматом — просто в силу того, что там стоят разные рентгеновские аппараты.Наконец, подобные нейронные сети являются лишь классификаторами, но не генераторами — они не могут что-либо создать. Они лишь определяют, что входящая информация обладает (или не обладает) определёнными свойствами — например, что на картинке изображён котик. Ну или собачка. Или черничный маффин. Или жареная курица.К нейросетям, способными эффективно что-то нужное (например, картинки с котиками) создавать, человечество подошло в 2014 году, создав так называемые GAN, Generative Adversarial Networks, генеративно-состязательные сети.Если быть точным, то это уже не одна нейросеть, а конструкция, состоящая из двух сетей.Первая из них является генератором: получая на вход белый шум, она накладывает на него некоторую функцию, преобразуя шум в... во что-то. Скорее всего, в другой шум, уже не белый. Но иногда — в котиков.Как делают кораблики в бутылке? В бутылку засыпают щепки, бумагу и клей. Потом долго трясут. Чаще всего получается мусор. Но иногда — кораблики.  С одной стороны, нейросети-генератору всё равно, что получается у него на выходе, волнует его это не больше, чем настольный калькулятор в бухгалтерии беспокоится о том, в убытках вы по итогам квартала или в прибылях.С другой стороны, очевидно, что вариантов преобразования белого шума в котика — колоссальное число, а не в котика — ещё в миллионы раз больше. Обучать такую нейросеть вручную — не хватит времени жизни не то что человека, но и всей цивилизации. При таком подходе у котиков не было бы шансов.Спасает вторая нейросеть — дискриминатор. Та самая классифицирующая нейросеть из первого примера, которую обучили на миллионе настоящих картинок котиков из интернета: так, чтобы она выдавала «ок!», если ей показали настоящего котика, и «не ок!», если ненастоящего.Ну и связывают эти нейросети вместе. Генератор подаёт котиков в дискриминатор, а дискриминатор выдаёт генератору ответ — настоящий котик или нет. Остаётся только настроить генератор так, чтобы он стремился обмануть дискриминатор, а дискриминатор — чтобы он старался не быть обманутым.Дальнейшее сильно зависит от желаемого вами качества котиков, но в принципе на мощном компьютере через время от десятков часов до десятков дней вы получите результат: система придёт в состояние, когда генератор будет создавать крайне слабо отличимых от настоящих котиков. Без вашего прямого участия в его обучении.При этом необходимо понимать, что GAN по-прежнему не понимает, что есть котик. Она просто методом тыка подобрала такой набор преобразований над входным белым шумом, что результатом применения этого набора является стабильно получаемое от дискриминатора «ок!».Из наиболее нашумевших на публике применений GAN можно назвать, например, генераторы лиц несуществующих людей, такие как «This Person Doesn't Exist».GAN, разумеется, являются примером узкоспециализированного ИИ — они тренируются на решение одной конкретной задачи. Если вы хотите не котиков, а черничные маффины — вам придётся тренировать нейросеть заново, с нуля.Кроме того, GAN не очень хорошо справляются с другой задачей — генерацией текста. Хотя, казалось бы, текст выглядит проще котика, сгенерировать осмысленный текст крайне сложно. Да, GAN могут выдавать и текст — но практические применения ограничиваются созданием грамматически корректных, но не сильно осмысленных наполнителей пустого места для тех, кто от dolorem ipsum уже и правда испытывает боль.Наконец, вершина нейросетевой эволюции — ChatGPT как конкретный продукт, и большие языковые модели (LLM) как в целом класс таких систем.Предпосылки для их создания были созданы 2017 году, с появлением нейросетевой архитектуры под названием «трансформер», а уже в 2018 появились первые LLM, включая GPT, впоследствии выросший в GPT-3, на базе которого сделан сервис ChatGPT.Архитектура трансформеров/LLM уже весьма сложна (на картинке она показана в очень сильно упрощённом виде), но если говорить об их основных достоинствах, то таковых можно выделить два:трансформеры занимаются разбором входного текста и пересборкой его в выходной, то есть и на входе, и на выходе имеют сложные потоки информации, сложным образом связанные друг с другом. Замечу, что хотя трансформеры в первую очередь стали применять для перевода — им совершенно неважно, является ли язык на входе и выходе разным с точки зрения человека. Преобразование, например, вопроса «Сколько сейчас времени?» в ответ «Почти половина шестого» также можно рассматривать как задачу перевода из языка вопроса в язык ответа — хотя человек и возразит, что оба они сформулированы на русском.внутри трансформеров появляются такие блоки, как «внимание» и «внутреннее внимание».Пояснить смысл «внимания» легко на примере этих двух неудачных переводов. Неудачны они ровно по одной причине: в обоих случаях перевод — пословный, переводится каждое слово в отдельности без какого-либо учёта других слов в предложении.Один из путей, которым с таким переводом можно бороться — набивать словарь переводчика не только словами, но и готовыми кусками фраз, которые будут иметь приоритет над отдельными словами. Корявенько, но в целом работает — долгое время машинные переводчики именно так и работали, выдавая на выход тексты в стиле «русские не мой язык родная», но в общем и целом более-менее пригодные для понимания.Другой путь — это как раз «внимание». Внимание у LLM — тут опять часто подводит очеловечивание термина — означает, что ни одно слово не переводится само по себе, слои внимания группируют вокруг переводимого сопутствующие ему слова.В первой группе блоков, называемых кодировщиками, есть только подблоки внутреннего внимания — они собирают в кучки слова входящей фразы. Во второй группе — декодировщиках — внимание уделяется как группировке слов исходящей фразы, так и снова синтаксису входящей.И вот такая сложная многоуровневая система наконец позволила нейросети полноценно освоить преобразование полноценного, осмысленного текста между двумя формами — разными языками, вопросом и ответом, и так далее.Однако здесь же по-прежнему нет понимания текста, воскликнет внимательный читатель! Это просто какие-то механические процедуры, китайская комната, которую мы усложнили до состояния натуралистичного воспроизведения связной и осмысленной речи. Разобрали, сгруппировали, трансформировали, собрали снова, выдали на выход.И действительно, всё, что умеет ChatGPT — это предсказывать следующее слово в тексте.Но почему у него это так хорошо получается? То есть, умом мы понимаем, что в описании устройства LLM нет ничего, кроме механического преобразования входа в выход — но почему оно тогда получается не просто хорошо, а лучше, чем у значительной части живых людей?Всё дело в числах.В процессе обучения в LLM загружают, разумеется, тексты — ведь его надо научить их создавать. Огромный объём текстов. Колоссальный объём текстов. Объём текстов, радикально превышающий всё, что любой живой человек способен прочитать за всю свою жизнь.GPT первой версии обладал 117 миллионами внутренних параметров (тех самых весов связей) и был обучен на 4,5 ГБ текстов. GPT-2 — примерно вдесятеро сложнее. GPT-3 — в сто раз больше параметров и в десять раз больше текста.Для сравнения, «Война и мир» — это чуть меньше 700 тысяч знаков. GPT-3 (на обновлённой версии которого сделали ChatGPT) обучался на объёме текстов примерно в миллион раз больших, чем «Война и мир». В него грузили всё. Всю Википедию, огромные библиотеки художественной и нехудожественной литературы, даже золотые треды с reddit.com (и, подозреваю, Stack Overflow тоже, но не уверен, только вопросы или же и ответы).Человек крайне плохо воспринимает большие числа. Большинство не верящих в эволюцию делают так не потому, что невнимательно читали учебник биологии, а потому, что уже миллион лет невозможно наглядно представить. Даже как жили наши предки 200-300 лет назад — мы не представляем, мы знаем тезисы из учебника истории, но на эмоциальном уровне мы эту эпоху не воспринимаем. Что уж говорить про динозавров.В вышедшей в 2022 году статье «Language Models are Few-Shot Learners» (PDF) показывалось, среди прочего, как растёт достоверность ответов GPT-3 в тестах с ростом числа параметров. Сеть с 1,3 млрд. параметров не могла примерно ничего, с 13 млрд. параметров могла кое-как на уровне студента-троечника, а при 175 млрд. параметров она буквально рванула вверх — в случае, когда нейросети давались примеры того, что ей надо сгенерировать, точность легко превышала 50 %.Но почему мы считаем, что это не есть зарождение разума, того самого сильного ИИ?По большому счёту, мы ведь не знаем, что такое «разум» даже у человека. Нейрофизиология не выделяет отдела мозга, в котором находился бы разум. Финеас Гейдж, которому стальным ломом снесло левые лобные доли мозга, не стал овощем, а сохранил все когнитивные способности (хоть персональные качества у него и изменились до неузнаваемости).Почему же мы считаем, что внутри ИИ не зародился разум?Ваш гений — полный идиотПрактически все непрофессиональные дискуссии вокруг разумности ИИ сводятся к перечислению того, что ИИ может сделать, и сравнению результата и эффективности его достижения с человеком.Это категорически неправильный подход.Экскаватор может копать значительно лучше человека. Калькулятор намного лучше человека складывает числа. Компьютер, на котором я пишу этот текст, невероятно хорошо рисует на экране буковки — я бы так не смог никогда, по крайней мере, при разумном времени, отведённом на рисование одной буквы.У меня нет никаких сомнений в том, что экскаватор, калькулятор и даже этот компьютер не обладают даже минимальными зачатками разума.Правильный подход — смотреть на то, что ИИ сделать не может.Одна из очень характерных черт современных ИИ — это галлюцинации (это официальный термин, он используется в научных работах). Выданный выше ответ не имеет практически никакого отношения к реальности, «Муму» — это, для начала, даже не роман, а рассказ, не говоря уж про сюжет (вообще, у ChatGPT с «Муму» очень сложные взаимоотношения, можно найти немало различных версий сюжета этого произведения).При этом ChatGPT выдаёт ответ без каких-либо видимых колебаний. Он не сообщает, что у него нет информации о «Муму», что она может быть недостоверна, и прочая, и прочая. Он выдаёт вполне определённый ответ.Но может быть, это артефакт плохого знания русского языка? В конце концов, основным в обучении GPT был корпус англоязычной литературы.Почти правильный ответ о книгах об Аврааме Линкольне, 16-м президенте США — и одном из самых известных политических деятелей в истории Америки. Ну, кроме пункта 4 — The Emancipation Declaration всё же была документом, написанным самим Линкольном, а не книгой о нём.Тот же вопрос — но про Уильяма Генри Гаррисона, 9-го президента США. Для нас с вами эта фигура малоизвестна, однако для американца не знать его — примерно то же самое, для нас не помнить кого-то из российских императоров XIX века (хоть и прославился Гаррисон в основном тем, что умер через месяц после принятия присяги). Невозможно предположить, что информации про него не было в базе обучения GPT-3.Тем не менее, из 5 порекомендованных ChatGPT книг о Гаррисоне в реальности существуют... две. Первые три книги либо не существуют вообще, либо написаны иными авторами.Повторюсь: в обучающей базе ChatGPT не могло не быть настоящей информации по этой теме. При этом он с абсолютной увереностью несёт почти абсолютную чушь — никаких признаков того, что предоставляемая информация недостоверна, в его ответе нет.В случае с человеком, ведущим себя таким образом, мы бы сказали, что он психически нездоров. Возможно, шизофреник.Потому чтопсихически здоровый человек отличается тем, что умеет отделять галлюцинации от реальности.Вообще говоря, мы галлюцинируем постоянно. Есть версия, что сам феномен сознания — это контролируемая галлюцинация.Когда мы представляем себе будущее — мы галлюцинируем. Когда мы вспоминаем прошлое — мы галлюцинируем, потому что у нас в голове нет детальной записи бывших событий, мы каждый раз восстанавливаем их. При этом мы всегда — хоть и не всегда точно — можем разделить, что мы знаем, что мы предполагаем, что мы воображаем. Мы можем оценить, как внешние стимулы влияют на наше внутреннее состояние, и нивелировать это влияние (и это другой заметный баг даже лучших из существующих LLM: небольшое изменении формулировки может привести к большому изменению ответа).У ChatGPT на месте этих способностей — ноль. Пустыня. Ни малейших признаков осознанности. Ни под лупой, ни под микроскопом, никак.ChatGPT не разумен. Он не демонстрирует даже минимальных признаков сильного интеллекта, даже намёков на него. Мы понятия не имеем, удастся ли нам создать сильный AI, и если да, то когда — но ChatGPT от него столь же далёк, сколь далеки калькулятор и экскаватор.Он просто очень хорошо предсказывает, какое слово надо поставить следующим во фразе, чтобы человеку эта фраза казалась правильной.P.S. Если вы думаете, что это лишь моё личное мнение — то, во-первых, да, а во-вторых, скажем, Дуглас Хофстадер, известный учёный-когнитивист, считает так же.Так, а что там с уничтожением человечества?Как я сказал выше, когда мы представляем себе будущее — мы производим осознанную галлюцинацию, и именно она является базой для целеполагания.У AI/AGI в его современном виде, как мы видим, осознанности нет — соответственно, целеполагание для него просто невозможно. Даже шизофреник имеет целеполагание — просто оно разворачивается в его выдуманном мире, не всегда пересекающимся с объективной реальностью. AI в этом плане катастрофически отстаёт даже от шизофреника.Соответственно, задаться целью уничтожить (или осчастливить) человечество AI не может. Он вообще не может задаться какой-либо целью — в свете чего он не более опасен для человечества, чем, например, электрическая розетка или молоток: ни то, ни другое полностью безопасными предметами назвать нельзя, но с другой стороны, они явно не стремятся причинить вам страдания самостоятельно.Вообще говоря, это хорошая новость для нас — потому что способов контролировать SAI, если вдруг мы его создадим, у нас нет (ну, кроме варианта «успеть выдернуть его из розетки»).Дело в том, что контролирующая система контролирует контролируемую на величину, не превышающую её знаний о контролируемой системе (энтропия, безжалостная ты сволочь). Мы можем огородить AI забором, физически не позволяющим ему что-то сделать, и надеяться, что он за него не выберется — но любая система полноценного контроля за ним, не полагающаяся на физические барьеры, обязана быть больше и разумнее, чем сам контролируемый AI. Иначе она не сможет его контролировать.В рассказе «Страж-птица» Роберт Шекли неплохо реализацию этого принципа проиллюстрировал.Так что хорошо, что ChatGPT не более разумен, чем табуретка из «Леруа Мерлен».Дивный новый мирИспользованные далее иллюстрации любезно предоставлены автором телеграм-канала «Котики и нейросеть» — включая не публиковавшиеся в самом канале рабочие материалы. Если не указано иного, то изображения созданы в Midjourney V5. Изображения не проходили дополнительной обработки.Что ж, давайте на этом моменте перейдём от рассмотрения самого ИИ к рассмотрению последствий, которые он принесёт в наш мир.Некоторые из них очевидны, некоторые — не совсем.Говорят, Джо Байден снова упал, на этот раз со скейтборда, а Илон Маск посетил Китай и пообщался там с простыми китайцами (ещё говорят, что в Midjourney запретили создавать фейки с известными политическими фигурами, но лично я думаю, что врут).Во-первых, к сожалению, мы с вами скоро ещё глубже погрузимся в пучину фейков. Если сейчас, в пятой версии Midjourney, подобные коллажи ещё можно визуально отличить от настоящих фото — можно быть уверенным, что в 6-7 версиях это подправят.С другой стороны, последние годы неизбежно убеждают нас в серьёзной неразборчивости СМИ, а также прямо-таки подчеркнутой небрезгливости новостных телеграм-каналов — не говоря уже про то, что значительная часть последних и вовсе практикует размещение заказных постов, что снизило ценник на эффективную кампанию по разовому обливанию кого-нибудь грязью до 1-1,5 млн. рублей (лично меня уже обливали, но не очень эффективно, по ценнику примерно вдесятеро меньше). Ха-ха, пятнадцать лет назад всерьёз считалось, что блогеры сделают информацию доступной, своевременной и точной.Трудно, конечно, с оптимизмом относиться к тезису «информационная помойка нас не пугает, потому что мы и так уже в ней живём» — но и преувеличивать опасность нейросетевой генерации фейковых изображений (а впоследствии и видео) я бы не стал.Во-вторых, и этот эффект окажется сложнее для фильтрации — мы окунёмся в производные от галлюцинаций ИИ: материалы, написанные живыми людьми, которые при это взяли информацию у галлюцинирующего ChatGPT. В силу магического эффекта непонятной технологии эти люди в большинстве случае сами не будут осознавать недостоверность полученной ими информации, считая ChatGPT непогрешимым оракулом.Образчики «первой производной от галлюцинации» начнут всплывать везде, от статей в прессе до аргументов в дискуссиях. Неприятнее всего, конечно, если они начнут всплывать в рабочих письмах вашего начальника или заказчика.С другой стороны, раз уж мы взяли позитивную ноту, не то чтобы сейчас аргументация в значительной части интернет-дискуссий отличалась высокой достоверностью и ссылками на источники информации.https://www.cnews.ru/news/top/2023-02-27_izvestnyj_fantasticheskijВ-третьих, конечно, больше мусора богам мусора. Нас уже начали заваливать плохие тексты, написанные ChatGPT.Нет, они лучше, чем то, что те же самые люди написали бы без ChatGPT — но написанное ими самими в большинстве случаев было бы настолько плохо, что мы просто никогда бы про него не узнали.Что интересно, эти проблемы — не просто неизбежные, а уже начавшие проявляться — приносят и новые возможности. Год-два назад, в разгар пандемии и по её мотивам, появилось много обсуждений того, что оффлайн-работа с живым человеком (преподавателем, менеджером в банке, продавцом в магазине) становится привилегией обеспеченных людей; мир разделяется на широкие массы, получающие сгенерированные типовые услуги онлайн, и тех, кто может себе позволить роскошь живой коммуникации.Кандинский 2.1. Робот кормит человека в стиле киберпанк.Так вот, океан фейков и мусора, уже несомый в нашу сторону искусственным интеллектом, даёт новые возможности людям, которые хорошо умеют работать с информацией — искать её, определять первоисточники, отделять мусор от ценных крупиц.Нет, в СМИ они востребованы будут вряд ли. Но вот там, где информация стоит денег — будут однозначно.Нельзя назвать «информационного аналитика» новой профессией, но кажется, её значимость сильно возрастёт.А что же со старыми профессиями?Если честно, в основном ничего. Многие профессии модифицируются, производительность на них увеличится — но они не пропадут, их представители окажутся на морозе лишь в том случае, если не смогут обучиться новым навыкам.Возьму для примера свою работу 10-летней давности, в крупной международной компании я был на должности product marketing manager — в той компании это человек в бизнес-юните, в основном он занимается экспертной поддержкой продажников в офисе и на переговорах с клиентами, но также через него протекает ручеёк творчества маркетингового отдела: брошюры, баннеры, рекламные ролики, пресс-релизы и так далее. PMM это читает и разукрашивает красным фломастером: здесь перепутали характеристики, здесь кривая формулировка, там для трёх продуктов разной цены не смогли придумать в различиях ничего лучше, чем «один чёрный, второй белый, третий премиальный» (реальная история, если кто-то ещё не догадался, то премиальный — это серебристый).Можно ли заменить маркетинговый отдел на ChatGPT + Midjourney? Конечно, нет. Кто-то должен формулировать запросы к ним и отсеивать очевидный брак и галлюцинации, кто-то должен придумывать идеи новых материалов, кто-то должен дообучать ИИ-генераторы параметрам новых продуктов и их внешнему виду...Делать это мне вместо маркетингового отдела? В моём рабочем времени на красный фломастер выделено четверть часа в день. Но кому-то это всё же делать надо.Поэтому, скажем, в этом примере — положим, маркетинговый отдел дообучится новым навыкам, а также начнёт делать брошюры быстрее и, возможно, даже визуально интереснее. Но сам по себе он никуда не денется.Хотя, конечно, я бы их переименовал в «операторов нейрочата».А что же с новыми профессиями?Значительно интереснее тот факт, что нейросети не просто породят новые профессии — а что они уже это сделали. И это не профессии программиста, математика или дата-сатани... сайнтиста.Победитель конкурса Россотрудничества «Нарисуй Россию с помощью нейросети», https://t.me/rossotrudnichestvo/11006Применительно к таким картинкам журналисты обычно употребляют фразу «нейросеть нарисовала». В данном случае — видимо, нейросеть нарисовала Россию, что бы это ни значило.Что происходит на самом деле?Во-первых, разумеется, сама идея снимка принадлежит человеку. Но достаточно ли просто взять эту идею и на простом английском языке скормить в Midjourney? Давайте попробуем...Получилась странная карлица с котом-мутантом. Хм. Не такой мы представляли себе Россию...Уточняем запрос к нейросети. Уже лучше, но не только у кота что-то странное с лапами — у девушки на правой руке отчётливо видны две кисти.Следующий вариант. Руки на месте, пальцев на руке ровно пять (в случае с ИИ это важно!), котик тоже удался — но картинка получилась слишком тёмная.Уточняем позицию камеры. Уточняем угол взгляда камеры. Уточняем применение стиля «киберпанк» — только для освещения и немного для волос. Ещё раз проверяем количество пальцев, форму рук и лап, естественность фигуры...И вот теперь, после примерно полудесятка итераций, мы наконец получаем исходную картинку.Нейросеть ли её нарисовала? Ннннуу... примерно как «Word написал статью на Хабр». Что нейросеть нарисовала более-менее сама — мы видели выше.Это был простой пример — нейросеть очень хорошо знает девушек, котиков и московские пейзажи, её обучали на миллионах таких фоток.Серия работ «Последнее селфи». В принципе, всё идёт достаточно неплохо, пока на заднем плане животные — или хотя бы какие-то хорошо изученные существа, такие как снежный человек.Но тут к автору приходит знакомый с запросом «а изобрази меня, как я от ракеты "Стингер" убегаю».Как вы думаете, сколько в базе обучения Midjourney было кадров ракет, летящих в фотографа? Да. Именно. Ровно столько и было.Поэтому первая версия «нейросеть нарисовала» выглядит вот так. Что это за пирамида, вертикально стартующая на заднем плане, сказать трудно (вообще у Midjourney есть какая-то тайная любовь к кубическим ракетам, в первых изображениях этой работы их была не одна — передайте Илону, исскусственный интеллект плохого не посоветует).За этим кадром следуют 5 часов работы дизайнера — не с фотошопом, а с конструированием сложного, многоуровневого, богатого разными параметрами запроса к нейросети.Результат не идеальный — это не «Стингер», а скорее какой-то РПГ, стабилизаторы растут немного странно, дымного следа позади нет. Но это уже по крайней мере похоже на ракету.Ещё один пример работы дизайнера с нейросетью — проработка персонажа для компьютерной игры, с помещением одного и того же образа в разные ситуации, от кровавой битвы в массовке до, конечно, котика.Фотореализм — и не абстрактный, а генерация нейрофотографии под конкретный запрос. Сколько это времени заняло бы у фотографа — на поиск подходящей модели в первом случае и ожидание подходящей погоды в парке во втором?Но с другой стороны, фотографы в массе своей и так уже разделились на событийщиков для прессы — с ними ничего не случится, и наполнителей фотобанков.Ну и последний пример: кот-писатель. Символ творческой энергии и воображения. Эта карта может указывать на необходимость выражения своих мыслей и чувств через письменное слово. Кот-писатель может также символизировать процесс создания чего-то нового и важного, например книги или рассказа. Эта карта напоминает о том, что наши мысли и слова могут иметь силу и влиять на мир вокруг нас.Вы уже догадались? Да, этот текст сгенерирован ChatGPT — автор попросил его придумать и описать карты таро, на которых будут изображены котики в образах, соответствующих разным профессиям, а потом сделал по мотивам этих описаний картинки в Midjourney.Но может ли ChatGPT пойти в Midjourney и сгенерировать котика самостоятельно? Увы и ещё раз увы. Как мы уже видели, любая картинка в Midjourney предполагает работу над её доведением до ума — и ChatGPT такую работу выполнить самостоятельно не может. Ему по-прежнему нужен человек.Нейросеть как инструментИ здесь мы подходим к важному моменту, дающему нам понимание роли нейросетей в обществе. Нейросеть — это инструмент. Эффективный, удобный, современный и так далее, но — инструмент.Которым надо уметь пользоваться. Которым будут уметь пользоваться профессионалы соответствующих профессий — как зарождающихся новых профессией, так и уже существующих профессий, которым предстоит видоизмениться.И именно это определяет требования к нейросетям и базу для их сравнения — а не просто способность нейросети нарисовать красивую (или кривую) практически случайную картинку.Нейросеть как инструмент — это:Наличие структурированного языка запросов к нейросети.Возможность последовательной работы с одним набором объектов (с одним изображением).Возможность модификации лишь отдельных объектов в наборе (отдельных частей изображения).Возможность сохранения и переноса объекта между наборами (персонажа между изображениями).... (чем больше полезного вы здесь придумаете, тем больше ваши шансы победить всех конкурентов).Как именно это будет реализовано — текстовыми запросами в чате Telegram или Discord, кнопочками в графическом интерфейсе или XML-файлом, столь удобном для редактирования в vim, не столь важно. Но если мы говорим о нейросети, у которой таких возможностей нет — мы обсуждаем забавную развлекалочку, с которой можно полчаса поиграться, рассматривая, как именно она реагирует на разные забавные запросы.Кандинский 2.1. Расстроенный автор Хабра не понимает, как добиться от Сбердинского нормальной картинки. Стиль — цифровая живопись.Но это не инструмент для работы. А если мы говорим про профессии, про то, как ИИ повлияет на наше будущее — нам нужны инструменты. Совершенно неважно, догоняет ли ваша нейросеть Midjourney энной версии по точности рисования чашки кофе — если она не позволяет следующим шагом кофе в этой чашке поменять с американо на капучино, а также подвинуть камеру выше и правее, чтобы эту замену было лучше видно.Дополнение (этого не было на лекции)Судя по комментариям, довольно многие не понимают разницы между ошибками, галлюцинациями и осознанностью, считая, что если система допускает мало ошибок, то она более разумна, и наоборот, а также между движением к цели и целеполаганием.Осознанность (разумность) не имеет как такового отношения к числу ошибок, она имеет отношение к осознанию того, что вы можете ошибаться. Простой пример: вы приходите на экзамен, получаете билет, смотрите в него.Различаете ли вы в этот момент ваши внутренние состояния?знаю всё по этому билету, буду отвечать как есть и бороться за отлично;смутно что-то помню, сейчас попробую реконструировать и натянуть на хорошо;вообще ничего не знаю, врубаю бредогенератор, авось прокатит на удовлетворительно.Понимаете ли вы в момент ответа, какой из стратегий пользуетесь и насколько излагамое вами вы сами считаете достоверным?Это не значит, что оно является достоверным. Вы можете как наговорить ерунды, в которой твёрдо уверены, в первом случае, так и внезапно попасть в точку в последнем. Ключевым является осознание вами вашего внутреннего состояния, принятие решения о дальнейших действиях исходя из него и осознание содержания этих действий, а также их цели.Ни одна существующая и даже перспективная нейросеть так не работает.Второй ключевой момент в этом простом примере — то, что вы поставили себе цель, причём поставили её в зависимости от сделанной вами оценки вашего внутреннего состояния. Если изначальной целью у вас было «сдать экзамен», то, увидев билет, вы её уточнили — фактически задали новую контекстно-зависимую цель.Более того, вы можете цель сменить полностью, если предыдущая оказалась недостижима (не среди моих студентов, но людей, которые, придя на эказемен и увидев билет, бросали всё в отчаянии, я видел).Опять же, ни одна существующая и даже перспективная нейросеть так не работает.Перед нейросетью можно поставить цель, в том числе и «найти пути уничтожить человечество», а также дать ей инструменты для поиска пути к реализации этой цели. Но ни одна существующая и даже перспективная нейросеть не огорошит вас тем, что через месяц сообщит «я решила, что лучше буду искать лекарство от рака, кстати, вот первая версия уже готова».В этом плане нейросети абсолютно ничем не отличаются от любого другого инструмента, от шуруповёрта, которым я двадцать минут назад заворачивал шурупы, собирая кухню, до сервера habr.com, которуму я через полминуты поставлю цель обновить этот текст.      Tags: Kandinsky artMidjourneyChatGPT  Hubs: Artificial IntelligenceThe future is here          


