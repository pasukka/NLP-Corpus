

OpenAI отказалась раскрывать исследовательские материалы для GPT-4 / Habr


               OpenAI отказалась раскрывать исследовательские материалы для GPT-4  Reading time  
    3 min
   Views  3.5K Machine learning *Product Management *Copyright Artificial Intelligence       OpenAI после анонса новой языковой модели GPT-4 отказалась публиковать исследовательские материалы, лежащие в её основе.Компания поделилась результатами тестов GPT-4, а также некоторыми демонстрациями, но практически не предоставила информации о данных, используемых для обучения системы, затратах электроэнергии на вычисления или конкретном оборудовании или методах, использованных при создании.Участники сообщества ИИ раскритиковали это решение, отметив, что оно подрывает дух компании как исследовательской организации и затрудняет воспроизведение её работы другими. Одновременно это затрудняет разработку средств защиты от угроз, исходящих от систем ИИ, таких как GPT-4.Одним из тех, кто выразил недовольство, стал Бен Шмидт, вице-президент по информационному дизайну в Nomic AI. По его словам, с выходом GPT-4 «можно положить конец “открытому” ИИ».Шмидт приводит выдержки из раздела технического отчёта о GPT-4, который гласит: «Учитывая как конкурентную среду, так и последствия для безопасности крупномасштабных моделей, таких как GPT-4, этот отчёт не содержит дополнительных сведений об архитектуре (включая размер модели), оборудовании, вычислениях, построении набора данных, методе обучения и т. п.».В интервью The Verge главный научный сотрудник и соучредитель OpenAI Илья Суцкевер подтвердил, что причины, по которым OpenAI не делилась дополнительной информацией о GPT-4 — страх перед конкуренцией и опасения по поводу безопасности: «GPT-4 разработать непросто. Почти все сотрудники OpenAI работали вместе в течение очень долгого времени, чтобы создать эту вещь. И есть много компаний, которые хотят делать то же самое, так что с точки зрения конкуренции вы можете рассматривать это как развитие отрасли». Он отметил также, что именно опасения конкуренции, а не вопросы безопасности стали главным фактором при принятии такого решения.Это заметное изменение в политике OpenAI, которая декларировала целью «создание ценностей для всех, а не для акционеров» и выступала за «свободное сотрудничество» с другими компаниями в этой области. Изначально OpenAI была некоммерческой организацией, но теперь в неё инвестируют такие IT-гиганты, как Microsoft.Уильям Фалькон, генеральный директор Lightning AI и создатель инструмента с открытым исходным кодом PyTorch Lightning, понимает это решение с точки зрения бизнеса. Но он также сказал, что этот шаг создаёт «плохой прецедент».Ещё одна причина, по которой OpenAI скрывает детали работы GPT-4, — это юридическая ответственность. Языковые модели ИИ обучаются на огромных наборах текстовых данных, при этом информацию берут из Интернета. Генераторы изображений ИИ уже столкнулись с юридическими проблемами.Однако Суцкевер считает, что «обучающие данные — это технология». Он не ответил на вопрос, включают ли они материалы, защищённые авторским правом. В целом, Суцкевер согласился с критиками OpenAI в том, что идея моделей с открытым исходным кодом «достойная». По этим причинам OpenAI предоставила некоторым академическим и исследовательским учреждениям доступ к своим системам.Джесс Уиттлстоун, руководитель отдела политики в области ИИ в британском аналитическом центре The Center for Long-Term Resilience, обеспокоена тем, что возможности искусственного интеллекта развиваются быстрее, «чем мы можем адаптироваться к ним как общество». Она сказала, что OpenAI использует уважительные причины для своих действий, но это вызывает опасения по поводу централизации в мире ИИ.«Эти решения не должны приниматься отдельными компаниями», — считает Уиттлстоун. — «В идеале нам нужно систематизировать практику, а затем привлечь независимые третьи стороны, которые будут играть более важную роль в тщательном изучении рисков, связанных с определёнными моделями, и в том, имеет ли смысл публиковать их в открытой среде».OpenAI представила GPT-4 14 марта. Модель способна интерпретировать не только текст, но и изображения. Также модель теперь распознаёт схематичные образы, в том числе и нарисованные от руки.      Tags: openaigpt-4языковая модельискусственный интеллектобучающие материалыавторское правобезопасностьисследователисокрытие данныхконкуренция  Hubs: Machine learningProduct ManagementCopyrightArtificial Intelligence          


