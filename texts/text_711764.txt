

Падаем в кроличью нору. Ищем способ характеризовать текстовые датасеты / Habr


               Падаем в кроличью нору. Ищем способ характеризовать текстовые датасеты  Reading time  
    10 min
   Views  1.5K MTS AI corporate blog Machine learning *Natural Language Processing *      Всем привет! На связи Игорь Буянов, разработчик в команде разметки MTS AI. Сегодня я поделюсь с вами своими наработками, появившимися во время изучения метрик оценки генерации данных. Когда я только пришел в команду разметки, эта задача была особо актуальной - нас тогда просили нагенерить данные под тестирование информационного бота по COVID. Дело в том, что тестирование результатов выполнялось вручную, что значительно замедляло работу. Каких-либо автоматических метрик оценки качества генерации тестовых данных не существовало.В какой-то момент мне надоело это терпеть, и я решил посмотреть, а как качество текстов оценивают разработчики языковых моделей. У них точно есть перплексия, может, есть что-то еще.Спустя время, проведенное за штудированием статей, я нашел кандидата среди известных метрик для оценки качества генерации, но кроме того, к своему удивлению, у меня появилось несколько теоретических тезисов о качестве данных вообще. В этом посте я делюсь ими с сообществом в надежде на дальнейшее обсуждение. Для лучшего понимания дальнейшего текста рекомендую прочитать эту статью.Немного саморекламы Я решил создать канал в телеге. Буду там постить выжимки из статей (может быть тогда очередь закончится), мысли, части вот таких статей и анонсы самих статей. Традиционное понятие генерализацииВ теории машинного обучения под понятием генерализации понимается способность алгоритмов обобщать характеристики объектов одного класса по обучающей выборке, в результате чего появляется возможность предсказать принадлежность ранее невиданных объектов к этому классу. В другом источнике [2] генерализация определяется как способность модели правильно адаптироваться к невиданным данным, семплированных из того же распределения, с помощью которого создавалась модель.Хорошо известно, что с генерализацией тесно связаны два понятия: смещение модели (model bias) и дисперсия модели (model variance). Напомню, что смещение модели определяется как где  - предсказание обученной модели, а  предсказание истинной модели. Другими словами, смещение показывает насколько точно модель способна выразить зависимость в данных или сколько предположений о типе зависимости в данных было сделано. Большое значение смещения модели говорит о недообучении модели (underfitting).  Пример: линейная модель, обученная на данных с кубической зависимостью, будет иметь больше смещения, чем та же модель, но обученная на данных с линейной зависимостью.Дисперсия модели характеризует степень изменчивости модели при изменении обучающей выборки. Определяется она какДругая трактовка может быть такой: это тенденция модели подгоняться под обучающую выборку, запоминать ее, что может привести даже к идеальному описанию зависимости в тренировочных данных. Если такое случилось, то модель вовсе не способна предсказывать данные, которых не было в обучающей выборке.  Говорят, что модель переобучилась (overfitting), при этом значение дисперсии будет велико.Известно, что смещение и дисперсия связаны между собой обратной пропорциональностью - чем больше квадрат смещения, тем меньше дисперсия и наоборот. Эта взаимосвязь отражает сложность модели - насколько сложные взаимосвязи она способна выучить. Оптимальной моделью, которая описывает наперед заданный набор данных, можно назвать такую модель, которая дает минимально возможные смещение и дисперсию.А как насчет оценки влияния данных на генерализацию?С развитием технологий машинного обучения, в частности, нейронных сетей, разработчики получили возможность обучать модели,  способные обнаруживать такие зависимости, о которых даже можно не подозревать. С одной стороны, это хорошо, ведь именно этого мы и хотим - автоматического извлечения зависимостей. С другой - не все зависимости одинаково полезны и равны. Не имея возможности охарактеризовать данные, откуда эти зависимости извлекаются, разработчики полагаются на удачу, надеясь, что модель обучится тому, что надо. И такие модели используют в проде, ведь они действительно показывают превосходные результаты на тестовых данных.Но, как было упомянуто в начале, в одном из определений генерализации имеется условие близости распределения тренировочных и тестовых, т.е. ранее невиданных, данных. Это условие является весьма существенным ограничением при работе в проде. Например, при создании замены оператора поддержки, например, делается предположение, что человек будет говорить и спрашивать примерно так, как это отражено в исторических логах клиент-оператор. Хотя это предположение оправдано с точки зрения и практики, и бизнеса, понимание границ применимости модели давало бы больший контроль над процессом ее создания и оценкой ее возможности работы в разных условиях.Данные являются одним из ключевых компонентов построения систем машинного обучения, но никаких способов оценки влияния данных на способность к обобщению нет. И кажется именно такие способы позволили бы разработчикам быть уверенными в том, что модель выучилась тому, что от нее требовалось.Характеристики данныхУченые заметили, что в современных датасетах, предназначенных для оценки моделей в решении определенных задач, таких как QA, NLI, STS и т.д., существуют зависимости, которые существенно упрощают предсказание. Например, в SNLI в значительной части примеров с меткой "counteract" встречается токен "not" [1]. Подобные зависимости могут быть упущены или неочевидны для человека ни при сборе данных, ни при их использовании. Модель, однако, подобные зависимости может найти и, при достаточном их количестве в данных, метод обратного распространения ошибок поощряет использование именно этих зависимостей ведь они помогают модели быстрее научиться правильно решать задачу. При этом сложные зависимости игнорируются, потому что высокое качество уже достигнуто с более простыми зависимостями.Поскольку часто для создания тестовой и тренировочной выборки используется равномерное распределение, то тестовая выборка тоже содержит эти простые зависимости. Опираясь на них, модель создает видимость высокого качества. Точнее качество действительно будет высоким, но ведь не все то counteract, что содержит not: как только этих простых зависимостей не станет, модель начнет сильно ошибаться.Можно сказать, что большая представленность в датасете этой зависимости смещает модель в сторону класса, с которой эта зависимость ассоциирована. С другой стороны, помимо частицы "not" в действительности есть еще много зависимостей, ведущих к классу "counteract", которые просто были мало или вовсе не представлены в данных. Кроме того, частица "not" не всегда используется только в текстах "counteract". Отсутствие примеров, показывающих другие зависимости кроме "not", и другие сценарии для этой частицы можно выразить как малое разнообразие (дисперсия по-русски) данных.Начальные положенияДля простоты будем рассматривать задачу классификации на текстовых данных. Для того чтобы иметь возможность обучать модели машинного обучения на текстовых данных  объемом  с метками , их обычно преобразуют в векторное пространство признаков  размерности  с помощью функции преобразования . Разнообразие таких функций и методов весьма обширно:матрица терм-документ,матрица PMI,матрица TF-IDF,word2vec,fasttext,BERTПервые три метода для удобства назовем количественными, поскольку эти методы предполагают подсчет каких-либо единиц: токенов, н-грамм, pos-тегов.Представления текстовых данных можно разделить по лингвистическому уровню, на котором они оперируют:морфологический - уровень граммем, частей слов, н-грамм символов;лексический - уровень отдельных слов;синтаксический - уровень частей речи, взаимосвязей слов в предложении;семантический - уровень смысловой нагрузки и значений;смешанный - комбинация предыдущих уровней;универсальный  - оперирование на всех уровнях сразу.К примеру, матрица терм-документ на униграммах токенов имеет лексический уровень, а на униграммах pos-тегов уже синтаксический. Fasttext будет иметь смешанный уровень, т.к. кодирует семантику вместе с морфологией. BERT же кодирует все типы представлений, поэтому его можно назвать универсальным.Определение смещения данныхЗадав преобразование  на данных  определим смещение данных следующим образомгде классификатор, взятый из какого-либо простого семейства (линейные модели),подмножество , которое мы тестируем на содержание смещения, - тестовый набор данных, сгенерированный из D, - распределение вероятностей над всеми возможными тестовыми наборами , - точность. это оценка предсказуемости (predictability score), которая определяется какВыражаясь словами, эта оценка показывает, насколько надежно в среднем модель  может корректно предсказать , используя преобразование , когда модель натренирована на случайно сформированным наборе данных , который не содержит .Таким образом, данное определение смещения показывает насколько сильно модель способна эксплуатировать признаки, полученные с помощью , используя для обучения и тестирования подмножество . Для получения такого подмножества , которое бы сводило к минимуму подобную эксплуатацию, был разработан алгоритм AFLite. Данный алгоритм был реализован и протестирован по протоколу тестирования с использованием синтетических данных из статьи.Стоит заметить, что именно способ представления определяет набор зависимостей, который доступен для модели, а значит и набор смещающих зависимостей. Логично предположить, что, чем больше доступно зависимостей, тем больше среди них окажется смещений. Но без сложных зависимостей иногда просто не решить сложные задачи.Эмпирическое определение разнообразия данныхЕсли с моделью смещения данных мне помогла литература, то с разнообразием данных сложнее. Исходя из вышесказанного о том, что разнообразие должно отражать разные сценарии использования признаков, я подумал, что в первом приближении можно использовать уровень разнообразия текстов, как некоторого посредника. То есть вся идея звучит так: чем разнообразнее текст у конкретного класса, тем больше разнообразие данных, тем больше сценариев использования представлено. Осталось узнать, как это разнообразие можно померить.Как раз в ходе поиска меток оценки генерации текстов была найдена статья, в которой анализировались различные метрики разнообразия текстов. Среди них указывалась Self-Bleu - модификация известной метрики качества машинного перевода, призванная оценивать отличие сгенерированных ответов диалоговых систем или языковых моделей.  Отличием self-bleu от оригинала заключается в том, что вместо референтного корпуса используются все сгенерированные тексты, кроме тестируемого. Сама формула вычисления остается такой же, выглядит она следующим образом [4]гдеBP это т.н. Brevity Penalty - веса для компонент (обычно берутся так ) - число грамм - точность по  грамме, определяемая следующим образом где - проверяемый текст,  - референтный корпус.Таким образом, чем больше совпадений н-грамм между референтным корпусом и проверяемым текстом, тем выше значение этой метрики. В контексте self-bleu получается, что чем выше значение этой метрики, тем больше конкретный сгенерированный текст похож на другие. Соответственно, чем больше текстов с высоким значением метрики, тем менее разнообразными в среднем являются сгенерированные тексты.Исходя из того, что мы противопоставляем разнообразию смещение, и что для расчета BLEU используется количественное представление данных по н-граммам, можно выбрать  Self-Bleu в кандидаты метрики для разнообразия данных.Был проведен пилотный эксперимент в поддержку этого утверждения. Для тестирования были отобраны два класса по две тысячи примеров из датасета интентов нашего чат-бота Смарти, которые показывали высокую и среднюю оценку разнообразия по self-bleu по 3-граммам. К этому датасету был применен AFLite, который на каждой итерации обучения использовал тысячу примеров, в качестве базовой модели использовалась логистическая регрессия, а в качестве функции представления использовалась матрица терм-документ из 3 н-грамм и от 1 до 3 н-грамм. Нижним пределом фильтрации датасета была одна тысяча примеров. После отработки AFLite, на полученном датасете снова был посчитан self-bleu. Результат представлен, как наложение двух гистограмм, показывающих распределение self-bleu по примерам. Синим цветом обозначена гистограмма исходного датасета, красным - после отработки AFLite, а фиолетовым - пересечение. В названии гистограмм фигурирует среднее значение self-bleu исходного датасета, а после стрелочки - после обработки.Представление по 3-граммамПредставление по набору от 1 до 3-граммНа первой гистограмме четко видно изменение профиля разнообразия, а также понижение среднего значения. На второй же эта тенденция выражена гораздо слабее - возможно из-за большего количества признаков, которые получаются при генерации такого набора.Стоит отметить, что метрика является количественной, работающей на лексическом уровне. И хотя лексика определяет многое в текстах, хорошо бы использовать всю мощь универсальных представлений.Понятие устойчивости моделиВ исходной статье, где был представлен алгоритм AFLite и определение смещения, авторы показывают, что модель RoBERTa, обученная на обработанном с помощью их алгоритма SNLI, показывает сравнительные или лучшие результаты на специальных датасетах, которые спроектированы с детальным контролем различных взаимосвязей(рисунок ниже). Идея такого тестирования заключается в том, что тестовые датасеты могут не иметь такого же смещения, как в тренировочном датасете, поэтому точность такой модели на таких датасетах должна падать. По сути, такое тестирование бросает вызов условию единства распределения тренировочных и тестовых данных. Такое тестирование называется внедоменным (out-of-domain), когда тестирование на данных из того же распределения, что и тренировочные данные, называется внутридоменным (in-domain).В таблице  обозначает обучение Роберты на полном SNLI,  - обучение Роберты на случайной подвыборке указанного объема,  показывает обучение на подвыборке, сформированным AFlite. В столбцах указаны три датасета, а ниже указаны название эвристики, которые использовались для того, чтобы заставить модель ошибаться, если она полагается на эти эвристики. Интуитивно кажется, что разницу между внутри доменной и вне доменной точностью можно назвать устойчивостью (robustness) модели к изменению распределения из которого поступают данные. Причем устойчивость модели зависит от данных, на которых обучается модель. Таким образом, качество данных в лице смещения и разнообразия определяет как модель себя будет вести - будет ли она работать на строго определенных данных или может позволить себе разные их вариации.Проблемы для изученияНа основе описанной концепции можно выделить некоторые дальнейшие проблемы для детального изучения:Провести дополнительные эксперименты, показывающие связь оценки self-bleu со смещением;Каким образом можно использовать универсальные представления для оценки разнообразия;Необходимо экспериментально подтвердить связь между оценкой self-bleu и устойчивостью обученной модели, как это сделано для AFLite;Математически связать self-bleu со смещением;Возможно, есть другие способы сформулировать понятие смещения;Найти способ определения внутридоменных данных от внедоменных.Со времени написания этого тезиса прошло уже достаточно много времени. Я успел исследовать вопрос по определению доменности данных и по использованию универсальных представлений. Я поделюсь с вами итогами своих исследований, как только наберу достаточное количество материала. Если у вас есть что добавить к моему теоретическому обзору, пишите в комментариях! На этом у меня всё. До скорого!СсылкиAnnotation Artifacts in Natural Language Inference DataMachine Learning Crash Course - GeneralizationAdversarial Filters of Dataset BiasesRe-evaluating the Role of BLEU in Machine Translation Research      Tags: natural language processingdatasetmetricsbleubiasvariance  Hubs: MTS AI corporate blogMachine learningNatural Language Processing          


