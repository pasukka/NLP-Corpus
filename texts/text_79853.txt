

Заметки об NLP (часть 4) / Habr


              2  January  2010 at 08:25  Заметки об NLP (часть 4) Artificial Intelligence Natural Language Processing *      (Начало: 1, 2, 3) На сей раз хочу немного отвлечься и порассуждать (а точнее, похоливарить) на тему статистических алгоритмов и вообще «обходных путей» компьютерной лингвистики.
В первых частях нашего разговора речь шла о «классическом пути» анализа текста — от слов к предложениям, от предложений к связному тексту. Но в наше безумное время появились и соблазны решить проблему «одним махом», найдя, если угодно, баг в системе или «царскую дорогу».

Кстати, о царских дорогах в науке и учёбе «вообще». Да простят меня читатели за пространную цитату:
Дезидерий. Как подвигаются твои занятия, Эразмий?
Эразмий. Кажется, Музы не очень ко мне благосклонны. Но дело пошло бы удачнее, если бы я мог кое что от тебя получить.
Дезидерий. Отказа ни в чем не встретишь — только бы это было тебе на пользу. Итак, говори.
Эразмий. Не сомневаюсь, что нет ни единого из тайных искусств, которого бы ты не знал.
Дезидерий. Если бы так!
Эразмий. Говорят, существует некое искусство запоминания, которое позволяет почти без хлопот выучить все свободные науки.
Дезидерий. Что я слышу? И ты сам видел книгу?
Эразмий. Видел. Но именно что видел: учителя не нашлось.
Дезидерий. А в книге что?
Эразмий. Изображения разных животных — драконов, львов, леопардов, разные круги, а в них слова — и греческие, и латинские, и еврейские, и даже из варварских языков.
Дезидерий. А в названии указывалось, за сколько дней можно постигнуть науки?
Эразмий. Да, за четырнадцать.
Дезидерий. Щедрое обещание, ничего не скажешь. Но знаешь ли ты хоть одного человека, которого бы это искусство запоминания сделало ученым?
Эразмий. Нет, ни одного.
Дезидерий. И никто иной такого человека не видел и не увидит, разве что сперва мы увидим счастливца, которого алхимия сделала богатым.
Эразмий. А мне бы так хотелось, чтобы это было правдой!
Дезидерий. Наверно, потому, что досадно покупать знания ценою стольких трудов.
Эразмий. Конечно.
...
Если рассказ заинтересовал, окончание прочтите сами. Это Эразм Роттердамский, «Разговоры запросто» (1524 год). На дворе XXI век, а книги из серии «за 21 день» не переводятся, заметим мы.

Так вот, предпринимаются и попытки анализа текста без какого-либо понимания его структуры. Причём как на уровне синтаксического анализа (создать дерево предложения, ничего не зная о законах построения фраз), так и на уровне дальнейшей работы, например, машинного перевода. Как это в принципе возможно? Ответ заключается в магическом заклинании «статистика».

Блеск и нищета статистикиСтатистика — штука замечательная, и имеет массу применений, в том числе и в компьютерной лингвистике. Но не панацея. Поскольку текстов за историю человечества накоплено уже несметное множество, возникает резонный соблазн изучать структуру новых текстов на основе существующих (предположительно, корректных). Надо сказать, что в предыдущих частях я нигде ещё не упоминал, каким именно образом строится дерево разбора фразы. Да, говорилось о грамматиках Хомского, но лишь как об идее, из которой выросла концепция phrase-structure parsing. Я специально нигде не писал, что грамматика Хомского реально используется для построения таких деревьев. Это необязательно так.

Как можно рассуждать о корректности фразы на основе накопленных данных? Например, так. Есть фраза «я съел пирожное». Давайте посмотрим, часто ли она встречается в существующих документах? А фраза «я съел веник»? Скорее всего, редко. А фраза «я съел пирожному», наверно, вообще не встречается. Отсюда и вывод, что первая фраза корректна, вторая небесспорна, а третья неправильна. Можно искать «коррелирующие словосочетания». Если какие-то слова встречаются друг с другом часто, вероятно, они зависят друг от друга. Так можно построить всё дерево. Хотя заметим, что такая система никогда не объяснит вам, чем именно фраза плоха. Просто сообщит, что так не говорят. Сами понимаете, для изучающего иностранный язык человека это не ахти какая помощь.

Можно пойти ещё дальше. Допустим, требуется перевести документ на другой язык. Какова вероятность, что вашу фразу никто и никогда не переводил? Вероятно, можно разыскать готовый перевод, хотя бы для части фразы. «Базой знаний» в таких проектах служат корпусы двуязычных текстов. Например, очень любят протоколы заседаний канадского парламента, так как ведутся они на двух языках: английском и французском. При этом тексты формальные, перевод строгий, без вольностей. Стало быть берём кусок текста, находим кусок соответствующего текста — и вуаля! (Конечно, я сильно упрощаю реальное положение вещей, но базовая идея такова). Отсюда и получаются шуточки с непонятным переводом. Было made in China, стало «сделано в республике Беларусь». Ну я это типа злободневно пошутил, а на самом деле именно так и происходит.

Вы не подумайте, что я нападаю на статистические алгоритмы в принципе. Существует масса прекрасных идей. Мне, например, нравится мысль анализировать трибанки (treebanks), но об этом в другой раз.

Поверить алгеброй гармониюА теперь я хочу немного поиграть в «верю — не верю». Во что верю, во что не верю.

Я верю, что с помощью анализа готовых текстов можно многое сделать. Я не верю, что «царская дорога» в машинной лингвистике существует. Лет тридцать назад казалось, что создание программы для игры в шахматы примерно эквивалентно созданию искусственного интеллекта. Нынешние результаты, когда компьютер может обыграть любого гроссмейстера, были приняты со смешанными чувствами. С одной стороны, да, успех, а с другой — очевидно, что алгоритмы не очень-то продвинулись, просто компьютеры резко подтянулись, и стало возможно просчитывать миллионы комбинаций и хранить обширнейшие библиотеки готовых партий.

В лингвистике аналогичным способом можно совершить рывок, но я уверен, что у подобного подхода есть теоретический потолок. Как ни крути, по крайней мере, создание «портретов объектов» необходимо. Ну как можно перевести на русский «sibling», если не знать, шла речь о брате или о сестре? Можно набить обширную базу, сделать так, чтобы компьютер переводил Байрона (по известным переводам), но по сути это будет та же Китайская комната Сёрля. Пока знаем входные куски, переводим, а шаг влево, шаг вправо — приехали. Да и машинный перевод — не единственная цель. Целью может быть, например, понимание текста, что бы ни стояло за этим термином. Скажем, пополнение базы знаний об описываемом в тексте мире. (Впрочем, это уже разговор о прагматике языка, явно не сегодняшнего дня тема).

То есть в каком-то смысле подход того же Google translate вызывает у меня противоречивые чувства. С одной стороны, спасибо за быстрый и удобный сервис. С другой стороны, мне кажется, они сместили «центр тяжести» в сторону статистики. Думаю, через несколько лет они упрутся в максимум, и тогда придётся искать другие методы. Особенно это очевидно для языков со свободным порядком слов и богатой морфологией — тут переводчик просто сходит с ума, так как вариантов перевода масса, однозначную статистику набрать трудно, и множество разнообразных входных фраз тоже велико. 

В конце концов, никому же не приходит в голову писать статистический компилятор Паскаля, хотя программ на Паскале тоже уже написано превеликое множество. Впрочем, в Гугле берут на работу вполне видных компьютерных лингвистов, так что, может быть, и у них будет не всё столь однозначно с используемыми алгоритмами.

Так, получилось как-то ядовито и эмоционально :) Но это ничего, в следующих частях вернёмся к более продуктивному разговору. Хотя и здесь, видимо, не всё сказано. Ну да ладно, напишу продолжение, ежели чего.    Tags: NLPобработка текстовкомпьютерная лингвистика Hubs: Artificial IntelligenceNatural Language Processing          


