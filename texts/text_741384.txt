

Геолоцировать пользователя по Tweet-у: машинное обучение, часть I / Habr


               Геолоцировать пользователя по Tweet-у: машинное обучение, часть I  Reading time  
    4 min
   Views  1.3K Geoinformation services *Machine learning *Artificial Intelligence Natural Language Processing *  
    From sandbox
       Как найти пользователя по твиту благодаря машинному обучению. Часть IВсем привет! Я ML-инженерка open-source-ного Machine Learning community Yachay AI. У нас небольшая команда, но большой опыт работы с natural language данными — в этом проекте мы разрабатываем State of the Art геолокационные тулы (на некоммерческой основе). В этой статье я расскажу про опыт нашей команды в создании и тренировке модели.Модели машинного обучения давно тренируются на постах в соцсетях. Самые большие текстовые корпусы созданы на основе Твиттера — они обогащают тысячи компаний сервисами, а библиотеки — академическими статьями. Самое интересное из всего этого спрятано за проблемами объемов данных, опечатками и жаргонизмами, кластеризацией и выбором наиболее подходящих покемонов (Large Language Models, в смысле). Под самым интересным я подразумеваю задачу определения местоположения пользователя по тексту. Каждый — от финансовых регуляторов до независимых журналистов — хочет залезть в Твиттер какого-нибудь мошенника и определить, где он прячется. Если есть спрос, появится и предложение. Эта серия постов будет посвящена креативным решениям по изменениям подходов, описанных в паре десятков научных статей. Мы начнем с маленьких изменений в датасетах, будем тестить разные алгоритмы фильтрации и кластеризации, языковые модели и надстройки. Я расскажу, как мы учили модели определять отличия между «Я живу в Нью-Йорке» и «Нью-Йорк — лучший город на планете».Шаг 1. Лимб, или анализ предыдущих методовКаждый уважающий себя ученый, который публикуется с этой темой, в первую очередь тренирует регрессивную или классификационную модель на большом публично доступном корпусе. Некоторые даже объединяют оба метода в мультизадачное решение.Из интересного: Huang и Carley в 2019 году писали про иерархическую модель геолокации и определение дискретной локации (страны и города) через классификационное решение на кластеризованных данных.Alsaqer в 2023 году опубликовал работу на применение регрессивного подхода для определения геолокации.Про мультитаск-подход можно прочитать работу Tommaso Fornaciari и Dirk Hovy, опубликованную в 2019 году.Мы будем пробовать все перечисленное: фильтровать и кластеризовать датасет, а после тестировать результаты и на регрессии, на классификации с разными алгоритмами кластеризации.Шаг 2. Гнев, или создание тренировочного датасетаМы пересмотрели существующие публикации и корпусы данных, и остановились на TwWorld, на котором в 2014 году тренировали свои модели Han, Cook и Baldwin. Основные причины такого выбора — сравнительно большой и распределенный публично доступный корпус, который к тому же переиспользовался в разных публикациях. Это делает сравнение с предыдущими работами более показательным.Проблема переиспользования готовых корпусов заключается в том, что большинство предыдущих публикаций рассматривало user-level предсказания, опираясь на большое количество текстов от каждого юзера, или кластеризовало данные на уровне Штатов или провинций внутри конкретного региона.Чтобы сместить фокус с дискретных предсказаний города до предсказаний конкретной точки, опираясь только на текст, мы тестировали разные алгоритмы фильтрации и сглаживания.КластеризацияЗадача классификация требует кластеризации данных. Давайте рассмотрим существующие алгоритмы:DBSCAN — алгоритм пространственной кластеризации на основе плотности. Не требует предопределенного числа кластеров. Алгоритм создает новый кластер каждый раз, когда находит выбранное минимальное количество объектов в заданном радиусе. Много слов — полезнее почитать эту статью.K Means — итеративный алгоритм. Случайным образом определяет, а затем перебирает K центров и группирует все ближайшие объекты к кластеру выбранного центра. Цель — минимальная дистанция между объектами и центроидами кластеров. Иерархическая агломерация — алгоритм начинает кластеризацию с минимального размера юнита и объединяет маленькие кластера, пока общее количество кластеров не достигнет заданного числа.Шаг 3. Архитектура модели (шутки про ад здесь не будет)Для всех тестов мы опираемся на посимвольную сверточную нейронную сеть (character-level CNN), представленную Izbicki, Papalexakis, and Tsotras в 2019 году.Мы создали словарь всех символов, встречающихся в корпусе.На входе в многоуровневую сверточную модель — embedding layer. На выходе:а) для регрессии — линейная классификация с широтой и долготой,б) для классификации — линейная классификация с количеством результатов, соответствующим количеству кластеров.Мы тренировали модель на двух циклах: со скоростью обучения 1e(-3) на первом цикле и 1e(-4) на втором.Шаг 4. Коварство, или результаты тестированияВ результате мы попробовали тренировать модели на публично доступном корпусе с моделями, уже презентованными в предыдущих публикациях. Это нужно было, чтобы определить наилучшую архитектуру или алгоритм кластеризации.Важно заметить, что мы меняли количество кластеров в своих тестах — слишком большое количество кластеров подразумевало низкое количество текстов из малонаселенных локаций. Слишком маленькое количество кластеров создавало проблему определения густонаселенных локаций. Все эксперименты проводились на корпусах из 100, 500 и 1000 кластеров.Если смотреть на базовые метрики в Accuracy, Mean Average Error и Median Average Error, результаты следующие:При выборе количества кластеров от 100 до 500, DBSCAN сильно опережает своих соперников по точности.Иерархическая кластеризация показала лучшие результаты по метрикам медианной и средней ошибок.Эффективность регрессии относительно кластеризации заметно хуже и по точности, и по медианной ошибке.Этот пост продолжится в паре статей — я расскажу об изменениях в архитектуре, трансформерах, и экспериментах с разными LLM и фильтрацией данных, которые привели к улучшению MAE до ~300км.      Tags: large language modelllmnlpmlmachine learninggeolocationгеолокация  Hubs: Geoinformation servicesMachine learningArtificial IntelligenceNatural Language Processing          


