

Исследователи выяснили, что системы ИИ не различают предложения с перемешанными словами / Habr


              13  January  2021 at 14:38  Исследователи выяснили, что системы ИИ не различают предложения с перемешанными словами Machine learning *Artificial Intelligence       Исследователи из Обернского университета пришли к выводу, что многие ИИ, предназначенные для обработки естественного языка (Natural Language Processing, NLP), не замечают, когда слова в предложении перемешиваются, а его значение меняется. Это показывает, что ИИ на самом деле не понимают язык, и создает проблемы в обучении систем NLP.Исследователи из Обернского университета в Алабаме совместно со специалистами компании Adobe Research попытались заставить систему NLP объяснить, почему разные предложения означают одно и то же. Они поняли, что перетасовка слов в предложении не влияла на объяснения. «Это общая проблема для всех моделей NLP», — считает руководитель исследования Ан Нгуен.Команда изучила несколько современных систем NLP, основанных на разработанной Google языковой модели BERT. Все эти системы показывают лучшие результаты, чем люди, в тестах GLUE (General Language Understanding Evaluation) — стандартных тестах, предназначенных для проверки понимания языка, и включающих такие задачи, как выявление перефразирований, определение того, выражает предложение положительный или отрицательный настрой, и задачи на вербальное мышление.Ученые обнаружили, что ИИ-системы не могут определить, когда слова в предложении перемешаны, даже если новый порядок слов изменил значение предложения или сделал его бессмысленным. Например, системы правильно определили, что предложения «Вызывает ли марихуана рак?» и «Курение марихуаны может вызвать рак легких?» означали одно и то же, хоть и были перефразированы. Однако системы были уверены в том, что у предложений «Вы курите рак, как может дать легкое марихуаны?» и «Легкие могут дать курение марихуаны, как вы рак?» такой же смысл. Системы также решили, что предложения с противоположным значением — например, «Вызывает ли марихуана рак?» и «Вызывает ли рак марихуану?» — были одинаковыми по смыслу. Ответы тестируемых систем не изменились при перемешивании слов в от 75% до 90% случаев.Как указывает журнал MIT Technology Review, модели улавливают несколько ключевых слов в предложении, в каком бы порядке они ни были. Они не понимают язык так, как люди. Кроме того, исследование показывает, что тест GLUE неспособен оценить понимание языка. Многие исследователи уже начали использовать более сложный набор тестов под названием SuperGLUE, но Нгуен подозревает, что и у него будут аналогичные недостатки.Проблему непонимания машинами естественного языка подтвердил также ученый 