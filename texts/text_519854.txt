

ANYKS Spell-checker / Habr


              20  September  2020 at 20:56  ANYKS Spell-checker Algorithms *Machine learning *Artificial Intelligence Learning languages Natural Language Processing * 
        Tutorial
           


Здравствуйте, это моя третья статья на хабре, ранее я писал статью о языковой модели ALM. Сейчас, я хочу познакомить вас с системой исправления опечаток ASC (реализованной на основе ALM).


Да, систем исправления опечаток существует огромное количество, у всех есть свои сильные и слабые стороны, из открытых систем я могу выделить одну наиболее перспективную JamSpell, с ней и будем сравнивать. Есть ещё подобная система от DeepPavlov, про которую многие могут подумать, но я с ней так и не подружился.

Список возможностей:

Исправление ошибок в словах с разницей до 4-х дистанций по Левенштейну.
Исправление опечаток в словах (вставка, удаление, замещение, перестановка) символов.
Ёфикация с учётом контекста.
Простановка регистра первой буквы слова, для (имён собственных и названий) с учётом контекста.
Разбиение объединённых слов на отдельные слова, с учётом контекста.
Выполнение анализа текста без корректировки исходного текста.
Поиск в тексте наличия (ошибок, опечаток, неверного контекста).


Поддерживаемые операционные системы:

MacOS X
FreeBSD
Linux


Написана система на С++11, есть порт для Python3

Готовые словари



Название
Размер (Гб)
Оперативная память (Гб)
Размер N-грамм
Язык




wittenbell-3-big.asc
1.97
15.6
3
RU


wittenbell-3-middle.asc
1.24
9.7
3
RU


mkneserney-3-middle.asc
1.33
9.7
3
RU


wittenbell-3-single.asc
0.772
5.14
3
RU


wittenbell-5-single.asc
1.37
10.7
5
RU



Тестирование

Для проверки работы системы использовались данные соревнования «исправления опечаток» 2016 года от Dialog21. Для тестирования использовался обученный бинарный словарь: wittenbell-3-middle.asc



Проводимый тест
Precision
Recall
FMeasure




Режим исправления опечаток
76.97
62.71
69.11


Режим исправления ошибок
73.72
60.53
66.48




Думаю, излишне добавлять другие данные, при желании каждый может повторить тест, все используемые материалы в тестировании прикладываю ниже.

Материалы использовавшиеся в тестировании

test.txt - Текст для тестирования
correct.txt - Текст корректных вариантов
evaluate.py - Скрипт Python3 для расчёта результатов коррекции



Теперь, интересно сравнить, работу самих систем исправления опечаток в равных условиях, обучим два разных опечаточника на одних и тех же текстовых данных и проведём тест. 


Для сравнения возьмём систему исправления опечаток, которую я упоминал выше JamSpell.

ASC vs JamSpell

Установка
ASC

$ git clone --recursive https://github.com/anyks/asc.git
$ cd ./asc
$ mkdir ./build
$ cd ./build
$ cmake ..
$ make

JamSpell

$ git clone https://github.com/bakwc/JamSpell.git
$ cd ./JamSpell
$ mkdir ./build
$ cd ./build
$ cmake ..
$ make




Обучение
ASC

train.json

{
  "ext": "txt",
  "size": 3,
  "alter": {"е":"ё"},
  "debug": 1,
  "threads": 0,
  "method": "train",
  "allow-unk": true,
  "reset-unk": true,
  "confidence": true,
  "interpolate": true,
  "mixed-dicts": true,
  "only-token-words": true,
  "locale": "en_US.UTF-8",
  "smoothing": "wittenbell",
  "pilots": ["а","у","в","о","с","к","б","и","я","э","a","i","o","e","g"],
  "corpus": "./texts/correct.txt",
  "w-bin": "./dictionary/3-middle.asc",
  "w-vocab": "./train/lm.vocab",
  "w-arpa": "./train/lm.arpa",
  "mix-restwords": "./similars/letters.txt",
  "alphabet": "абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz",
  "bin-code": "ru",
  "bin-name": "Russian",
  "bin-author": "You name",
  "bin-copyright": "You company LLC",
  "bin-contacts": "site: https://example.com, e-mail: info@example.com",
  "bin-lictype": "MIT",
  "bin-lictext": "... License text ...",
  "embedding-size": 28,
  "embedding": {
      "а": 0, "б": 1, "в": 2, "г": 3, "д": 4, "е": 5,
      "ё": 5, "ж": 6, "з": 7, "и": 8, "й": 8, "к": 9,
      "л": 10, "м": 11, "н": 12, "о": 0, "п": 13, "р": 14,
      "с": 15, "т": 16, "у": 17, "ф": 18, "х": 19, "ц": 20,
      "ч": 21, "ш": 21, "щ": 21, "ъ": 22, "ы": 23, "ь": 22,
      "э": 5, "ю": 24, "я": 25, "<": 26, ">": 26, "~": 26,
      "-": 26, "+": 26, "=": 26, "*": 26, "/": 26, ":": 26,
      "%": 26, "|": 26, "^": 26, "&": 26, "#": 26, "'": 26,
      "\\": 26, "0": 27, "1": 27, "2": 27, "3": 27, "4": 27,
      "5": 27, "6": 27, "7": 27, "8": 27, "9": 27, "a": 0,
      "b": 2, "c": 15, "d": 4, "e": 5, "f": 18, "g": 3,
      "h": 12, "i": 8, "j": 6, "k": 9, "l": 10, "m": 11,
      "n": 12, "o": 0, "p": 14, "q": 13, "r": 14, "s": 15,
      "t": 16, "u": 24, "v": 21, "w": 22, "x": 19, "y": 17, "z": 7
  }
}

$ ./asc -r-json ./train.json


Приведу также пример на языке Python3

import asc
asc.setSize(3)
asc.setAlmV2()
asc.setThreads(0)
asc.setLocale("en_US.UTF-8")
asc.setOption(asc.options_t.uppers)
asc.setOption(asc.options_t.allowUnk)
asc.setOption(asc.options_t.resetUnk)
asc.setOption(asc.options_t.mixDicts)
asc.setOption(asc.options_t.tokenWords)
asc.setOption(asc.options_t.confidence)
asc.setOption(asc.options_t.interpolate)
asc.setAlphabet("абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz")
asc.setPilots(["а","у","в","о","с","к","б","и","я","э","a","i","o","e","g"])
asc.setSubstitutes({'p':'р','c':'с','o':'о','t':'т','k':'к','e':'е','a':'а','h':'н','x':'х','b':'в','m':'м'})
def statusArpa1(status):
    print("Build arpa", status)
def statusArpa2(status):
    print("Write arpa", status)
def statusVocab(status):
    print("Write vocab", status)
def statusIndex(text, status):
    print(text, status)
def status(text, status):
    print(text, status)
asc.collectCorpus("./texts/correct.txt", asc.smoothing_t.wittenBell, 0.0, False, False, status)
asc.buildArpa(statusArpa1)
asc.writeArpa("./train/lm.arpa", statusArpa2)
asc.writeVocab("./train/lm.vocab", statusVocab)
asc.setCode("RU")
asc.setLictype("MIT")
asc.setName("Russian")
asc.setAuthor("You name")
asc.setCopyright("You company LLC")
asc.setLictext("... License text ...")
asc.setContacts("site: https://example.com, e-mail: info@example.com")
asc.setEmbedding({
     "а": 0, "б": 1, "в": 2, "г": 3, "д": 4, "е": 5,
     "ё": 5, "ж": 6, "з": 7, "и": 8, "й": 8, "к": 9,
     "л": 10, "м": 11, "н": 12, "о": 0, "п": 13, "р": 14,
     "с": 15, "т": 16, "у": 17, "ф": 18, "х": 19, "ц": 20,
     "ч": 21, "ш": 21, "щ": 21, "ъ": 22, "ы": 23, "ь": 22,
     "э": 5, "ю": 24, "я": 25, "<": 26, ">": 26, "~": 26,
     "-": 26, "+": 26, "=": 26, "*": 26, "/": 26, ":": 26,
     "%": 26, "|": 26, "^": 26, "&": 26, "#": 26, "'": 26,
     "\\": 26, "0": 27, "1": 27, "2": 27, "3": 27, "4": 27,
     "5": 27, "6": 27, "7": 27, "8": 27, "9": 27, "a": 0,
     "b": 2, "c": 15, "d": 4, "e": 5, "f": 18, "g": 3,
     "h": 12, "i": 8, "j": 6, "k": 9, "l": 10, "m": 11,
     "n": 12, "o": 0, "p": 14, "q": 13, "r": 14, "s": 15,
     "t": 16, "u": 24, "v": 21, "w": 22, "x": 19, "y": 17, "z": 7
}, 28)
asc.saveIndex("./dictionary/3-middle.asc", "", 128, statusIndex)

JamSpell

$ ./main/jamspell train ../test_data/alphabet_ru.txt ../test_data/correct.txt ./model.bin




Тестирование
ASC

spell.json

{
    "debug": 1,
    "threads": 0,
    "method": "spell",
    "spell-verbose": true,
    "confidence": true,
    "mixed-dicts": true,
    "asc-split": true,
    "asc-alter": true,
    "asc-esplit": true,
    "asc-rsplit": true,
    "asc-uppers": true,
    "asc-hyphen": true,
    "asc-wordrep": true,
    "r-text": "./texts/test.txt",
    "w-text": "./texts/output.txt",
    "r-bin": "./dictionary/3-middle.asc"
}

$ ./asc -r-json ./spell.json


Пример на языке Python3

import asc
asc.setAlmV2()
asc.setThreads(0)
asc.setOption(asc.options_t.uppers)
asc.setOption(asc.options_t.ascSplit)
asc.setOption(asc.options_t.ascAlter)
asc.setOption(asc.options_t.ascESplit)
asc.setOption(asc.options_t.ascRSplit)
asc.setOption(asc.options_t.ascUppers)
asc.setOption(asc.options_t.ascHyphen)
asc.setOption(asc.options_t.ascWordRep)
asc.setOption(asc.options_t.mixDicts)
asc.setOption(asc.options_t.confidence)
def status(text, status):
    print(text, status)
asc.loadIndex("./dictionary/3-middle.asc", "", status)
f1 = open('./texts/test.txt')
f2 = open('./texts/output.txt', 'w')
for line in f1.readlines():
    res = asc.spell(line)
    f2.write("%s\n" % res[0])
f2.close()
f1.close()

JamSpell


Так-как версия для Python у меня не собралась, пришлось написать небольшое приложение на C++

#include <fstream>
#include <iostream>
#include <jamspell/spell_corrector.hpp>
// Если используется BOOST
#ifdef USE_BOOST_CONVERT
	#include <boost/locale/encoding_utf.hpp>
// Если нужно использовать стандартную библиотеку
#else
	#include <codecvt>
#endif
using namespace std;
/**
 * convert Метод конвертирования строки utf-8 в строку
 * @param  str строка utf-8 для конвертирования
 * @return     обычная строка
 */
const string convert(const wstring & str){
	// Результат работы функции
	string result = "";
	// Если строка передана
	if(!str.empty()){
// Если используется BOOST
#ifdef USE_BOOST_CONVERT
		// Объявляем конвертер
		using boost::locale::conv::utf_to_utf;
		// Выполняем конвертирование в utf-8 строку
		result = utf_to_utf <char> (str.c_str(), str.c_str() + str.size());
// Если нужно использовать стандартную библиотеку
#else
		// Устанавливаем тип для конвертера UTF-8
		using convert_type = codecvt_utf8 <wchar_t, 0x10ffff, little_endian>;
		// Объявляем конвертер
		wstring_convert <convert_type, wchar_t> conv;
		// wstring_convert <codecvt_utf8 <wchar_t>> conv;
		// Выполняем конвертирование в utf-8 строку
		result = conv.to_bytes(str);
#endif
	}
	// Выводим результат
	return result;
}
/**
 * convert Метод конвертирования строки в строку utf-8
 * @param  str строка для конвертирования
 * @return     строка в utf-8
 */
const wstring convert(const string & str){
	// Результат работы функции
	wstring result = L"";
	// Если строка передана
	if(!str.empty()){
// Если используется BOOST
#ifdef USE_BOOST_CONVERT
		// Объявляем конвертер
		using boost::locale::conv::utf_to_utf;
		// Выполняем конвертирование в utf-8 строку
		result = utf_to_utf <wchar_t> (str.c_str(), str.c_str() + str.size());
// Если нужно использовать стандартную библиотеку
#else
		// Объявляем конвертер
		// wstring_convert <codecvt_utf8 <wchar_t>> conv;
		wstring_convert <codecvt_utf8_utf16 <wchar_t, 0x10ffff, little_endian>> conv;
		// Выполняем конвертирование в utf-8 строку
		result = conv.from_bytes(str);
#endif
	}
	// Выводим результат
	return result;
}
/**
 * safeGetline Функция извлечения строки из текста
 * @param  is файловый поток
 * @param  t  строка для извлечения текста
 * @return    файловый поток
 */
istream & safeGetline(istream & is, string & t){
	// Очищаем строку
	t.clear();
	istream::sentry se(is, true);
	streambuf * sb = is.rdbuf();
	for(;;){
		int c = sb->sbumpc();
		switch(c){
 			case '\n': return is;
			case '\r':
				if(sb->sgetc() == '\n') sb->sbumpc();
				return is;
			case streambuf::traits_type::eof():
				if(t.empty()) is.setstate(ios::eofbit);
				return is;
			default: t += (char) c;
		}
	}
}
/**
* main Главная функция приложения
*/
int main(){
	// Создаём корректор
	NJamSpell::TSpellCorrector corrector;
	// Загружаем модель обучения
	corrector.LoadLangModel("model.bin");
	// Открываем файл на чтение
	ifstream file1("./test_data/test.txt", ios::in);
	// Если файл открыт
	if(file1.is_open()){
		// Строка чтения из файла
		string line = "", res = "";
		// Открываем файл на чтение
		ofstream file2("./test_data/output.txt", ios::out);
		// Если файл открыт
		if(file2.is_open()){
			// Считываем до тех пор пока все удачно
			while(file1.good()){
				// Считываем строку из файла
				safeGetline(file1, line);
				// Если текст получен, выполняем коррекцию
				if(!line.empty()){
					// Получаем исправленный текст
					res = convert(corrector.FixFragment(convert(line)));
					// Если текст получен, записываем его в файл
					if(!res.empty()){
						// Добавляем перенос строки
						res.append("\n");
						// Записываем результат в файл
						file2.write(res.c_str(), res.size());
					}
				}
			}
			// Закрываем файл
			file2.close();
		}
		// Закрываем файл
		file1.close();
	}
    return 0;
}


Компилируем и запускаем

$ g++ -std=c++11 -I../JamSpell -L./build/jamspell -L./build/contrib/cityhash -L./build/contrib/phf -ljamspell_lib -lcityhash -lphf ./test.cpp -o ./bin/test
$ ./bin/test



Результаты

Получение результатов
$ python3 evaluate.py ./texts/test.txt ./texts/correct.txt ./texts/output.txt



ASC



Precision
Recall
FMeasure




92.13
82.51
87.05



JamSpell



Precision
Recall
FMeasure




77.87
63.36
69.87




Одной из главных возможностей ASC — обучение на грязных данных. В отрытом доступе найти текстовые корпуса без ошибок и опечаток практически не реально. Исправлять руками терабайты данных не хватит жизни, а работать с этим как-то надо.

Принцип обучения который предлагаю я

Собираем языковую модель на грязных данных
Удаляем все редко встречающиеся слова и N-граммы в собранной языковой модели
Добавляем одиночные слова для более правильной работы системы исправления опечаток.
Собираем бинарный словарь

Приступим

Предположим, что у нас есть несколько корпусов разной тематики, логичнее обучить их отдельно, потом объединить.


Сборка корпуса с помощью ALM
collect.json

{
	"size": 3,
	"debug": 1,
	"threads": 0,
	"ext": "txt",
	"method": "train",
	"allow-unk": true,
	"mixed-dicts": true,
	"only-token-words": true,
	"smoothing": "wittenbell",
	"locale": "en_US.UTF-8",
	"w-abbr": "./output/alm.abbr",
	"w-map": "./output/alm.map",
	"w-vocab": "./output/alm.vocab",
	"w-words": "./output/words.txt",
	"corpus": "./texts/corpus",
	"abbrs": "./abbrs/abbrs.txt",
	"goodwords": "./texts/whitelist/words.txt",
	"badwords": "./texts/blacklist/garbage.txt",
	"mix-restwords": "./texts/similars/letters.txt",
	"alphabet": "абвгдеёжзийклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz"
}

$ ./alm -r-json ./collect.json


size — Мы собираем N-граммы длиной 3
debug — Выводим индикатор выполнения сбора данных
threads — Для сборки используем все доступные ядра
ext — Указываем расширение файлов в каталоге которые пригодны для обучения
allow-unk — Разрешаем хранить токен