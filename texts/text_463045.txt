

Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей / Habr


               12  August  2019 at 15:12  Автоматическое определение эмоций в текстовых беседах с использованием нейронных сетей VK corporate blog Python *Data Mining *Big Data *Machine learning *      

Одна из основных задач диалоговых систем состоит не только в предоставлении нужной пользователю информации, но и в генерации как можно более человеческих ответов. А распознание эмоций собеседника — уже не просто крутая фича, это жизненная необходимость. В этой статье мы рассмотрим архитектуру рекуррентной нейросети для определения эмоций в текстовых беседах, которая принимала участие в SemEval-2019 Task 3 “EmoContext”, ежегодном соревновании по компьютерной лингвистике. Задача состояла в классификации эмоций (“happy”, “sad”, “angry” и “others”) в беседе из трех реплик, в которой участвовали чат-бот и человек.


В первой части статьи мы рассмотрим поставленную в EmoContext задачу и предоставленные организаторами данные. Во второй и третьей частях разберём предварительную обработку текста и способы векторного представления слов. В четвёртой части мы опишем архитектуру LSTM, которую мы использовали в соревновании. Код написан на языке Python с использованием библиотеки Keras. 

1. Обучающие данные

Трек “EmoContext” на SemEval-2019 был посвящен определению эмоций в текстовых беседах с учетом контекста переписки. Контекст в данном случае — это несколько последовательных реплик участников диалога. В беседе два участника: анонимный пользователь (ему принадлежит первая и третья реплика) и чат-бот Ruuh (ему принадлежит вторая реплика). На основе трех реплик необходимо определить, какую эмоцию испытывал пользователь при написании ответа чат-боту (Таблица 1). Всего разметка датасета содержала четыре эмоции: «happy», «sad», «angry» или «others» (Таблица 1). Подробное описание представлено здесь: (Chatterjee et al., 2019).

Таблица 1. Примеры из датасета EmoContext (Chatterjee et al., 2019)


Пользователь (Этап-1)
Диалоговый робот (Этап-1)
Пользователь (Этап-2)
True Class


I just qualified for the Nabard internship
WOOT! That’s great news. Congratulations!
I started crying
Счастье


How dare you to slap my child
If you spoil my car, I will do that to you too
Just try to do that once
Злость


I was hurt by u more
You didn’t mean it.
say u love me
Грусть


I will do night.
Alright. Keep me in loop.
Not giving WhatsApp no.
Другое



В ходе состязания организаторы предоставили несколько наборов данных. Обучающий датасет (Train) состоял из 30 160 размеченных вручную текстов. В этих текстах было примерно по 5000 объектов, относящихся к классам «happy», «sad» и «angry», а также 15000 текстов из класса «others» (Таблица 2). 


Также организаторы предоставили наборы данных для разработки (Dev) и тестирования (Test), в которых, в отличие от обучающего датасета, распределение по классам эмоций соответствовало реальной жизни: примерно по 4 % для каждого из классов «happy», «sad» и «angry», а остальное — класс «others». Данные предоставлены Microsoft, скачать их можно в официальной группе в LinkedIn.

Таблица 2. Распределение меток классов эмоций в датасете (Chatterjee et al., 2019).


Датасет
Счастье
Грусть
Злость
Другое
Итого


Учебный

14,07 %

18,11 %

18,26 %

49,56 %

30 160



Для разработки

5,15 %

4,54 %

 5,45 %

84,86 %

2755



Тестовый

5,16 %

4,54 %

5,41 %

 84,90 %

5509



Дистанцированный

33,33 %

33,33 %

33,33 %

0 %

900 тыс.




В дополнение к этим данным мы собрали 900 тыс. англоязычных сообщений из Twitter, чтобы создать Distant-датасет (300 тыс. твитов на каждую эмоцию). При его создании мы придерживались стратегии Go et al. (2009), в рамках которой просто ассоциировали сообщения с наличием относящихся к эмоциям слов, таких как #angry, #annoyed, #happy, #sad, #surprised и так далее. Список терминов основан на терминах из SemEval-2018 AIT DISC (Duppada et al., 2018). 


Главной метрикой качества в соревновании EmoContext является усредненная F1-мера для трёх классов эмоций, то есть для классов «happy», «sad» и «angry».

def preprocessData(dataFilePath, mode):
	conversations = []
	labels = []
	with io.open(dataFilePath, encoding="utf8") as finput:
    	finput.readline()
    	for line in finput:
        	line = line.strip().split('\t')
        	for i in range(1, 4):
            	line[i] = tokenize(line[i])
        	if mode == "train":
            	labels.append(emotion2label[line[4]])
        	conv = line[1:4]
        	conversations.append(conv)
	if mode == "train":
    	return np.array(conversations), np.array(labels)
	else:
    	return np.array(conversations)
texts_train, labels_train = preprocessData('./starterkitdata/train.txt', mode="train")
texts_dev, labels_dev = preprocessData('./starterkitdata/dev.txt', mode="train")
texts_test, labels_test = preprocessData('./starterkitdata/test.txt', mode="train")

2. Предварительная обработка текста

Перед обучением мы предварительно обработали тексты с помощью инструмента Ekphrasis (Baziotis et al., 2017). Он помогает исправить орфографию, нормализовать слова, сегментировать, а также определить, какие токены следует отбросить, нормализовать или аннотировать с помощью специальных тегов. На этапе предварительной обработки мы сделали следующее:


Адреса URL и почту, дату и время, ники, проценты, валюты и числа заменили соответствующими тегами.
Повторяющиеся, цензурированные, удлинённые написанные прописными буквами термины мы сопроводили соответствующими метками.
Удлинённые слова были автоматически скорректированы.


Кроме того, Emphasis содержит токенизатор, который может идентифицировать большинство эмодзи, эмотиконов и сложных выражений, а также даты, время, валюты и акронимы.

Таблица 3. Примеры предварительной обработки текста.


Исходный текст
Предварительно обработанный текст


I FEEL YOU… I'm breaking into million pieces 
<allcaps> i feel you </allcaps>. <repeated> i am breaking into million pieces 


tired and I missed you too :