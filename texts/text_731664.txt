

OpenAI разрешила отключать историю чатов в ChatGPT и представила подписку ChatGPT Business / Habr


               OpenAI разрешила отключать историю чатов в ChatGPT и представила подписку ChatGPT Business  Reading time  
    5 min
   Views  3.9K Information Security *Cloud services *Artificial Intelligence Social networks and communities IT-companies       


OpenAI разрешила пользователям отключать историю чатов в настройках доступа к ChatGPT. Также компания представила подписку ChatGPT Business для организаций, которые заботятся о безопасности своих данных. OpenAI не будет использовать для обучения ИИ данные клиентов по такой подписке. Доступ к сервису ChatGPT Business в компании планируют открыть через некоторое время.


Разработчики из OpenAI пояснили, что теперь пользователи могут отключать историю чатов, чтобы контролировать, какие именно их беседы с чат-ботом будут использованы компанией для обучения ChatGPT. 


Отключить историю чатов можно в настройках профиля пользователя ChatGPT. В OpenAI уточнили, что все новые беседы с чат-ботом будут храниться на серверах компании в течение 30 суток, чтобы иметь возможность «отслеживать злоупотребления», прежде чем их окончательно удалят из базы данных. Также отмечается, что новые настройки не будут применяться к любым существующим разговорам, которые у пользователей были ранее с включённой историей чата. Это означает, что OpenAI может по-прежнему использовать их для обучения своих ИИ-моделей без ограничений.


В начале февраля OpenAI представила платную версию популярного чат-бота ChatGPT Plus за $20 в месяц. Разработчики пообещали, что платная версия чат-бота будет всегда доступна для использования (сейчас многие пользователи бесплатной версии видят сообщение: ChatGPT is at capacity right now) и будет выдавать больше ответов в день по сравнению с бесплатной версией. Также в ней будет доступен ранний показ новых функций.


Ранее разработчики из OpenAI начали готовиться к соблюдению требований регуляторов разных стран. Они на входе в диалог с чат-ботом ChatGPT стали показывать предупреждение, что этот ИИ небезопасен в использовании и может выдавать неправильные ответы. Также OpenAI признала, что эксперты компании просматривают ответы и запросы пользователей, так что не надо при общении с ИИ делиться с чат-ботом конфиденциальными данными.«Это бесплатный предварительный доступ к экспериментальной версии чат-бота.


Наша цель — получить от вас отзывы, чтобы улучшить текущую версию ИИ и сделать нейросеть более безопасной. Хотя у нас есть меры безопасности, чат-бот может время от времени генерировать неверную или вводящую в заблуждение информацию, а также создавать оскорбительный или предвзятый контент. ChatGPT не предназначен для того, чтобы давать советы.


Как мы собираем данные: наши специалисты по искусственному интеллекту могут просматривать разговоры чат-бота с пользователями для улучшения наших систем. Пожалуйста, не делитесь конфиденциальной информацией в своих беседах с чат-ботом.


Мы будем рады вашим отзывам. Эта система оптимизирована для диалога. Дайте нам обязательно знать, если конкретный ответ был хорошим или бесполезным для вас»,


 — рассказали в OpenAI.13 апреля глава OpenAI сообщил, что инженеры компании разрабатывают языковую модель GPT-5, но пока ещё не начинали обучение и не планируют приступать к этому в ближайшее время. При этом глава компании обратил внимание на то, что продолжаются улучшения GPT-4. В частности, сотрудники OpenAI работают над безопасностью.


14 апреля Европейский совет по защите данных (European Data Protection Board, EDPB) организовал рабочую группу, которая будет заниматься вопросами использования чат-бота ChatGPT. Ожидается, что она разработает политику конфиденциальности для систем искусственного интеллекта.

Ограничения в развитии чат-ботов с ИИ

 14 марта OpenAI представила новую модель ИИ интерпретации изображений и текста GPT-4, которую компания назвала «последней вехой в своих усилиях по расширению масштабов глубокого обучения». GPT-4 создала за несколько десятков секунд по короткому ТЗ рабочую версию Pong, Asteroids, Breakout и Pac-Man, а также написала простую игру на JavaScript, в которой можно «играть лесными эльфами, охраной дворца и злодеями» и «грабить корованы» и даже помогла «превратить» $100 в $25 тыс.
 В конце марта некоммерческая организация Future of Life опубликовала письмо, в котором глава SpaceX Илон Маск, соучредитель Apple Стив Возняк, филантроп Эндрю Янг и ещё около тысячи исследователей искусственного интеллекта призвали «немедленно приостановить» обучение систем ИИ «более мощных, чем GPT-4».
 Организация проблем этики в IT Center for Artificial Intelligence and Digital Policy направила жалобу против OpenAI в Федеральную торговую комиссию США. Она потребовала запретить компании развёртывать новые модели GPT, а также попросила регулятора начать расследование в отношении OpenAI из-за выпуска GPT-4, чтобы выяснить, не нарушает ли он законы США и других стран.
 В начале апреля группа специалистов по этике AI выступила с ответом на письмо Future of Life. Они скептически отнеслись к призыву взять шестимесячную «паузу» в развитии AI и обучении систем, «более мощных, чем GPT-4», раскритиковали текст письма за акцент на гипотетических будущих угрозах, связанных с развитием искусственного интеллекта. По их мнению, реальный вред может принести использование AI-технологий уже сегодня.
 Билл Гейтс считает, что призыв приостановить работу над нейросетями мощнее GPT-4 на полгода не решит проблемы. По его мнению, вместо ввода моратория необходимо определить проблемные области и заняться ими.


Ограничения в работе с OpenAI и ChatGPT в разных странах

 25 марта OpenAI признала, что сбой с публикацией историй запросов пользователей чат-бота ChatGPT произошёл из-за некорректного использования и ошибки в клиенте Redis открытой библиотеки redis-py. Разработчики выяснили, что из-за бага также произошло непреднамеренное отображение третьим лицам платёжной информации и персональных данных 1,2% подписчиков сервиса ChatGPT Plus.
 31 марта разработчики из OpenAI временно отключили доступ к сервису ChatGPT для пользователей в Италии. Компания сделала блокировку по геолокации по требованию итальянского агентства по защите персональных данных. Регулятор выявил в работе ChatGPT нарушения при сборе данных пользователей и заявил, что у OpenAI нет правовой основы, оправдывающей массовый сбор и хранение персональных данных. Ограничение по геоблокировке в Италии затрагивает веб-версию ChatGPT, но не влияет на доступ к чат-боту поисковой системы Microsoft Bing, который также основан на GPT-4 от OpenAI.
 В начале апреля регулятор по защите персональных данных Германии сообщил, что ведомство не исключает блокировки ChatGPT в стране по аналогии с прецедентом в Италии из-за нарушений OpenAI законодательства ЕС в сфере обработки и защиты персональных данных GDPR (General Data Protection Regulation). Комиссар Германии по защите данных Ульрих Кельбер заявил СМИ, что ведомство изучает ситуацию с ChatGPT по соображениям безопасности данных граждан страны.
 5 апреля регулятор Канады начал расследование нарушений в деятельности американской компании OpenAI в рамках обработки данных пользователей ChatGPT. Комиссариат по защите частной жизни Канады сообщил, что ведомство оперативно запустило расследование против OpenAI после получения от граждан жалоб о сборе, использовании и раскрытии личной информации сервисом ChatGPT без согласия пользователей. 
      Tags: chatgptчат-ботперсональные данныеутечкаИИисторияобучение  Hubs: Information SecurityCloud servicesArtificial IntelligenceSocial networks and communitiesIT-companies          


