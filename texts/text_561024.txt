

“ематическое исследование распознавани€ именованных сущностей в биомедицине / Habr


              4  June  2021 at 17:17  “ематическое исследование распознавани€ именованных сущностей в биомедицине SkillFactory corporate blog Machine learning *Health Natural Language Processing * 
        Translation
         
                Original author:
                
                  Stephan Tulkens
                  Ќе так давно у автора этой статьи возник вопрос: может ли простой метод сопоставлени€ строк Ч в сочетании с некоторыми простыми оптимизаци€ми Ч конкурировать с моделью, обученной с учителем, в биомедицинской задаче распознавани€ именованных сущностей (NER)? јвтор сравнил эти два метода между собой и предположил, что при правильном подходе даже простые модели могут конкурировать со сложными системами, а мы к старту курса "Machine Learning и Deep Learning" перевели его статью.¬ начале любого нового проекта Ќ»ќ – € ищу наиболее подход€щее решение поставленной задачи. Ќесмотр€ на наличие нескольких очень интересных крупных моделей, одной из моих самых больших проблем €вл€етс€ внедрение решени€ в производство без ущерба дл€ результатов, которые € хотел бы поддерживать. „то касаетс€ системы сопоставлени€ строк, € использовал классификатор QuickUMLS. QuickUMLS [1] Ч как система сопоставлени€ строк Ч принимает на вход строку (например, документ или реферат статьи, содержащий медицинские пон€ти€) и выводит все промежутки документа, которые соответствуют пон€ти€м унифицированного €зыка медицинских систем (UMLS). «атем эти пон€ти€ могут быть повторно использованы в других услови€х или в качестве исходных данных дл€ других систем машинного обучени€. ѕо этой причине QuickUMLS можно рассматривать как удобный инструмент предварительной обработки дл€ получени€ релевантных пон€тий из клинических и биомедицинских текстов. ќднако в этой статье мы сосредоточимс€ на использовании QuickUMLS в качестве классификатора на сложном наборе данных MedMentions [2].–исунок 1. —хематическое описание того, как работает QuickUMLS. ѕолучив строку, базу данных UMLS, превращЄнную в Ѕƒ simstring, модель возвращает оптимальные соответстви€, идентификаторы пон€тий и семантические типыЌекоторые ключевые моменты, которые необходимо знать о биомедицинском NERѕрежде чем мы погрузимс€ в проблему, которую пытаемс€ решить, полезно описать некоторые особенности биомедицинского NER. ¬ целом проблема NER заключаетс€ в поиске именованных сущностей (например, известных мест, лиц, организаций и т. д.) в тексте.  ак вы, веро€тно, догадываетесь, многие из этих сущностей можно найти через контекст. Ќапример, в таком предложении, как "—эм и ƒрю пошли в  олизей", мы можем сделать вывод, что  олизей Ч это место, потому что вы обычно ходите в какие-то места. јналогично, мы можем предположить, что "—эм" Ч это им€ собственное, потому что слова в позиции подлежащего "идти", которые не €вл€ютс€ обычными словами, это обычно имена.¬ отличие от этого биомедицинска€ NER заключаетс€ в поиске и однозначном определении интересующих биомедицинских терминов из текста, таких как заболевани€, названи€ лекарств, а также общих терминов, таких как "больница.роддом" (hospital), "палата интенсивной терапии/подопечный отделени€ интенсивной терапии" или "алкоголь/спирт" (alcohol). Ёто важное различие, поскольку существует очень мало контекстуальной информации, определ€ющей, имеет ли данное слово медицинское значение. „тобы привести немного нагруженный пример, рассмотрим слово "alcohol" в предложении "пациент выпил много alcohol" [дл€ €сности того, что речь идЄт о неоднозначности, оставлено оригинальное alcohol]. “€жесть этого заключени€ зависит от того, относитс€ ли оно к алкоголю, такому как пиво или вино, или к чистому спирту, такому как спирт дл€ растирани€. ƒл€ более полного обзора состо€ни€ дел в области биомедицинского NER см. эту запись в блоге моего коллеги из Slimmer AI, —ибрена янсена.«нать, какие пон€ти€ имеют медицинское значение, сложно без большого количества обучающих данных, которые, как правило, не всегда доступны. ѕоэтому многие системы используют унифицированный €зык медицинских систем (UMLS), котора€ представл€ет собой большую онтологию, содержащую множество различных пон€тий вместе с их строковыми представлени€ми и другой информацией. ќбратите внимание, что "пон€тие" здесь отличаетс€ от "строки", поскольку многие строки могут ссылатьс€ на более чем одно пон€тие. Ќапример, строка "alcohol" может относитьс€ к спирту дл€ растирани€ или к алкогольным напиткам.¬ UMLS каждое пон€тие описываетс€ уникальным идентификатором пон€ти€ (CUI), который €вл€етс€ символическим идентификатором дл€ любого данного уникального пон€ти€, и семантическим типом (STY), который, в свою очередь, €вл€етс€ идентификатором семейства, группирующим пон€ти€ с похожими характеристиками. ќдной из причин, по которой UMLS €вл€етс€ полезным, но в то же врем€ сложным дл€ работы, Ч его огромный размер. ¬ерси€ UMLS 2020AB, которую мы будем использовать в дальнейшем, насчитывает более 3 миллионов уникальных английских пон€тий. ћаловеро€тно, что значительна€ часть этих пон€тий по€витс€ даже в больших аннотированных наборах данных.–абота с набором данных MedMentionsќдним из таких наборов данных €вл€етс€ MedMentions. ќн состоит из 4 392 статей (заголовки и рефераты), опубликованных в Pubmed за 2016 год; аннотировано 352 K пон€тий (идентификаторов CUI) и семантических типов из UMLS. ¬ документах имеетс€ около 34 тыс€ч аннотированных уникальных пон€тий Ч это около 1 % от общего числа пон€тий в UMLS. ‘акт показывает, что аннотирование упоминаний в UMLS €вл€етс€ сложной задачей, которую не всегда можно решить с помощью машинного обучени€ с учителем.ќсобый интерес в этом отношении представл€ет то, что корпус MedMentions включает в тестовое множество CUI, которые не встречаютс€ в обучающем наборе. ¬ целом, однако, эта задача всЄ ещЄ рассматриваетс€ как задача машинного обучени€ с учителем и с использованием семантических типов пон€тий UMLS в качестве меток. ѕоскольку UMLS имеет 127 семантических типов, это всЄ равно приводит к большому пространству меток. ” набора данных MedMentions тоже есть уменьшенна€ верси€ Ч st21pv, который состоит из тех же документов, что и обычный набор, но в нЄм аннотирован только 21 наиболее часто встречающийс€ семантический тип.ѕолумарковска€ базова€ модель получает около 45,3 по F-мере на уровне сущностей [2]. ƒругие подходы, включа€ BlueBERT [3] и BioBERT [4], были протестированы и улучшили оценку до 56,3 балла, использу€ точное соответствие на уровне сущностей [5]. ќбратите внимание, что все эти подходы €вл€ютс€ контролируемыми и, следовательно, полагаютс€ на определЄнное совпадение между обучающим и тестовым множеством в плане пон€тий. ≈сли пон€тие или метка никогда не встречалась в процессе обучени€, в подходе машинного обучени€ с учителем будет сложно еЄ правильно классифицировать. ƒалее в качестве меток мы будем использовать семантические типы из набора данных MedMentions.QuickUMLS: без учител€ и на основе знаний¬ отличие от BERT QuickUMLS по своей сути €вл€етс€ методом без учител€, а это означает, что он не полагаетс€ на обучающие данные. “очнее, QuickUMLS Ч это метод, основанный на знани€х. “о есть модель, вместо того чтобы иметь параметры, сообщающих, что прогнозировать, дл€ прогнозировани€ меток полагаетс€ на внешнюю базу знаний. ѕодход подразумевает две вещи: ачество модели ограничено качеством базы знаний. ћодель не может предсказать то, чего нет в базе знаний.ћодель может обобщать не только аннотированные данные. ћодель, котора€ обучалась с учителем и во врем€ обучени€ не видела конкретной метки, в целом не может точно предсказать эти вещи. »сключение из правила Ч методы обучени€ zero-shot.Zero-shot learning (ZSL) Ч это постановка задачи в машинном обучении, когда во врем€ тестировани€ алгориттм наблюдает выборки из классов, которые не наблюдались во врем€ обучени€, и должен спрогнозировать, к какому классу они принадлежат.»сход€ из этих двух фактов, мы утверждаем, что основанные на знани€х методы хорошо подход€т дл€ набора данных MedMentions. „то касаетс€ первого пункта, база данных MedMentions была аннотирована с использованием пон€тий UMLS, поэтому сопоставление между базой знаний и набором данных €вл€етс€ точным сопоставлением. „то касаетс€ второго пункта, набор данных MedMentions в тестовом наборе содержит пон€ти€, которых нет в обучающем наборе.јрхитектура модели QuickUMLSQuickUMLS как модель проста. —начала она анализирует текст с помощью парсера spacy. «атем выбирает словесные n-граммы, то есть последовательности слов, на основе цитат и описаний цитат, а также списков стоп-слов.† Ёто означает, что модель отбрасывает определЄнные словесные n-граммы, если они содержат нежелательные токены и знаки препинани€. ѕодробные сведени€ об этих правилах можно найти в оригинальной статье [1]. ѕосле выбора кандидатов вс€ база данных UMLS запрашиваетс€, чтобы найти пон€ти€, частично соответствующие словам n-грамм. ѕоскольку точное сопоставление в такой огромной базе данных неэффективно и сложно, авторы выполн€ют приблизительное сопоставление строк с помощью simstring [6]. ѕри задании текста QuickUMLS, таким образом, возвращает список пон€тий в UMLS вместе с их сходством со строкой запроса и другой св€занной информацией. Ќапример, текст У” пациента было кровоизли€ниеФ, использу€ (по умолчанию) порог сходства строк 0,7, возвращает следующих кандидатов:ƒл€ слова patient:{СtermТ: СInpatientТ, СcuiТ: СC1548438Т, СsimilarityТ: 0.71, СsemtypesТ: {СT078Т}, СpreferredТ: 1},
{СtermТ: СInpatientТ, СcuiТ: СC1549404Т, СsimilarityТ: 0.71, СsemtypesТ: {СT078Т}, СpreferredТ: 1},
{СtermТ: СInpatientТ, СcuiТ: СC1555324Т, СsimilarityТ: 0.71, СsemtypesТ: {СT058Т}, СpreferredТ: 1},
{СtermТ: С*^patientТ, СcuiТ: СC0030705Т, СsimilarityТ: 0.71, СsemtypesТ: {СT101Т}, СpreferredТ: 1},
{СtermТ: СpatientТ, СcuiТ: СC0030705Т, СsimilarityТ: 1.0, СsemtypesТ: {СT101Т}, СpreferredТ: 0},
{СtermТ: СinpatientТ, СcuiТ: СC0021562Т, СsimilarityТ: 0.71, СsemtypesТ: {СT101Т}, СpreferredТ: 0}ƒл€ слова hemmorhage:{СtermТ: СNo hemorrhageТ, СcuiТ: СC1861265Т, СsimilarityТ: 0.72, СsemtypesТ: {СT033Т}, СpreferredТ: 1},
{СtermТ: СhemorrhaginТ, СcuiТ: СC0121419Т, СsimilarityТ: 0.7, СsemtypesТ: {СT116Т, СT126Т}, СpreferredТ: 1},
{СtermТ: СhemorrhagicТ, СcuiТ: СC0333275Т, СsimilarityТ: 0.7, СsemtypesТ: {СT080Т}, СpreferredТ: 1},
{СtermТ: СhemorrhageТ, СcuiТ: СC0019080Т, СsimilarityТ: 1.0, СsemtypesТ: {СT046Т}, СpreferredТ: 0},
{СtermТ: СGI hemorrhageТ, СcuiТ: СC0017181Т, СsimilarityТ: 0.72, СsemtypesТ: {СT046Т}, СpreferredТ: 0},
{СtermТ: СHemorrhagesТ, СcuiТ: СC0019080Т, СsimilarityТ: 0.7, СsemtypesТ: {СT046Т}, СpreferredТ: 0} ак вы можете видеть, слово УpatientФ имеет три соответстви€ с корректным семантическим типом (T101) и два соответстви€ с корректным пон€тием (C0030705). —лово Укровоизли€ниеФ также имеет лишние совпадени€, включа€ пон€тие "No hemmorhage". “ем не менее кандидат с самым высоким рейтингом, если исходить из сходства, €вл€етс€ правильным в обоих случа€х.¬ приложении QuickUMLS по умолчанию мы сохран€ем только предпочтительные термины, то есть термины, дл€ которых предпочтительным €вл€етс€ 1, а затем сортируем по сходству. ѕосле мы берЄм семантический тип (семтип) кандидата с самым высоким рейтингом в качестве прогноза Ч мы называем это базовой моделью (baseline model). ћы использовали seqeval со строгой парадигмой соответстви€, котора€ сопоставима с предыдущей работой [5].