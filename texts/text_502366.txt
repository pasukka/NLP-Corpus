

Сравниваем работу open source Python — библиотек для распознавания именованных сущностей / Habr


              17  May  2020 at 13:20  Сравниваем работу open source Python — библиотек для распознавания именованных сущностей Open source *Python *Natural Language Processing *      Введение

Мы в компании создаем сервис, который позволяет автоматически создавать, управлять и безопасно хранить лицензионные соглашения и прочие договоры между фрилансерами и их клиентами. 


Для решения это задачи я опробовал десятки решений в области обработки естественного языка, в том числе решения с открытым кодом и хотел бы поделиться опытом работы с open source Python — библиотеками для распознавания именованных сущностей.

Распознавание именованных сущностей 

Несколько слов о самой проблеме. Named Entity Recognition (NER) — это направление технологии обработки человеческого языка, программная реализация которой позволяет находить в речи и тексте опредмеченные категории слов и словосочетаний. Сначала это были географические наименования, имена людей, организаций, адреса, однако в настоящее время это понятие сильной расширилось и с помощью NER мы ищем в тексте относительные и абсолютные даты, числа, номера и т.д. 

Выявление именованных сущностей — это «ворота» в человеческий язык, оно позволяет выявлять и обрабатывать намерения человека, устанавливать связи слов в его речи и реальным миром. 


Языковое неравенство

Для начала, хотел бы обратить внимание на очевидное неравенство в программных решениях для разных языков. Так, большинство разработок (в том числе созданные российскими программистами) работают с английским языком. Найти готовые модели для бахаса, хинди или арабского — задача неблагодарная. 


Европейские языки худо-бедно представлены в наиболее популярных библиотеках, языки африки не существуют в современном Natural Language Processing в принципе. Между тем, по своему опыту знаю, что африканский континент — это огромный и богатый рынок, и такое отношение это, скорее всего, инерция рынка. 


Для русского языка есть несколько вызывающих удивление своим качеством решений, однако, за ними не чувствуется такой коммерческой мощи и академического потенциала как для развитых библиотек «построенных» на обработке английского языка. 

Текст для обработки

Я взял несколько предложений из разных источников, и соединил их в несколько гипнотический текст, чтобы протестировать насколько хорошо справятся со своей задачей выбранные библиотеки. 

english_text = ''' I want a person available 7 days and with prompt response all most every time. Only Indian freelancer need I need PHP developer who have strong experience in Laravel and Codeigniter framework for daily 4 hours. I need this work by Monday 27th Jan. should be free from plagiarism . 
Need SAP FICO consultant for support project needs to be work on 6 months on FI AREAWe.  Want a same site to be created as the same as this https://www.facebook.com/?ref=logo, please check the site before contacting to me and i want this site to be ready in 10 days. They will be ready at noon tomorrow .'''
russian_text = '''Власти Москвы выделили 110 млрд рублей на поддержку населения, системы здравоохранения и городского хозяйства. Об этом сообщается на сайте мэра столицы https://www.sobyanin.ru/ в пятницу, 1 мая. По адресу Алтуфьевское шоссе д.51 (основной вид разрешенного использования: производственная деятельность, склады) размещен МПЗ? Подпоручик Киже управляя автомобилем ВАЗ2107 перевозил автомат АК47 с целью ограбления банка ВТБ24, как следует из записей. 
Взыскать c индивидуального предпринимателя Иванова Костантипа Петровича дата рождения 10 января 1970 года, проживающего по адресу город Санкт-Петербург, ул. Крузенштерна, дом 5/1А 8 000 (восемь тысяч) рублей 00 копеек гос. пошлины в пользу бюджета РФ Жители требуют незамедлительной остановки МПЗ и его вывода из района. Решение было принято по поручению мэра города Сергея Собянина в связи с ограничениями из-за коронавируса.'''


Библиотека NLTK

NLTK это классическая библиотека для обработки естественного языка, она проста в использовании, не требует длительного изучения и выполняет 99% задач, которые могут возникнуть при решении студенческих задач. 
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
for sent in nltk.sent_tokenize(english_text):
   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):
      if hasattr(chunk, 'label'):
         print(chunk)


Output:
(GPE Indian/JJ)

(ORGANIZATION PHP/NNP)

(GPE Laravel/NNP)

(PERSON Need/NNP)

(ORGANIZATION SAP/NNP)

(ORGANIZATION FI/NNP)



Как мы видим, NLTK неплохо справился со своей задачей, однако для того, чтобы сделать результат более «богатым» нам придется обучать свой собственный tagger (или выбрать другой из достаточно широкого списка). Но, стоит ли это делать в 2020 году если есть более простые решения? 

Stanford CoreNLP



Один из способов расширить возможности NLTK это использовать вместе с классической Python библиотекой классическую Java библиотеку от Stanford CoreNLP. Качество улучшается значительно, при сравнительно низких требованиях. 
from nltk.tag.stanford import StanfordNERTagger
jar = "stanford-ner-2015-04-20/stanford-ner-3.5.2.jar"
model = "stanford-ner-2015-04-20/classifiers/" 
st_3class = StanfordNERTagger(model + "english.all.3class.distsim.crf.ser.gz", jar, encoding='utf8') 
st_4class = StanfordNERTagger(model + "english.conll.4class.distsim.crf.ser.gz", jar, encoding='utf8') 
st_7class = StanfordNERTagger(model + "english.muc.7class.distsim.crf.ser.gz", jar, encoding='utf8')
for i in [st_3class.tag(english_text.split()), st_4class.tag(english_text.split()), st_7class.tag(english_text.split())]:
  for b in i:
    if b[1] != 'O':
        print(b)


Output:
('PHP', 'ORGANIZATION')

('Laravel', 'LOCATION')

('Indian', 'MISC')

('PHP', 'ORGANIZATION')

('Laravel', 'LOCATION')

('Codeigniter', 'PERSON')

('SAP', 'ORGANIZATION')

('FICO', 'ORGANIZATION')

('PHP', 'ORGANIZATION')

('Laravel', 'LOCATION')

('Monday', 'DATE')

('27th', 'DATE')

('Jan.', 'DATE')

('SAP', 'ORGANIZATION')


 Как мы видим, качество выдачи улучшилось значительно, и теперь, с учетом скорости работы и простоты использования очевидно, что для несложных задач NLTK вполне пригодна и в промышленной разработке. 

Spacy




Spacy это Python-библиотека с открытым исходным кодом для обработки естественного языка, она издается под лицензией MIT (!), ее создали и развивают Мэтью Ганнибал и Инес Монтани, основатели компании-разработчика Explosion.

Как правило, каждый, кто сталкивается с необходимостью решения каких-то задач для обработки естественного языка, рано или поздно узнает об этой библиотеке. Большинство функций доступно «из коробки», разработчики заботятся о том, чтобы библиотека была удобна в использовании. 

Space предлагает 18 меток (tags) которыми отмечаются именованные сущности, равно как и простой способ дообучить свою собственную модель. Добавьте сюда отличную документацию, огромное сообщество и хорошую поддержку — и станет понятно, почему это решение стало таким популярным в последние пару лет. 

import spacy
model_sp = en_core_web_lg.load()
for ent in model_sp(english_text).ents:
  print(ent.text.strip(), ent.label_)


Output:
7 days DATE

New York GPE

Indian NORP

Laravel LOC

Codeigniter NORP

4 hours TIME

Monday 27th Jan. DATE

FICO ORG

6 months DATE

10 days DATE

noon TIME

tomorrow DATE

Iceland GPE


Как видим, результат намного лучше, а код существенно проще и понятней. Минусы работы — большой вес моделей, медленная работа, относительно нелогичные «метки», отсутствие моделей для многих языков, в том числе русского (хотя есть мультиязычные модели). 

Flair



Flair предлагает гораздо более глубокое погружение в предметную область, библиотека создана, фактически, для решения исследовательских задач, документация неплохая, но с некоторыми провалами, есть интеграция с большим количеством других библиотек, понятный, логичный и читаемый код. 

У библиотеки развитое сообщество, причем не только ориентированное на английский язык, благодаря большому количеству доступных моделей Flair существенно более демократичен в выборе языков чем Spacy. 
from flair.models import SequenceTagger
tagger = SequenceTagger.load('ner')
from flair.data import Sentence
s = Sentence(english_text)
tagger.predict(s)
for entity in s.get_spans('ner'):
    print(entity)


Output:
Span [6,7]: "7 days" [