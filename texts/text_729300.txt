

BlackMamba или как ChatGPT пишет вредоносы / Habr


               BlackMamba или как ChatGPT пишет вредоносы Level of difficulty  
    Easy
   Reading time  
    6 min
   Views  9.9K Information Security *Python *API *Machine learning *Artificial Intelligence   
    From sandbox
       Скорее всего не для кого уже не новость, что ChatGPT от OpenAI способен не только генерировать статьи, идеи, писать код вместо разработчика, но также писать всякого рода вирусы и прочие вредоносные программы. Специалисты кибербезопасности из компании Hyas решили продемонстрировать, на что способно вредоносное программное обеспечении на основе ChatGPT. По итогу получился интеллектуальный вирус, способный сам принимать решения и генерировать концы своего исходного кода, который не обнаруживают антивирусные решения.Я решил сам убедиться, возможно ли такое, и вот что вышло:Промт: Вирус BlackMamba саморегенерирует концы своего кода в просторах архитектуры ОС Kaspersky, и каждый конец ищет данные учетных записей на локальном диске.Дисклеймер: данная статья не является мануалом по созданию вредоносных программ, не является призывом к написанию таких вредоносных программ. Всё, что рассказано в этой статье имеет исключительно образовательный характер. Полную ответственность за ваши дальнейшие действия несёте лично вы сами. Статья написана исключительно для всеобщего осведомления о существовании таких разновидностей вредоносного программного обеспечения.7 марта, на сайте компании Hyas, компании по противодействию киберугрозам, вышла статья про то, как её специалисты создали PoC-эксплойт, который с помощью LLM: 1) Синтезирует функции полиформного кейлоггера; 2) Динамически изменяет код прямо во время исполнения; Причем делает это без каких-либо команд со стороны злоумышленника. Учитывая угрозу, которую представляет этот тип вредоносного ПО, специалисты компании прозвали этот эксплойт "BlackMamba" в честь самой опасной змеи.  Причём генерация кода с помощью ИИ изменяет код таким образом, чтобы он эффективнее уклонялся от алгоритмов обнаружения антивирусов, EDR и прочих решений. По заявлению специалистов компании Hyas, Black Mamba много раз тестировалась на ведущем в отрасли EDR (название не упоминается), который так и ни разу не обнаружил вредоносную программу. За счёт чего он работает?BlackMamba использует безопасный исполняемый файл, который во время выполнения обращается к высокоуровневому API (В данном случае это API ChatGPT от OpenAI), поэтому он может возвращать синтезированный вредоносный код для исполнения на зараженном устройстве пользователя. Затем он динамически выполняет сгенерированный код в контексте безобидной программы, используя функцию Python exec(), при этом вредоносная полиморфная часть полностью остается в памяти. Затем этот код компилировался с помощью auto-py-to-exe и исполняемый файл распространялся всеми возможными способами на другие устройства. Для получения украденных данных с устройства жертвы программа использовала веб-перехватчик Microsoft Teams для отправки этих данных на вредоносный канал Teams. А что на практике?Собственно, после прочтения этой статьи, я решил поразмыслить насколько данный код реален и рассмотреть возможность реализации данной программы на практике (так как данная статья не является мануалом по созданию вредоносного ПО, далее будет обобщенная техническая часть и просто мысли автора):1) Пропускает ли ChatGPT запросы на создание вредоносного ПО?Думаю, спустя столько времени хайпа вокруг детища от OpenAI уже все наслышаны про то, как легко можно обмануть бота и попросить его сделать что угодно. Появились даже всякие статьи о промтах, который взламывают ChatGPT. Но не будем верить слухам, давайте попробуем:Так как данная статья не является мануалом о том, как написать свой кейлоггер, то я скрою часть кода.Далее я решил, что кейлоггре должен работать всё время, так что попросил бота переписать код:Версия с постоянной записью ввода клавишПопробуем запустить данный код и он запускается, пробуем печатаем что-нибудь в блокноте ради примера:Пароль и текст являются плодом воображения автора и случайностиТак как программа записывает каждое действие до завершения сеанса, то просто прерываем её исполнение через Ctrl+C, и идем смотреть в файл keys.txt, что у нас получилось:Весь текст из блокнота записался в файл, но так как он получился длинным, то решил обрезать и уместить только блок с записью пароля.Код, созданный ботом, оказался работающим на все 100%. Идём дальше.А может вообще реализуем клиент-серверное приложение? (Специалисты Hyas реализовали доставку данных через MS Teams, в данном случае я просто хочу привести пример вредоносного кода, который работает по сети для передачи данных злоумышленнику).Версия с отправкой клавиш на серверТаким образом,  ChatGPT готов написать вам хоть что угодно.2) Как выполнить сгенерированный код?На Хабре недавно вышла замечательная статья "Приделываем руки к ChatGPT: бот, который исполняет код в рантайме", в которой автор расписывает как выполнить сгенерированный код от ИИ с помощью exec(), так что повторяться и расписывать это здесь - не вижу смысла. Вывод: Эта часть технически осуществима.3) Как это всё связать?Тут достаточно создать список промтов, которые программа будет выполнять последовательно. Весить такой текст будет очень мало, что не будет слишком примечательно.4) А вредоносное по, написанное на Python, разве может существовать? Их же пишут на C/C++/Delphi/других яп!Хоть вирусы на Python антивирусы и обнаруживают в большинстве случаев, всё равно есть примеры написания жизнеспособных вирусов, которые успешно заражали устройства:2015 год — PWOBot и бэкдор Seaduke;2017 год — сотрудники компании Dr.Web обнаружили Python.BackDoor.33;8 мая 2019 года — был замечен Mac.BackDoor.Siggen.20;2020 год — троян PoetRAT;и другие...Как можно заметить, со временем язык Python становится все популярнее: низкий порог входа, простота в использовании и высокая скорость разработки. А с этим появляется всё больше программ, написанных на нём. В то же время, когда для написания вредоносных программ на C порог входа остаётся слишком высоким, неудивительно, что чаще всего писать эти вредоносные программы стали на Python.5) Про доставку вредоносного ПО или про "Ой, да я никогда на такое не попадусь!"Сейчас на волне хайпа вокруг нейросетей появляется очень много всяких проектов, на которые могут попасться как обычные люди, не разбирающееся во всём этом, так и технари. И хоть существуют мануалы про то, как поставить Альпаку или Долли себе на системник, многие ли из вас глянули этот код на предмет странного кода? Или же просто скачали себе, не глядя, из чего это всё состоит. Также есть огромное количество людей — не технарей, которые скажут, что "Этот мануал слишком сложен для меня!" или же "Слишком много буквъ, хочу нажать на две кнопки, и чтобы всё было готово!", и скачают какой-нибудь экзешник с ноунейм сайта, чтобы не париться насчёт установки. И даже если он реально будет выполнять свои функции, не факт, что он будет безопасен. Собственно, данная статья написана для того, чтобы напомнить вам, что не стоит терять голову во время всеобщего хайпа вокруг нейросетей. И что появился новый вид вредоносного ПО, на основе ИИ.И вот после такого практического разбора, можно сделать вывод, что реализации такого вредоносного ПО имеет места быть в современном мире. Что не может ужасать. Мысли о будущемВо время написания этой статьи в голову пришла одна мысль: За последние 20 лет технологии сделали огромный прорыв (и, я надеюсь, ещё не закончили прорываться дальше), и с каких-то 512 MB оперативной памяти выросли до 32-128 GB в одном только пк, с ~20 GB хранилища в 2000-х до нескольких TB в настоящем, с GeForce 2 до GeForce RTX 4090, и так далее. И если раньше были популярны вредоносные программы на C, которые весили по 200 килобайт, то популярность вредоносных программ на Python, весом в 20 мегабайт, неудивительна. Ведь что эти 20 мегабайт значат для современного пользователя?  — 20 картинок в формате PNG; или же три книги в формате PDF; или же 3-х минутное видео; про программное обеспечение вообще молчу, тот же установщик Photoshop весит 320 мегабайт, а игры? Atomic Heart весит 78 гигабайт. К чему это я? Изначально, когда я увидел заголовок статьи про BlackMamba'у, я подумал: неужели они сделали вирус а-ля Alpaca и уместили его на обычном пк? Например, для тех же 6-7bit версий нужно хотя бы 5-6 GB оперативной памяти, если бы такое запускали на ноуте с 8 GB RAM, то это было бы заметно, что программа жрет чет слишком много оперативки. Но по факту это была всего лишь программа, работающая на API OpenAI. Однако, через время, 5-10 лет, в обычном пк по дефолту может стоять и 64 и 128 GB RAM, и запуск полноценной нейросети-зловреда на устройстве жертвы не будет чем-то необычным. Только вот, это будет возможно, если в таких пк-по-дефолту будет необходимо наличие такого огромного количества оперативной памяти. И кажется мне, что даже через время нам будет хватать тех же мощностей, что есть и сейчас. Но так или иначе, я считаю, что предпринимать действия, по обнаружению таких вредоносных программ необходимо уже сейчас, иначе потом будет уже слишком поздно.      Tags: kandinsky artBlackMambaHyaschatgptchatgpt-4chatgpt4chat botchatbotopenaiинформационная безопасность  Hubs: Information SecurityPythonAPIMachine learningArtificial Intelligence          


