

Практические применения генеративных моделей: как мы делали суммаризатор текстов / Habr


              19  May   at 12:43  Практические применения генеративных моделей: как мы делали суммаризатор текстов SberDevices corporate blog Python *Machine learning *Artificial Intelligence Natural Language Processing *      


В последнее время вышло большое количество генеративных моделей для русского языка. Команды Сбера выпустили целое семейство авторегрессионных моделей ruGPT3, ruT5, о которых мы подробно писали ранее. Сегодня мы расскажем, как практически применять обучение таких моделей и какие продукты можно получить на их основе.


Мы выводим в открытый доступ два новых сервиса: Рерайтер и Суммаризатор. Модель «Рерайтер» способна переписать любой текст другими словами с сохранением смысла вне зависимости от длины и формата — от новостей и художественной литературы до постов в социальных сетях. Модель «Суммаризатор» позволяет создать сжатое изложение исходного текста, сохраняющее его главные тезисы. Эта модель может быть полезна для экономии времени читателя, а также выделения главных мыслей объёмных документов, научной или бизнес-литературы. В частности, использовать сервис можно для подготовки обзоров научных работ на заданную тему, создания новостных дайджестов, выделения наиболее важных событий в лентах информагентств для аналитики. 


Демо бета-версии сервисов с бесплатным доступом опубликованы в маркетплейсе AI-Services, который размещен в SberCloud ML Space — платформе полного цикла ML-разработки. 


В текущей серии постов мы подробно поговорим о том, как с технической точки зрения можно сделать на основе генеративных моделей системы рерайтинга и суммаризации.

Что такое суммаризатор

Суммаризация — сокращение текста, когда из него автоматически убираются незначительные детали и остаётся только суть. Это один из трудоёмких и сложных этапов обработки текстов. Мы хотели создать прикладной инструмент (онлайн-сервис), который бы упростил работу с большим количеством текстов для редакторов, копирайтеров и др. Суммаризатор должен уметь работать с текстами разной длины и доменов. Ниже расскажем, как мы тестировали наш сервис с помощью текстов новостей, художественной литературы, комментариев из социальных сетей.


Существует два способа решения задачи суммаризации — экстрактивный и абстрактивный. В эсктрактивном подходе из исходного текста выбираются наиболее важные предложения, которые одно за другим склеиваются в абстракт текста. Абстрактивный метод подразумевает генерацию нового текста, содержащего основные мысли из исходного. Нам было интересно протестировать генеративные модели, предобученные нами на русском языке, на задаче абстрактивной суммаризации.

Как мы обучали

Для задачи суммаризации на русском языке существует не очень много датасетов. Все они собраны из новостей, где абстрактом, в основном, служит короткий заголовок статьи. Заголовки, особенно новостные, чтобы привлечь внимание, часто не отражают реального содержания статьи, например:

Абстракт: «О разрухе в головах»

Текст: «Недавно одна газета посвятила разворот Неделе моды в Лондоне. Там была икона панк-дизайна Вивьен Вествуд, которую, по словам издания, с трудом удалось на секунду вырвать из толпы фанатов, чтобы задать единственный вопрос.»


Особенность новостного домена ещё в том, что абстракты очень короткие в сравнении с текстом — то есть уровень компрессии слишком высокий. Мы выбрали в качестве датасета GusevGazeta с самыми длинными абстрактами. Также, чтобы обойти выше перечисленные недостатки существующих датасетов, дополнительно мы с помощью редакторов создали свой датасет (в таблице ниже назовем его private dataset). Новости для датасета были отобраны и отредактированы людьми, абстракты писались вручную.

Сравнительная таблица корпусов:


 Название корпуса
Размер корпуса
Средняя длина абстракта
Средняя длина текста 

(в символах)


MLSUM
30k
12 слов
5321


GusevGazeta
60k
41 слово
4515


XLSum 
70k
25 слов
4055


ria 
600k
8 слов
1953


private dataset
8k
74 слова 
1340



Для обучения мы взяли модели ruT5-large и rugpt3large_based_on_gpt2 из нашего зоопарка моделей. Модели учились на данных GusevGazeta и нашем приватном новостном датасете. Мы также провели оценку моделей с разными стратегиями генерации, выбрав лучшую, и подобрали параметры генерации. Для сравнения результатов мы взяли лучшие результаты наших моделей и довольно известную обученную на GusevGazeta модель суммаризации для русского языка mbart.


Стандартные метрики для оценки задач обработки языка ROUGE и BLEU также используются для оценки суммаризации, но почти ничего не говорят о качестве переданного смысла в сгенерированном тексте. Дело в том, что абcтрактивная суммаризация может изменять текст: менять предложения местами, перефразировать какие-то куски. Поэтому мы решили включить в оценку метрику BERTscore.


Практически по всем метрикам, модель ruT5 показывает хорошие результаты сравнимые с известным суммаризатором на основе mbart. Однако последний заметно проигрывает нашим предобученным rut5 и rugpt3 по метрике BERTscore. 

Сравнительная таблица моделей на тестовом сете GusevGazeta:


Модель 
BERTscore
ROUGE-1-F
ROUGE-2-F
ROUGE-L-F
BLEU         


MBART
55.5
32.1
14.2
27.9
50.1


ruT5-large

(генерация BS)
73.68
31.9
13.3
27.8
49.6


ruGPT3-large 

(генерация top-p)
71.44
28.4
11.7
21.6
29.9



Как можно заметить, лучшей моделью для суммаризатора получилась модель ruT5 со стратегией генерации beam search.

Оценка

Модели были оценены на тестовом корпусе текстов различных длин из нескольких доменов: социальные медиа (SocMedia), литература (Literature), новости (News) и отзывы (Reviews). Самые короткие тексты в домене — отзывы, самые длинные — в новостном домене.



Reviews
Literature
SocMedia
News


Средняя длина в символах
990
2453
2516
3050



Для модели суммаризации были отобраны тексты, ограниченные снизу по длине (порог длины примерно равен средней длине текстов). Из каждого домена было взято по 125 тестовых кейсов. В результате применения модели мы получили 500 пар <оригинальный текст — абстракт> для проведения оценки. 


Для оценки абстракта мы просили краудсорсеров оценить следующие параметры текста, получившегося в результате работы модели:


Grammar — правильно ли написан текст с точки зрения правил русского языка;
Meaning — верно ли передан смысл исходного текста;
Coherent — связность текста (причинно-следственная связь, порядок фактов).

Интерфейс задания для оценки задачи суммаризатора:



Оценка краудсорсеров:


 Metric
Reviews
Literature
SocMedia
News


Grammar
0.9363
0.9949
0.8827
0.9896


Meaning
0.5418
0.7898
0.3408
0.5498


Coherent
0.8964
0.9576
0.8883
0.9046



Для пар <оригинальный текст — абстракт> рассчитаны также автоматические метрики (умножены на 100):


Mean Bleu — средняя оценка по всем текстам метрики BLEU(BLEU-1);
Mean Rouge — средняя оценка по всем текстам метрики ROUGE(ROUGE-L);
Bert score — средняя оценка по всем текстам метрики BertScore.



 Metric
Reviews
Literature
SocMedia
News


BERTscore
85.21
77.56
75.93
74.53


ROUGE-L-F
70.19
39.3
35.8
30.28


BLEU
37.93
1.77
1.58
0.51



Мы оценили, насколько хорошо лучшая модель суммаризации сокращает текст. Для отзывов модель в среднем сокращает лишь половину текста. Также был рассчитан процент плагиата в тексте абстракта. Аналогично, для отзывов около половины абстракта является плагиатом исходного текста.



Reviews
Literature
SocMedia
News


Усреднённый процент сжатия текста
51%
20%
19%
16%


Усреднённый процент плагиата
54%
13%
19%
16%


Как использовать AI-сервис Суммаризатора

Демо Суммаризатора, а также Рерайтера доступны в виде AI-Service — деплоя, развернутого на платформе SberCloud ML Space. Что это значит? Это бесплатные, развёрнутые в открытый доступ демо с привычным интерфейсом SWAGGER и возможностью отправки запросов по REST API. 


Для использования демо сервисов необходимо перейти в каталог AI-Services на cайте SberCloud и выбрать и выбрать «Суммаризатор» или «Рерайтер» — по кнопке «Подключить» появится доступ в интерфейс Swagger, с которым можно взаимодействовать. Базовое использование модели в AI-Service подразумевает работу с уже обученной моделью в режиме инференса. 


Вы также можете получить тестовый доступ к платформе ML Space  для запуска промышленных версий сервисов и всей подборки ruGPT-3 & family, включая эксклюзивные ruDALL-E, ruGPT-3 и ruCLIP, на высокопроизводительной инфраструктуре SberCloud.




На вход подаётся оригинальный текст с настраиваемыми параметрами генерации:


text — оригинальный текст для суммирования; 
num_return_sequences — количество примеров, из которых выбирается лучший финальный текст. Дефолтное значение 5; 
num_beams — параметр генерации текста num_beams. Дефолтное значение 7; 
no_repeat_ngram_size — параметр генерации текста; no_repeat_ngram_size — все ngrams такого размера могут встречаться только один раз. Дефолтное значение 5; 
repetition_penalty — параметр генерации текста repetition_penalty, используется в качестве штрафа за слова, которые уже были сгенерированы. Дефолтное значение 2.0; 
length_penalty — параметр генерации текста length_penalty — экспоненциальный штраф к длине. Дефолтное значение 2.0;
genstrategy — параметр переключения между стратегиями генерации (0 — для beam search, 1 — для sampling). Дефолтное значение 0;
top_k — параметр top_k текста для генерации. Дефолтное значение 30;
top_p — параметр top_p текста для генерации. Дефолтное значение 0.95.


Выходные параметры инференса для суммаризатора, возвращается словарь со следующими полями:


comment — комментарий («Ok», если суммаризация прошла успешно);
origin — оригинальный текст (текст);
predictions — сокращённый текст (абстракт).


Ниже представлены примеры запросов к сервису:

Запрос:
Текст: «Качество нормальное, за эти деньги хорошо. Конечно же есть недостатки по пошиву. Брала XXL потому что рост 180 см, так советовал продавец.  ….»
Параметры:  num_beams: 5, num_return_sequences: 3, length_penalty: 0.5 


Результат
Комментарий: «Ok». 
Текст: «Качество нормальное, за эти деньги хорошо. Конечно же есть недостатки по пошиву. Брала XXL потому что рост 180 см, так советовал продавец. На фото я кушала 3 раза уже, но пояс очень сильно торчит. Этот размер на красавиц с большими объёмами, но явно не на талию 70 см, в ягодицах объём 100, но тоже большеваты. Зато в ногах отлично и длина очень хорошая. У меня очень длинные ноги и мне хорошо. Пояс приходится подворачивать, это очень неудобно. Возможно найду Ателье, где смогут ушить их. Тянутся невероятно :) но вот воняют ужасно. Уже неделю адский запах не выветривается. Тёплые, но в мороз -20 градусов они не спасут на голое тело. Не верьте отзывам, они наверно шерстяные колготки под них одевают. В помещение ноги не преют, хотя думала будут потеть сильно. С радостью бы такие и другого цвета купила, но на 2 размера меньше. Но тогда длина будет короткой. Продавец, может попробуете шить несколько штук на высоких и стройных девушек? На рынке нет никого предлагающего длинные леггинсы».

Абстракт: «На рынке нет никого предлагающего длинные леггинсы. Этот размер на красавиц с большими объёмами, но явно не на талию 70 см, в ягодицах объём 100, но тоже большеваты. Зато в ногах отлично и длина очень хорошая. У меня очень длинные ноги и мне хорошо. Пояс приходится подворачивать, это очень неудобно. Возможно найду Ателье, где смогут ушить их. Тянутся невероятно. Уже неделю адский запах не выветривается. В помещение ноги не преют, хотя думала будут потеть сильно. Продавец, может попробовать шить несколько штук на высоких и стройных девушек?».


Запрос:
Текст: «Если гриль в вашей духовке расположен внизу.»
Параметры:  num_return_sequences: 2, num_return_sequences: 3, length_penalty: 0.5 


Результат
Комментарий: «Your text is too short. Try again with another example.» 
Текст: «Если гриль в вашей духовке расположен внизу.»

Абстракт: «Если гриль в вашей духовке расположен внизу.»


Запрос:
Текст: «Маски и глины для лица могут быть эффективными для удаления лишнего жира из кожи, однако существует также опасность того, что слишком частое использование может привести к сухости и раздражению. … »
Параметры:  top_k: 50, top_p: 0.75, genstrategy: 1


Результат
Комментарий: «Ok».
Текст: «Маски и глины для лица могут быть эффективными для удаления лишнего жира из кожи, однако существует также опасность того, что слишком частое использование может привести к сухости и раздражению. Будьте осторожны с использованием масок и постарайтесь сконцентрировать их применение на наиболее жирных участках кожи. Не используйте маски и глины слишком часто. Вместо этого следует применять их только накануне особых случаев, таких как вечеринки или большой презентации на работе.  Вы можете приобрести маски специально для жирной кожи. Будьте готовы к тому, что придется попробовать несколько продуктов, прежде чем вы найдете подходящий. Постоянное жирнение кожи в течение дня может очень огорчать вас, а слишком частое умывание способно сделать только хуже. В таком случае вы можете использовать обычные промокательные салфетки, которые помогут убрать излишки жира с поверхности кожи. Это отличный способ, который можно применять незаметно и быстро, независимо от того, где вы находитесь и чем занимаетесь.  В продаже доступен целый ряд подобной продукции, которую вы можете приобрести для удаления жирного блеска в течение дня. Также вы можете использовать кусочек ткани или туалетной бумаги. Будьте осторожны со своей кожей и не трите ее слишком сильно. Астрингенты достаточно часто включаются в курс по уходу за кожей, но вы должны применять его осторожно, так как он может ее пересушивать и оказывать жесткое воздействие. Высушивание такими средствами не является решением проблемы жирной кожи и может даже усугубить ситуацию. Если вы хотите его использовать, убедитесь, что выбрали мягкое, без спирта и без содержания жиров в составе.  Наносите только на маслянистые участки кожи. При возникновении сухости прекратите использование астрингента на этих участках кожи. Не забывайте, что у большинства людей кожа представляет собой сочетание сухих и жирных участков, поэтому необходимо подбирать правильный подход для каждой из этих зон. Посетите своего врача или дерматолога, если вы придерживаетесь правильного ежедневного ухода за кожей, но маслянистость не уменьшается. Специалист в состоянии подсказать вам, какие дальнейшие шаги необходимо предпринимать, и даже может выписать вам некоторые препараты.  Помните, что выделение кожного жира является абсолютно естественным и нормальным процессом. Если данная ситуация вас беспокоит, обратитесь к профессионалу за помощью..».

Абстракт: «Маски и глины для лица могут быть эффективными для удаления лишнего жира из кожи, однако существует также опасность того, что слишком частое использование может привести к сухости или раздражению. Вы можете использовать обычные промокательные салфетки, которые помогут убрать излишки жира с поверхности кожи. Астрингенты достаточно часто включаются в курс по уходу за кожей, но вы должны применять его осторожно, так как он может ее пересушивать и оказывать жесткое воздействие. Высушивание такими средствами не является решением проблемы жирной кожи.».



В следующих сериях… 

В этом посте мы рассказали о наших экспериментах, как из генеративных моделей Сбера сделать практический инструмент для сокращения текста. Область применения сервиса очень широкая. Можно использовать суммаризатор, например, в качестве помощи новостным редакторам и журналистам, контент-менеджерам, студентам для сокращения текста. Однако наиболее интересен сервис в связке с рерайтером, о котором пойдёт речь в будущем посте.     Tags: nlp (natural language processing)речевые технологииязыковые моделиrut5суммаризация Hubs: SberDevices corporate blogPythonMachine learningArtificial IntelligenceNatural Language Processing          


