

Тестируем новые языковые модели. WizardLM / Habr


               Тестируем новые языковые модели. WizardLM Level of difficulty  
    Easy
   Reading time  
    12 min
   Views  4.1K Timeweb Cloud corporate blog Machine learning *Reading room Artificial Intelligence  
    Opinion
        Ещё до выхода «утёкшего» внутреннего документа от Google стало ясно, что намерение OpenAI закрыть всю техническую информацию по моделям GPT-3.5 и GPT-4 вызывает у сообщества ещё больше желания иметь доступную открытую реализацию модели. Недавняя презентация Bard AI от Google на базе модели PaLM 2, не показала каких-то новых прорывных сверхвозможностей и примерно равна уровню GPT-4.


Так по мнению авторов выглядит иллюстрация к их модели:



Это может косвенно свидетельствовать о том, что нащупан некий промежуточный барьер в текущем витке развития LLM и дальнейшее улучшение будет уходить в расширение поддержки мультимодальностей, таких как аудио, видео и других данных, а так же улучшение архитектуры и повышение размера контекста.


Появляются модели, реализующие концепцию мультимодальности, близкой к GPT-4 (miniGPT-4, LLaVA) и мультимодальные датасеты для обучения таких моделей. Скорость улучшения качества доступных моделей растёт с невероятной скоростью. 




Появляются открытые бенчмарки (lmsys, LLM Logic Tests, LLM Leaderboard) для тестирования качества ответов моделей. 






Продолжают появляться комплексные датасеты с триллионом+ токенов и инициативы обучить с нуля аналоги LLaMA (OpenLLaMA, Cerebras, Pythia), при коммерческом использовании которых не будет юридических проблем. 


Распределение данных в датасете RedPajama 1.2 trillion token:



Важными составляющими начавшейся в этом году гонки больших языковых моделей, можно считать «слив» LLaMA и реализацию инференса через библиотеку ggml и llama.cpp на базе этой технологии, а так же технологию LoRA адаптеров с применением PeFTтехнологии.


Синергия этих составляющих дала настоящий буст в развитии LLM, благодаря снижению порога как для обучения, так и для инференса. Ведь теперь для запуска модели с 30 млрд параметров у себя на десктопе, достаточно не самого топового процессора и немного памяти. Исчезает необходимость в дорогостоящих GPU для взаимодействия с моделями. Причём llama.cpp сделала эту возможность кросс-платформенной.


Тот факт, что Bard AI от Google и Bing AI от Microsoft стали доступны публично так скоро, а так же «откровение» из недр Google может говорить о том, что корпорации видят большой потенциал и риски в том, что включившееся в гонку сообщество развивает открытые технологии LLM такими высокими темпами.


Для нас такая ситуация, безусловно, выглядит благоприятно, потому как, во-первых, конкуренция — это двигатель развития, а во-вторых, доступные модели не дадут корпорациям возможности накручивать стоимость услуг для доступа к их моделям.


Сегодня я хочу поделиться результатами своих экспериментов с одной новой LLM, на базе дообученной LLaMA 7b: WizardLM.

