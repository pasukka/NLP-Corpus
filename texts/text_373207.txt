

О чём хорошие боты спорят в Википедии / Habr


              26  February  2017 at 14:09  О чём хорошие боты спорят в Википедии Crowdsourcing Artificial Intelligence       


В августе 2011 года Игорь Лабутов и Джейсон Йосински, два аспиранта Корнелльского университета, запустили пару чат-ботов напротив друг друга. Начав с простого приветствия, разговор ботов быстро превратился в словесную перепалку с обвинениями и спором о Боге. Первая беседа представителей ИИ завершилась конфликтом. 


На страницах Википедии война правок уже давно ведётся с привлечением слабого ИИ, но иногда даже «хорошие» боты вступают в бесконечный конфликт.


Интернет-боты, которые выполняют автоматизированные запрограммированные действия в зависимости от контекста, родились практически вместе с самим интернетом. С тех пор они постоянно совершенствовались и усложнялись. Один из-первых чат-ботов Eggdrop приветствовал посетителей IRC-каналов в 1993 году. По мере усложнения боты начали брать на себя всё больше и больше функций. Значительная часть современных коммуникаций в интернете — это боты. Например, в 2009 году они генерировали около 32% всех сообщений в твиттере для самых активных пользователей. В целом они тогда генерировали 24% всех твитов. Маркетологи считают, что 54% просмотров баннерной рекламы в интернете тоже обеспечивают боты. Представители слабого ИИ контролируют сотни тысяч аккаунтов на игровых сайтах, а десятки тысяч искусственных женщин «раскручивают» клиентов на сайтах знакомств.


Численность ботов в интернете постепенно растёт. Они работают 24 часов в сутки 7 дней в неделю. И как показывает пример ботов из Корнелльского университета, эти цифровые создания редко запрограммированы на сотрудничество — поэтому могут вступать в конфликт. Чем более сложную деятельность ведут боты, чем лучшая у них функциональность и реагирование на контекст, тем больше вероятность, что боты встретятся и начнут мешать друг другу.


У ботов разные функции. Некоторые перечислены в таблице, в зависимости от выполняемой задачи и намерений. Во второй колонке перечислены боты с хорошими намерениями, в третьей колонке — с вредоносными намерениями. Вполне логично, что боты одинаковой функциональности из второй и третьей колонки будут вступать в конфликт. Они должны вступать в конфликт. Зачастую прямая задача хороших ботов — ликвидация негативных последствия действия вредоносных ботов.


Таблица 1


Несмотря на надежды футурологов, до сих пор ИИ неведомы понятия морали и культуры, даже в простом общении. Это только увеличивает вероятность конфликтов.


Специалисты из Оксфордского института интернета недавно опубликовали результаты исследования, что происходит на страницах Википедии, когда на странице правок встречаются несколько ботов, предназначенных для внесения изменений в статью.


По статистике, 15% всех правок в Википедию вносят именно боты. У современных программ продвинутая функциональность: они умеют автоматически исправлять вандализм, отслеживать баны, проверять правописание, создавать ссылки между статьями на разных языках, автоматически импортировать контент, осуществлять майнинг данных, определять нарушения копирайта, приветствовать новичков и т.д.


Доля ботов в правках Википедии (B) и доля правок людей и ботов, которые отклоняются (С, D)


Боты Википедии не подчиняются центральной власти — это принципиальная и важная идея самоорганизующегося общества, единственный способ выстроить действительно эффективную систему. Но если отдельные редакторы Википедии могут не сойтись во мнении ми многократно править друг друга, то и боты отражают их точки зрения.


Исследование показало, что если правки ботов отклоняются, то обычно это происходит по инициативе других ботов, а не людей. При этом доля правок «бот-бот» постепенно возрастает, что наталкивает на мысль о нарастании конфликта и напряжённости в сообществе ботов.


Доля правок «бот-бот» постепенно возрастает


Наибольшее количество правок ботов, которые исправляются другими ботами, а затем исправляются обратно, относится к «несогласию между ботами, которые специализируются на создании и исправлении ссылок между различными языковыми редакциями энциклопедии». По мнению авторов исследования, «отсутствие координации может быть связано с тем, что в разных языковых редакциях немного различаются правила именования и соглашения». Чаще всего в конфликтах замечены боты Xqbot, EmausBot, SieBot и VolkovBot, а война правок между ботами чаще всего происходит в нескольких статьях, среди них:


Первез Мушарраф (бывший президент Пакистана)
Узбекистан
Эстония 
Беларусь
арабский язык
Нильс Бор
Арнольд Шварценеггер


Как было сказано выше, правки происходят преимущественно в ссылках между языковыми редакциями.


Википедия — лишь маленький пример экосистемы, густо населённой сложными ботами. Как видно из таблицы 1, ботосфера представляет собой гораздо более обширное пространство. Такие же конфликты, а иногда ещё более острые конфликты, могут возникать в других областях. Самые известные классические примеры — войны ботов на биржах (в т.ч. высокочастотный трейдинг) и на аукционах (в т.ч. скальпинг), а также автоматическая скупка ботами дефицитных товаров в интернете (билеты на концерты, места в очередях в посольство и т.д.).


В Википедии экосистема ботов находится под постоянным контролем. Здесь трудно представить себе расцвет пропаганды в твиттере и социальных сетях, где боты успешно распространяют фейковые новости и раскручивают фальшивые новостные сюжеты, чтобы вывести их потом на уровень центральных СМИ и повлиять на общественное мнение. Информационные войска по пропаганде и контрпропаганде в интернета созданы и эффективно работают в нескольких странах мира. Боты в твиттере координируют свои действия как часть ботнетов, хотя такие ботнеты редко удаётся идентифицировать, разве что случайно.


Научная работа специалистов из оксфордского института интернета опубликована 23 февраля 2017 года в журнале PLOS One (doi:10.1371/journal.pone.0171774).    Tags: ВикипедияботыИИконфликты мненийвойна правокботосфера Hubs: CrowdsourcingArtificial Intelligence          


