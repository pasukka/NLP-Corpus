

Как работают системы распознавания речи / Habr


               Как работают системы распознавания речи  Reading time  
    5 min
   Views  7.4K Amvera corporate blog Programming *Machine learning *Reading room Artificial Intelligence       В русскоязычном сегменте интернета не так много информации о том, как устроены системы распознавания речи. В этой статье мы, команда проекта Amvera Speech (ООО "Клэрити"), расскажем нюансы технологии и опишем путь создания собственного решения. В конце статьи – бесплатный телеграм-бот для теста системы распознавания речи, построенной на архитектуре, описанной в статье. Сложности, с которыми сталкиваются разработчики систем распознавания речи:   Есть распространенное мнение, что распознавание речи - давно решенный кейс, но это не совсем так. Действительно, задача решена для определенных ситуаций, но универсального решения пока не существует. Это происходит из-за ряда проблем, с которыми сталкиваются разработчики: Зависимость от доменаa)     Разные дикторыb)    «акустический» канал записи звука: кодеки, искаженияc)     Разное окружение: шум в телефоне, в городе, фоновые дикторыd)    Разный темп и подготовленность речиe)    Разная стилистика и тематика речи Большие и «неудобные» наборы данныхНе всегда интуитивно понятная метрика качества Метрика качестваКачество распознавания измеряется по метрике WER (Word Error Rate).Insertions – вставки слов, которых нет в исходной аудиозаписи Substitutions – замены слов на некорректные  Deletions – система слово не распознала и сделала пропуск Пример расчетаИсходные данные: Стационарный (неразборчивая речь) телефон зазвонил поздней ночьюГипотеза: Стационарный синийi айфонs прозвонилs поздней ночью WER = 100*(1+2+0)/5 = 60% (т.е. ошибка равна 60%).При этом есть как простые заблуждения при подсчете метрики, так и более сложные.Пример простых заблуждений при подсчете метрикиЕ/е с точками. Система переводит речь в текст и везде использует букву Е без точек, в то время как эталон, с которым сравнивается транскрипция, содержит Е с точками. Это  неправомерно увеличивает количество Substitutions и увеличивает WER на 1%. разное написание таких слов, как алло, але, алле и т.д.строчные и заглавные буквы усреднение по текстам, а не подсчет общего количества слов. Бывает, что в одном тексте WER 0,6, в другом 0,5, а в третьем – 0,8. Неверно будет вывести WER как среднее арифметическое из этих значений. Правильнее – подсчитать общее количество слов на всех текстах и на основе этого рассчитать WER. Более сложные заблуждения могут быть вызваны тем, что на разных тестовых выборках WER будет разным. Иногда на одной конкретной аудиодорожке испытываемое решение работает лучше или хуже, чем решения конкурентов. Но делать из этого общий вывод о качестве работы решения – некорректно. Необходимы результаты на большом объеме данных. Типы систем распознавания речиСистемы распознавания речи бывают двух видов – гибридные и end2end. End2end переводят последовательность звуков в последовательность букв. Гибридные системы содержат акустическую и языковую модель, работающие независимо. Решение Amvera Speech построено на гибридной архитектуре. Устройство гибридной системы распознавания речиПринцип работы гибридной системы распознавания речи: Нейронная сеть классифицирует каждый конкретный фрейм звука,HMM моделирует «динамику», «лексикон», «лексику», опираясь на постериоры NN,Алгоритм Viterbi (Viterbi decoder, beam-search) занимается поиском по HMM   оптимального пути, с учетом постериоров классификатора.Общая схема построения гибридной системы распознавания речиПервым шагом в гибридной модели распознавания речи выделяются признаки. Как правило, это MFCC коэффициенты.Затем акустическая модель решает задачу классификации фреймов. Далее используется Viterbi-decoder (поиск по лучу). Он использует предсказание акустической модели и статистику языковой модели, которая по ngram показывает вероятность встречаемости звуков и слов. Затем производится рескоринг и выдается наиболее вероятное слово.Устройство гибридной архитектурыНиже – иллюстрация классификации фреймов. Продемонстрированы фонемы в фреймах для слов «да и нет». Вероятность каждой из фонем записана в соответствующую ячейку.   № фрейма/графема012345678Д000,60,700000А00.100.10.40.50.40.10Н000000000Е00.10.10.10.60.50.400Т000.30000.100Тишина (SIL)10.800.1000.10.91Визуализируем принцип работы вычислительного графаПредставьте, что у вас в первом фрейме классификатор обнаружил фонему «д», и так 10 раз подряд. Цикл будет выполняться, пока не обнаружится фонема «а», и если слово содержится в словаре, оно будет записано. Аналогично, алгоритм отработает слово «нет» и закончит работу, когда вканале наступит тишина «SIL».Визуализация принципа работы поискового графаСовместим визуализацию поискового графа в связке с фреймами для большей наглядности:   Обучение гибридной системы распознавания речиРассмотрим общий принцип обучения классификатора акустической модели, принцип сопоставления фреймов с фонемами, количество классов и способы улучшения решения.Обучение классификатора акустической модели:Возьмем графемы.Пример – М, А, Ш, АПредставим их в виде фонем, получится m* i1 sh a0Для русской речи на обучающей выборке в 80 часов фонемы на 1 процент лучше, при 4 тысячах часов – разницы уже нет.Используем бифоны/биграфемыМоделируют влияние соседних фонемЛевые: SIL (sil)M (м)А (а)Ш (ш)А SILПравые: SIL M(a) A(ш) Ш(а) А(sil) SILМожно использовать трифоныSIL (sil)M(a) (м)А(ш) (а)Ш(а) (ш)А(sil) SILЛибо использовать многостейтовые фонемы/графемы/трифоны …  Как фрейму приписать фонему? Проще всего это описать фразой «натянуть сову на глобус».Для этого используем связку алгоритмов Flat-start+Viterbi forced alignment:   берем пару звук-текст получаем фонемную запись разбиваем звук на равные части по числу фонем, приписывая соответствующие лейблы обучаем классификатор (обычно GMM). делаем forced alignment, получаем уточненные labels Повторяем пункт 4После нескольких итераций, получаем labels, пригодные для обучения нейронной сети.КлассыЕсли используются {би, три} {фоны, графемы}, то:Проблема 1: классов слишком многоБифоны: 57 фонем^2 – 3249Двустейтовые бифоны: (2 стейта*57 фонем )^2=12996Трифоны: 57фонем^3 = 185193Проблема 2: размеры классов не сбалансированыРешение – кластеризацияОбъединяет похожие классы (5-10 тыс. классов)Балансирует размеры классов(класс называют сеноном для фонемных, ченоном для графемных моделей)Улучшаем распознаваниеИспользуем MMI или MPE/sMBRСтроится CE-модельСтроится «числитель» - множество вариантов распознавания, приводящих к правильному ответуСтроится «знаменатель» - много неправильных вариантов распознаванияLoss = f(числитель)/f(знаменатель) т.е. «поднять» правильные и «опустить неправильные»Достоинства: sMBR несколько поднимает качествоНедостатки: стремится оттянуть выдачу label, следовательно портит time-разметку и latency.Достоинства гибридной архитектуры распознавания речиАкустическая модель отделена от языковой. Языковую модель легко дополнить дополнительной информацией (новые слова и т.д.). Можно быстро получить NBest списки для улучшения с помощью языковой модели.Для обучения достаточно несколько десятков часов аудиозаписей. Недостатки гибридной архитектуры распознавания речиНе умеют распознавать слова, которых нет в словаре.Не модно.Как итог - мы рассмотрели принцип устройства классической гибридной архитектуры распознавания речи.Бонус для дочитавших: наш телеграм бот @AmVeraSpeechBot. В боте вы можете проверить качество работы нашего решения (Amvera Speech) по распознаванию речи на основе классической гибридной архитектуры. Просто отправьте в бот короткую аудиодорожку или голосовое сообщение – и получите текстовую расшифровку.       Tags: распознавание речиasrsttkaldiamveraсистемы распознавания речисервисы распознавания речиалгоритм распознавания речи  Hubs: Amvera corporate blogProgrammingMachine learningReading roomArtificial Intelligence          


