

Исследователи изучают, как GPT-3 разбирает входящую почту / Habr


              9  February  2021 at 09:56  Исследователи изучают, как GPT-3 разбирает входящую почту Algorithms *Machine learning *Research and forecasts in IT *Artificial Intelligence       Команда исследователей из Университетского колледжа Маастрихта опубликовала работу, посвященную использованию GPT-3 в качестве почтового менеджера. В работе исследуется, можно ли эффективно использовать GPT-3 и проигрывает ли модель человеку. Авторы описали варианты использования модели в секторах страхования, энергетики и государственного управления.  Исследователи отмечают, что модели нужно предоставить точные данные для обучения. Для решения этой проблемы требуется архитектура, которая позволяет GPT-3 анализировать содержание письма и оценивать, какая информация актуальна для ответа. Таким образом, нужно разработать решение для поиска по большим массивам неструктурированных ресурсов. При этом использование GPT-3 все же может быть экономически выгодным. Затраты на масштабирование системы будут практически нулевыми относительно другого ПО, хотя придется потратиться на дополнительное обучение системы. Главная проблема, связанная с использованием GPT-3, заключается в том, что модель может сгенерировать вводящий в заблуждение или даже оскорбительный текст. Если речь идет о публичной деятельности или работе компании, то это может привести к судебным искам. В настоящее время исследование продолжается, и пока делать конкретные выводы о работе системы рано. Обычный чат-бот, как и прежде, пока выглядит лучшей альтернативой.OpenAI представила модель машинного обучения GPT-3, обученную на 175 млрд параметров, в июне 2020 года. В отличие от предшественников GPT-2 и GPT-1 ее исходный код или обучающий набор данных решили не открывать. Модель уже попытались применить в медицинской сфере для общения с пациентами, но результаты эксперимента оказались неутешительными.Между тем создатели проекта GPT-Neo от EleutherAI решили воссоздать аналог GPT-3, но с открытым исходным кодом. Большую часть модели уже построили и обучили модели размера GPT-2, а также реализовали несколько экспериментальных архитектур.    Tags: gpt-3почтаписьмагенерация текстовnlp (natural language processing)исследование Hubs: AlgorithmsMachine learningResearch and forecasts in ITArtificial Intelligence          


