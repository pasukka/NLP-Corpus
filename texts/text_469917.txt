

Fasttext на PHP\Python. Первые шаги / Habr


               3  October  2019 at 10:13  Fasttext на PHP\Python. Первые шаги PHP *Python *Artificial Intelligence       Чё, зачем, почему



Уже достаточно давно популярность набрали разного рода алгоритмы машинного обучения. Также, благодаря крупным компаниям, которые двигают технологический прогресс, появилось много opensource продуктов. Одним из них является Fasttext, о котором пойдет речь ниже.


Fasttext — разработка от Facebook. Основная задача программы — классификация текста. Классификация текста может понадобиться для:


объединение текстовой информации в группы по «похожести» (новости на одну тему ) 
группировка текста со схожей тематикой в одну группу (новости про автомобили)
поиск информации, которая может являться спамом
поиск кликбэйтовой информации
...


Вариантов, на самом деле, очень много и перечислять все нет смысла, идея должна быть понятна.

Первая тренировка

На странице библиотеки есть пошаговая инструкция по установке и первой тренировке. Останавливаться на них не буду. 

плюшкиУ них также есть готовые модели на разных языках для классификации тут

Настройка библиотеки

Проблема тренировки — это индивидуальность параметров. Нет каких-то параметров, которые дают гарантировано отличный результат. Вы можете найти в интернете массу (или не очень) статей с примерами параметров и вам они могут не подойти, так как будут давать неудовлетворительный результат.


Только эмпирическим путем вы сможете подобрать параметры, которые вас устроят. Ниже приведу список тех, которые заметно влияют на результат:


-dim — размерность контролирует размер векторов (масло масленое): чем они больше, тем больше информации они могут захватить, но для этого требуется больше данных. Но если данных слишком много, то процесс тренировки будет медленнее. По умолчанию используется 100 измерений. Начните со 150 и подбирайте оптимальное для вас значение.


-lr — скорость обучения. Если параметр очень маленький, то модель становиться более чувствительна к тексту и может не отличать похожие тексты, а если параметр очень большой, то наоборот, может «говорить», что тексты похожи, хотя на деле это будет не так. Начните с 0.1 (По умолчанию 0.05).


 — epoch — кол-во эпох. Это количество проходов по вашим данным. Больше — качественнее (но, увы не всегда). При этом увеличивается время тренировки. Начните со 150 (По умолчанию 5).


 — модель обучения. Прочтите описание от Facebook. Оно достаточно понятно.


 — loss — как будет происходить сравнение. Тут все очень индивидуально и зависит от данных. 

небольшое отступлениеОчень здорово то, что даже не обладая достаточными знаниями в классификации текстов и внутренних механизмов нейросети, можно получить вполне рабочую модель.

Подготовка текста

Входной текст также имеет немаловажное значение. Чем текст качественнее, тем информация от модели будет лучше. Основные правила для подготовки текста для тренировки:


 удалить все тэги
 привести к нижнему регистру
 убрать символы пунктуации
 убрать хэш-тэги, ссылки
 исключить стоп-слова
 исключить мелкие слова (1,2,3 символа. тут каждый решает для своих данных)


Некоторые пишут, что можно просто загонять в модель текст и тренировать. Мне такой вариант не подошел. Я склоняюсь к тому, что без предобработки получается некачественная модель.

Подготовка текста для классификации

Тут действуют те же самые правила, но как показывает опыт, эти правила можно дополнить лемматизацией или стэммингом. С ними результаты могут быть существенно улучшены (или ухудшены) Кроме того, когда у вас уже есть сформированные кластера, не надо забывать, что к этим кластерам также нужно применять алгоритмы кластеризации, но очень аккуратно, так как можете схлопнуть в один кластер схожую тему. Очень сильно такое проявляется в спорте: модель понимает, что новость из футбола. Но очень сложно заставить отличать модель чемпионат Испании от чемпионата Италии.

Язык программирования
более чем правдаКак было сказано в Гриффинах: «Да всем насрать»


Для тренировки модели можно выбрать как PHP (взял его, так как большая часть сайтов написана на нем) так и Python (для него есть библиотека). Но есть очень забавный момент. Тренировать модель приходится все равно запуском fasttext из командной строки если вам дорого время обучения. А значит, на чем писать код для тренировки, не имеет значения (на чем удобно, на том и пишите).


Что касается механизма кластеризации — то тут немного сложнее (или проще). Если вы любите велосипеды (сами контролировать все процессы и вам нужен гибкий механизм управления) пишите на php (если сайт на php). Если вы не хотите писать библиотеки и есть возможность выбора языка — то, наверное, лучше взять Python. Разницы в скорости я не заметил существенной (в скорости работы кода, а не в скорости его написания). Тут решать вам.

Вместо заключения

У меня есть модель, которая строится исключительно на новостном контенте за последние несколько дней. Размер слов в ней около 40 000. С ней можно поиграться. Но, следует учитывать, что:


 это не универсальная модель. Она тренируется только на новостном контенте
 модель содержит не все новости из базы, а лишь передовицу (для решения поставленной задачи этого хватает). Это значит, что модель может давать низкий процент на похожих новостях.


UPD: материал не актуален. Тестовая ссылка удалена.    Tags: fasttextphppython Hubs: PHPPythonArtificial Intelligence          


