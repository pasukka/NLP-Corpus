

Психология ИИ должна проверять теории сознания в ИИ и информировать дизайн взаимодействия людей и ИИ / Habr


               Психология ИИ должна проверять теории сознания в ИИ и информировать дизайн взаимодействия людей и ИИ  Reading time  
    5 min
   Views  1.6K Artificial Intelligence Brain  
    Opinion
   
    Translation
     
                Original author:
                
                  Roman Leventov
                  Данный пост - продолжение поста пользователя Buck "The case for becoming a black-box investigator of language models". Я хочу выделить еще две причины для изучения поведенческой психологии ИИ, о которых Buck не упомянул:данные по психологии ИИ будут нужны для проверки теорий сознания в ИИ; ипсихология ИИ должна информировать дизайн интерфейсов взаимодействия человека и ИИ, их ограничений, а также правил и принципов поведения людей и ИИ в средах из взаимодействия.Midjourney: "AI psychology should ground the theories of AI consciousness and inform human-AI ethical interaction design"Сознание в ИИНейробиологи, не имеющие психологического образования, могут обсуждать человеческое сознание, потому что они сами обладают сознанием. Все люди (в том числе и исследователи сознания) хотя бы отчасти являются психологами, потому что им приходится иметь дело с собственной психикой и окружающими людьми на протяжении всей их повседневной жизни, а значит, у них должна быть «своя» психологическая теория, объясняющая и помогающая им предсказывать собственное поведение и поведение окружающих людей.Поэтому роль психологии в изучении сознания неочевидна. Однако это методологическая ошибка. Например, зоопсихология (или, в более общем смысле, этология) является важнейшим источником данных для рассуждений о сознании у животных.Аналогично, теории сознания в ИИ должны основываться на большом количестве данных о психологии ИИ. Психология ИИ должна стать новой областью эмпирической науки со своими собственными методами работы. Методы изучения психологии ИИ должны отличаться от методов изучения психологии человека из-за отсутствия "first person" точки зрения, которая есть у каждого психолога-человека, а также из-за того, что фенотип и экологическая ниша ИИ-систем очень сильно отличаются от человеческого фенотипа. Разные фенотипы/экологические ниши предъявляют другие требования к психике агентов. Аналогично, методы изучения психологии ИИ должны отличаться от методов изучения зоопсихологии, потому что мы можем использовать язык как для воздействия на ИИ (промптинг, вопросы, диалог), так и для получения ответов от них, тогда как животные почти никогда (исключение - попугаи) не могут ответить зоопсихологам "на языке", а многие животные не могут понимать и языковые команды.Дизайн взаимодействия людей и ИИSafron, Sheikhbahaee et al. (2022) и Friston et al. (2022) уже указывали на необходимость явного проектирования экосистем для взаимодействия естественных и искусственных интеллектов. Очевидно, что эти взаимодействия должны иметь некоторые ограничения, начиная от "мягких" кодексов поведения и заканчивая жесткими ограничениями в интерфейсах.Чтобы совместная активность в этих экосистемах приносила пользу всем участникам, правила и ограничения взаимодействий должны информироваться теорией игр и теорией дизайна механизмов в сочетании с теориями разума (т. е. психологическими теориями) всех участников: и людей, и различных ИИ.Не слишком ли рано заниматься психологией ИИ? Ведь текущие системы всего лишь "повторяют увиденное в интернете"Поведенческая психология ИИ должна быть эмпирической областью науки. Методологически, надо задаваться не вопросом "Не слишком ли рано ...?", а двигаться в обратном направлении:Собирать данные о поведении ИИ.Выдвигать "психологические" теории, которые компактно описывают (некоторые аспекты) поведения ИИ и одновременно дают более конкретные и более точные предсказания поведения ИИ, чем «ИИ просто предсказывает следующий наиболее вероятный токен в тексте». Следуя этой логике, мы можем сказать, что «ИИ просто действует, как ей предписывает уравнение Гейзенберга и унитарная эволюция вселенной».Перекрестно проверять теории механистической интерпретируемости (mechanistic interpretability; а-ля «нейробиология ИИ») и психологии ИИ друг с другом, точно так же, как нейробиология человека и психология человека теперь используются для информирования и перекрестной проверки друг друга.Основывать теории сознания в ИИ на данных как механистической интерпретируемости, так и психологии ИИ, точно так же, как теории cознания у животных и человека основаны на данных как нейронауки, так и психологии человека и животных.Когда поведение систем становится сложным и не может быть объяснено низкоуровневыми теориями одновременно 1) компактно и 2) с достаточной точностью и предсказательной силой, использование только теорий более низкого уровня становится редукционизмом. Таким образом, попытки объяснить поведение человека только через нейронауку, или только через физиологию являются редукционизмом. Психология человека - это валидная научная область. Хотя в ней очень много плохих теорий, плохих методов исследований, и неподтверждающихся результатов, есть и достаточно очевидно валидные результаты и валидные теории верхнего уровня.Неизвестно, преодолел ли уже ИИ этот уровень сложности. Я уверен, что да. Я думаю, что поведение ChatGPT уже во многих отношениях сложнее, чем поведение большинства животных, в то время как зоопсихология уже является настоящей, нередукционистской областью науки. Так или иначе, первый и второй шаги в списке выше должны быть предприняты в любом случае, как раз чтобы установить, является ли поведение ИИ достаточно сложным. И, по крайней мере, второй шаг уже требует некоторых навыков, опыта, и предрасположенности ученого-психолога, а не случайного ИИ-инженера или технократа из Силиконовой Долины.Кроме того, надо учитывать, что даже если ChatGPT прямо сейчас еще не совсем на этом уровне, будущие версии ИИ, которые будут выпущены в этом году (или, максимум, в следующем), определенно преодолеют эту планку.Самое большое препятствие к изучению поведенческой психологии ИИ: архитектуры меняются очень быстро, и поведение может полностью измениться даже при простом масштабировании одних и тех же архитектур. Но тут надо отметить, что то же самое препятствие было определено и для механистической интерпретируемости ИИ. Но это не означает, что работы по механистической интерпретации существующих ИИ - бесполезны. Аналогично, полезно и проводить психологические исследования существующих ИИ и отслеживать, как психология ИИ меняется с изменением архитектур и масштабированием моделей.Результаты изучения психологии ИИ потом могут использоваться не только исследователями сознания в ИИ, философами-этиками, и дизайнерами сред, но и инженерами самих ИИ, исследователями безопасности ИИ, экономистами, и стратегами.Призыв к действиюРасскажите об этой теме своим знакомым ученым-психологам (или зоопсихологам), возможно, они будут заинтересованы в том, чтобы переключиться и начать какую-то фундаментальную работу в области психологии ИИ. Я знаю, что тема немного не в российском дискурсе сейчас, где людям надо буквально выживать и искать что намазывать на хлеб завтра. Запрос не психологическую помощь в русскоязычном пространстве сейчас тоже очень велик, все психологи очень заняты. Тем не менее, я считаю, что потенциал темы огромен, и поэтому все равно важно, чтобы хоть кто-нибудь ею занимался. Мне кажется, сейчас в мире психологией ИИ как наукой (и методологией этой науки) не занимается абсолютно никто. Эта просто-сфера науки на данный момент совершенна пуста, и почти каждый может оказать огромное влияние на ее развитие.      Tags: ChatGPTпсихология ИИсознаниесознание ИИдизайн механизмовметодология наукиметодологияпсихология  Hubs: Artificial IntelligenceBrain          


