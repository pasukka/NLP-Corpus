

GigaChat против всех — тестируем языковую модель на генеративных задачах / Habr


               GigaChat против всех — тестируем языковую модель на генеративных задачах  Reading time  
    10 min
   Views  2.1K SberDevices corporate blog Machine learning *Artificial Intelligence Natural Language Processing *      В предыдущих постах про рерайтер и суммаризатор мы рассказывали о том, как решали некоторые популярные генеративные задачи с помощью отдельных моделей, и какие возможности дают сервисы на их основе. Однако технологии не стоят на месте. Недавно доступ в GigaChat стал открытым для всех. В этом посте мы решили  исследовать его способности и рассказать вам, как GigaChat справляется с рядом задач в сравнении со «старыми» подходами, ответив на вопросы:— Может ли модель переписать текст, сохранив его смысл?— Насколько хорошо GigaChat суммаризирует тексты?— Умеет ли он стилизовать текст, упрощать, или, например, заменять англицизмы?Спойлер: оказалось, что GigaChat в формате zero-shot часто обходит классические подходы, использующиеся в наших исходных сервисах, генерируя качественные, осмысленные и грамматически корректные тексты. Так что, кажется, есть все основания полагать, что очень скоро мы все перейдём на GigaChat ;)Как использовать GigaChat?В предыдущих сериях наши команды выложили в открытый доступ претрейн-модель, лежащую в основе GigaChat. На её основе можно обучить различные адаптеры на ваших специализированных данных (например, LoRA) или сделать дообучение (файнтюнинг) на инструктивном сете, если у вас есть мощности и большое количество данных. Мы проанализировали возможности такой конфигурации (претрейн + LoRA) на разных генеративных задачах, а также протестировали GigaChat (чекпоинт версии v.1.17.0, то есть обученную на инструкциях SFT-версию модели) в zero-/few-shot сеттинге. Данные подходы мы сравнили с ChatGPT, а также с предложенными ранее «более классическими» решениями этих задач. Но сперва давайте поговорим про тестируемые задачи, сеты и метрики.На каких задачах тестируем?Парафраз текста Одна из самых традиционных seq2seq задач — парафраз или рерайт текста, когда мы хотим переписать текст другими словами, сохранив его смысл. Для этих целей мы уже разрабатывали генеративный прототип рерайтера на основе ruT5-large, который решает задачи рерайтинга на уровне как текста целиком, так и отдельного предложения. Сеты обучения и теста мы взяли для корректного сравнения такие же, как в посте: около 7000 обучающих примеров и золотой тест — данные из различных доменов. В качестве автоматических метрик для обучения используем классические CHRF++, BLEU, Rouge-L, BERTScore, LaBSE.Суммаризация текстаВ посте про суммаризатор год назад мы рассказывали, как решали одну из самых востребованных генеративных задач с помощью разных классических моделей (ruT5, mBART, ruGPT). Тогда по разным метрикам мы выбрали модель ruT5-large и на основе неё сделали сервис с API для разработчиков. Сейчас для экспериментов с адаптером мы использовали два вида данных: 1) инструкции с разными текстовыми затравками (промптами) (