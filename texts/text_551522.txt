

Как машины учатся эмоциональному поведению / Habr


              9  April  2021 at 10:18  Как машины учатся эмоциональному поведению SberDevices corporate blog Machine learning *Popular science Artificial Intelligence       Нередко при взаимодействии с техникой люди проявляют эмоции: мы можем злиться на сломавшийся банкомат или умиляться пронырливости робота-пылесоса. Да, мы общаемся с роботами, но не стоит оценивать это общение как одностороннее: в логику аватаров, которые компании используют для взаимодействия с пользователем, часто бывает встроен навык понимания эмоций, и даже их проявления. Обычно это нужно, чтобы сделать общение приятным для клиента. Как же это всё работает?



Часто сюжеты фильмов и книг о роботах вращаются вокруг темы эмоций. «Добрые» роботы учатся у людей любви и самопожертвованию, а «злые» оказываются повержены из-за неспособности любить, жертвовать собой, предугадывать «иррациональные» поступки людей. Так, робот Вертер из фильма «Гостья из будущего» мучается из-за любви к Полине, а Электроник из одноименных «Приключений» в разные моменты фильма плачет, улыбается и смеётся, и в итоге именно это делает его человеком. 


Смогут ли машины в самом деле испытывать эмоции? Ответить на этот вопрос будет трудно, покуда нам непонятна физиологическая составляющая эмоций. Если смотреть на эмоции широко, даже в поведении примитивных организмов наблюдаются явления, которые можно интерпретировать как эмоции. Например, у некоторых моллюсков в результате обучения формируются условные рефлексы, которые заставляют их избегать определённых стимулов. А что это, как не страх? Но оставим философствования философам, а современным учёным и разработчикам — практические исследования. По данным последних, с уверенностью можно сказать, что машины можно научить распознавать эмоции и их симулировать. 


Давайте разберёмся с тем, как смотрит на эмоции современная наука, и как эволюционировали научные воззрения на эмоциональную сферу человека. 

Что такое эмоциональный интеллект?

Эмоциональный интеллект — это умение распознавать свои и чужие эмоции и управлять ими. Корни этой концепции можно найти в трудах Чарльза Дарвина, который считал, что умение управлять эмоциями появилось в результате эволюции. Следующая попытка научного рассмотрения эмоций приходится на начало 1920-х годов: тогда появились первые работы, в которых способность людей выстраивать социальные взаимодействия рассматривалась как особый вид интеллекта. Тогда же американский психолог и педагог Эдвард Торндайк (Edward Lee Thorndike), который, кстати, изобрёл «кривую обучения», ввёл понятие «социальный интеллект», который определил как «способность понимать людей, мужчин и женщин, мальчиков и девочек, умение обращаться с людьми и разумно действовать в отношениях с ними». Если задуматься, «социальный интеллект» имеет много общего с эмоциональным интеллектом, потому что существование последнего возможно только в обществе. Несмотря на то, что «социальный интеллект» — это многомерное явление, исследователи постарались создать линейную шкалу, чтобы сравнивать людей по его «уровню» (да, люди часто стараются квантифицировать встречающиеся им явления, но в социальной сфере это особенно сложно). В 1926 году был создан один из первых тестов для измерения социального интеллекта — «Тест университета Джорджа Вашингтона на социальный интеллект». В последующее десятилетие предпринимались и другие попытки создания подобных тестов. 


Термин «эмоциональный интеллект» (emotional intellect) впервые появился в работе Майкла Белдока (Michael Beldoch), написанной в 1964 году. Расцвет теории эмоционального интеллекта пришёлся на 1980-е и 1990-е годы. В 1983 году Говард Гарднер (Howard Earl Gardner) описал популярную модель интеллекта, где разделил навыки на внутриличностные и межличностные. С тех пор концепция интеллекта, связанного с социальными взаимодействиями, глубоко укоренилась в научном сообществе. В 1985 году Уэйн Пэйн (Wayne Leon Payne) защитил свою диссертацию, на основе которой написал статью, посвящённую развитию эмоционального интеллекта. В 1988 году психолог Рувен Бар-Он (Reuven Bar-On) ввёл понятие «эмоционального коэффициента» (EQ, emotional quotient), по аналогии с популярным показателем IQ. Современное представление об эмоциональном интеллекте окончательно оформилось в статье «Эмоциональный интеллект» американских социальных психологов Питера Саловея (Peter Salovey) и Джона Майера (John D. Mayer), увидевшей свет в 1990 году.  

Эмоциональные вычисления

Теперь давайте перейдём к «эмоциональным вычислениям». Созданием технологий, ответственных за обработку эмоциональной информации в системах ИИ, занимается направление, получившее название «аффективные» или «эмоциональные вычисления» (affective computing). Иногда также употребляются термины «эмоциональный искусственный интеллект» и «искусственный эмоциональный интеллект», и хотя расстановка слов немного меняет смысл, специалисты ещё не договорились, какое из этих названий предпочтительнее. 


Считается, что направление появилось в 1995 году с выходом в свет работы профессора Розалинды Пикард (Rosalind Wright Picard) из Медиа-лаборатории MIT.


Розалинда Пикард. Источник изображения.


В этом исследовании предложены модели для компьютерного распознавания человеческих эмоций, и обосновано их практическое применение. На заре этого направления доминировали различные классические техники обработки сигнала, такие как спектральные и кепстральные разложения вкупе с регрессионными деревьями, марковскими моделями и т.д… В эпоху революции глубокого обучения в арсенал разработчиков систем для анализа эмоций добавились многослойные нейронные сети. 


Модели, предназначенные для распознавания эмоций, в наши дни обычно представляют собой рекуррентные, свёрточные или свёрточно-рекуррентные нейронные сети. А после 2017-го года к ним добавились ещё и трансформеры. Причём стоит заметить, что характерными маркерами эмоций могут быть не только лингвистические показатели (смысл слов и выражений), но и экстралингвистические, такие как тон голоса, интонации, выражение лица, динамика тела и жестикуляция. Эмоциональная информация «разбросана» по разным каналам: мы можем найти её и в звуке, и в видео. А если рассматривать сенсорную сферу, проявление эмоций можно найти в касаниях, и это тоже может быть важно для роботов. Ещё один канал, в котором эмоции проявляются на уровне активности мозга — энцефалографический. Его можно использовать, например, при проектировании «продвинутого» детектора лжи. Одним из подразделов эмоционального ИИ является сентимент-анализ, цель которого — определить, какая смысловая окраска у высказывания: негативная, нейтральная или позитивная. В наши дни эту задачу решают при помощи трансформерных моделей, подобных BERT. К сожалению, объём поста не позволяет рассказать об этом сейчас, и мы посвятим сентимент-анализу один из следующих материалов. В этом посте из всех каналов, которые задействуются при общении человека с машиной или людей друг с другом, мы рассмотрим только аудиальный канал.


Автор изображения: ioat/Shutterstock.com


Распознавание эмоций в речевом канале — это одна из наиболее распространенных задач в области эмоционального ИИ. Чаще всего для построения модели применяются глубокие сети, которым на вход подаются различные представления звукового сигнала (спектрограммы, хромаграммы, последовательности наборов мел-кепстральных коэффициентов и т.п.). Такие модели решают задачу классификации или регрессии. Чтобы обучить модель, распознающую эмоциональную окраску речи, нужно подготовить обучающую выборку. А для этого нужно условиться, какое представление эмоций мы будем использовать. Возможные классификации предоставляет язык разметки EmotionML 1.0. Он содержит несколько «эмоциональных словарей», основывающихся на научных классификациях. Одна из них — это «большая шестёрка» эмоций (отвращение, печаль, гнев, страх, счастье и удивление) — предложена в 1972 году в работе американского психолога Пола Экмана (Paul Ekman). Другой эмоциональный словарь, предусмотренный EmotionML 1.0, основан на концепции соответствия эмоций тенденциям действия [action tendencies], разработанной голландским психологом Нико Фрейдой (Nico Henri Frijda). Этот словарь включает в себя 12 эмоций: безразличие, высокомерие, гнев, желание, интерес, наслаждение, отвращение, покорность, смирение, страх, удивление и шок. 


Есть много разных словарей, но наивным было бы считать, что их авторы просто соревновались друг с другом в составлении бессистемных списков эмоций. В основе больших эмоциональных словарей обычно лежит анализ лингвистических данных (статистики использования слов, используемых для передачи эмоциональной информации в различных языках). При этом сами словари нередко являются лишь «побочным продуктом» исследований, цель которых — построить «эмоциональное пространство», то есть такое представление, в котором каждая эмоция будет разделена на несколько независимых друг от друга компонент. Одну из попыток построить такое 

пространство предпринял Джеймс Рассел (James A. Russell) в 1980 году. Он разложил эмоции по двум шкалам: первая, «удовольствие-неудовольствие», характеризует позитивный или негативный характер эмоции, и вторая, «возбуждение-сон», характеризует активность или пассивность психического состояния. Эта работа вызвала закономерную критику: мир эмоций не сводим к двумерному пространству. Критики предложили свою модель, уже не двухмерную, а в виде сетки, под названием «GRID» [сетка, решётка]. 

 

Так как у нас есть эмоциональный континуум, вместо задачи классификации, когда у нас есть несколько классов эмоций, мы сталкиваемся с задачей регрессии. В данном случае от модели требуется не предсказание метки конкретного эмоционального класса в соответствии с выбранным эмоциональным словарём, а оценка величины каждой из выбранных компонент эмоции. Для этой цели в стандарте EmotionML 1.0 введены системы измерений эмоций. Кроме упомянутой нами системы GRID (FRSE) с четырьмя шкалами, стандартом предусмотрена возможность использования пространства «Удовольствие-Возбуждение-Доминирование» (Pleasure, Arousal, and Dominance, PAD), основанного на трёх соответствующих шкалах, а также плоской шкалы интенсивности эмоции. 


Кстати, модели эмоций могут быть и мультимодальными, так как  при оценке эмоциональной окраски речи люди неизбежно ориентируются не только на звуковые признаки, но и на текст сказанного. А если вы используете видеозаписи человеческой речи, то к числу признаков добавятся ещё и признаки из видеоканала — выражение лица, а возможно и движения тела говорящего. В таком случае понадобится модель, которая сможет получать на вход мультимодальную информацию. Некоторые компоненты этой информации будут довольно универсальными для разных культур (например, то, каким образом эмоции, испытываемые человеком, влияют на его голос), а некоторые будут весьма специфичны для конкретной культуры (например, тот же язык — не факт, что нейронная сеть, которая обучалась на эмоциях людей-носителей одного языка, будет применима для распознавания эмоций у носителей другого языка). 


Когда мы определились со словарём, приходит очередь разметки данных, которая является проблемной задачей: разметчики не всегда сходятся в оценках эмоциональной окраски той или иной фразы. Например, кто-то может услышать в одной фразе нейтральную окраску, а кто-то — скрытую печаль. Если вы используете при оценке систему, основанную на шкалах, то в датасете значения оценок, полученные от всех оценщиков по каждой шкале, можно подвергнуть усреднению. При использовании словаря придётся либо доверять большинству оценщиков, либо отбрасывать фразы, получившие неоднозначные оценки. 


К счастью, на данный момент сформировано уже некоторое количество эмоциональных датасетов, на 2009-й год их было порядка сотни. Однако таких же объёмных, как ImageNet или LibriSpeech, для эмоциональной речи в публичном доступе так и не появилось. 

Вот некоторые наиболее популярные на сегодняшний день у разработчиков публичные датасеты эмоциональной речи: 

1. RAVDESS состоит из записей 24 профессиональных актёров (12 мужчин и 12 женщин), озвучивающих две фразы («у двери разговаривают дети», «собаки сидят у двери») на английском языке с североамериканским акцентом в двух вариантах: речь и пение, по две озвучки на каждый вариант. В качестве эмоционального словаря разметки использована «большая шестёрка» эмоций, к которой было добавлено «спокойствие». Каждая фраза представлена в датасете двумя уровнями эмоциональной интенсивности для каждой из эмоций, а также однократно с нейтральной окраской. Каждая запись присутствует в датасете в трёх модальностях (только видео, только звук, звук вместе с видео). RAVDESS считается одним из наиболее качественных датасетов эмоциональной речи, но лексически он крайне беден.

2. SAVEE состоит из записей четырёх актёров-мужчин, говорящих на родном для них британском английском. В качестве эмоционального словаря снова выбрана «большая шестёрка», при этом фразы с нейтральной эмоциональной окраской записывались дважды. Сами фразы были выбраны из корпуса TIMIT (датасет с записями 630 дикторов), для каждой эмоции было взято 15 фраз, при этом из них три были общими для всех эмоций, десять — разными для разных эмоций, но без эмоциональной специфики, а ещё две фразы были основаны на текстах, имеющих специфическую эмоциональную окраску для данной эмоции (например, «Кто одобрил счёт с неограниченным расходным лимитом?» для эмоции «гнев»). К сожалению, объём этого датасета крайне мал, что создаёт проблемы для разработчиков. 

3. SEMAINE — это аудиовизуальная база данных, ставшая одним из продуктов исследовательской программы по созданию «Чувствующего искусственного слушателя» (Sensitive Artificial Listener, SAL) — аудиовизуальной диалоговой системы, способной вовлечь человека в длительный эмоционально окрашенный разговор. По сути разговор с агентом SAL для человека напоминает обычный разговор при помощи системы видеосвязи с той лишь разницей, что собеседником является виртуальный персонаж, внешний облик которого (лицо, мимика, движения губ во время речи) в реальном времени генерируется при помощи библиотеки для трёхмерной визуализации. Данные, содержащиеся в базе SEMAINE, были получены в результате взаимодействия между пользователями и человеком-оператором, имитирующим чувствующего искушённого слушателя, а затем и ассистентом на базе нейросетевой модели. База включает записи 959 диалогов, в которых участвовало 150 человек. Длина каждой записи составляет около 5 минут. Все диалоги были расшифрованы и размечены при помощи эмоциональных меток (использовалась система с пятью шкалами и 27 эмоциональными классами). Для части записей присутствует разметка при помощи «Системы кодирования лицевых движений» (FACS). Используя FACS, можно с лёгкостью отличить, например, дежурную «улыбку Pan-Am» (называется в честь авиакомпании Pan-American Airways, стюардессы которой должны были улыбаться каждому пассажиру) от искренней «улыбки Дюшена». Один из недостатков этого датасета в том, что различные эмоции представлены в SEMAINE крайне неравномерно, также никак не был сбалансирован ни состав участников исследования, ни лексическая основа диалогов. Тем не менее, нельзя не отметить удивительную детальность разметки.

4. TESS. В 1966 году исследователи из Северо-Западного университета разработали так называемый «Слуховой тест №6», предназначенный для измерения чувствительности слуха пациентов. Набор фраз, используемых в тесте, состоит из так называемой фразы-носителя — «Скажи слово...» — и набора из 200 различных слов, которые добавляются к фразе-носителю. Исследователи из Университета Торонто использовали этот же набор текстов, при этом каждая из фраз произносилась двумя актрисами (26 и 64 лет; обе были из региона Торонто, являлись носительницами английского языка, имели высшее и высшее музыкальное образования) с семью различными типами эмоциональной окраски (использовалась всё та же «большая шестёрка» эмоций с добавлением нейтральной окраски). Таким образом, в сумме было получено 200 