

Призрак AGI. Записки читателя Хабра / Habr


               Призрак AGI. Записки читателя Хабра  Reading time  
    13 min
   Views  4.3K Machine learning *Artificial Intelligence   
    From sandbox
       Поводом для статьи послужила вот эта публикация К AGI через самоорганизацию и структурную адаптацию / Хабр (habr.com) , в которой автор замахнулся на святое и заявил, что нейросети - это тупик. Я попытаюсь поддакнуть коллеге в том смысле чтобы определить где тупик и почему тупик.По поводу поводаК сожалению, со всем уважением к автору статьи, очень сильный постулат о тупиковости нейросеток автор объясняет тем чтоНейросети, убирая единицы измерения, мешают в кучу коней и людей. Черный ящик, действуя как безжалостная мясорубка, перемалывает объекты на входе в неинтерпретируемый фаршИ плюс несколько картинок про мужиков, пилящих ледяные фигуры. Получилось не очень убедительно, честно говоря... Ну да, нутрянка нейросетей неинтерпретируема. Вот, например, несколько лет назад Google представлял свою концепцию, как бы там внутри все понять Google представила «объяснимый» ИИ (Explainable AI) / Хабр (habr.com). Ну люди посмотрели на разноцветные точечки, попытались что-то там увидеть, и ничего не увидели. Картинка взята из статьи @ZlodeyBaal там ниже ссылка будетНе все опустили руки, вот тут, например, и собственные опыты, и ссылки на ресурсы есть Интерпретируемость машинного обучения: состояние дел / Хабр (habr.com).Но, по правде говоря, никаких победных реляций о прорывах в этом направлении я не читал.Но, с другой стороны, сам по себе постулат о неинтепретуремости не служит доказательством неправильности и тупиковости. Мозг homo sapiens, который, вроде как, эталон AGI, тоже пытаются интерпретировать лет эдак 100, и тоже не очень получается.Заявление о том, что нейросетка игнорирует единицы измерения, мне тоже не кажется справедливым, я даже берусь утверждать как раз обратное. Распознавание образов, в той своей постановке, в которой оно решается нейросетями, это обратная задача к К-кластеризации. В задаче кластеризации у нас есть облако точек в N-мерном пространстве, которые каким-то образом флуктуируют, и мы хотим определить принадлежность каждой точки к кластеру с центром в точке флуктуации. И для этого нам надо придумать, как мы будем мерить расстояние между точками. И мера пространства совсем не обязательно и не всегда декартова. Поскольку координаты вашей точки могут быть не очень измеримыми (битовые признаки, например).В общем задачка определения меры нетривиальная, но, если с ней справились, дальше открываем википедию, читаем про алгоритм и запиливаем.А при распознавании образов решаем обратную задачу. Мера пространства неизвестна. Не то что неизвестна, а вообще даже никаких идей нету как она может выглядеть. Как померить расстояние между фотографиями кошечки и собачки? Тупая картинка, извините. Просто чтобы текст разбавить.Но зато есть обучающая выборка с разметкой – какая точка к какому кластеру относится. Это – кошечка, это – собачка, а это – попугайчик. Пихаем обучающую выборку из стапятьсот фотографий в нейросетку и она, подстраивая веса, как раз меру-то пространства и вычисляет. Правда при таком подходе мы получаем критическую чувствительность системы к обучающей выборке. Пример с волками и хасями помните? (Как избежать «подводных камней» машинного обучения: руководство для академических исследователей / Хабр (habr.com)  )Но в целом, мне кажется, что это тоже не аргумент против. Рефлексия - не выходНейросетки считаются слабым ИИ,то есть заточенным под решение конкретных задач. Главный вопрос в том, можем ли мы, продолжая исследование этой концепции, найти подходы для построения сильного ИИ. И вот мне кажется, что нет. Я понимаю, что это очень наглое заявление, и вряд ли мне удастся расшатать фундамент нейросетевого храма, но подкопаться я попробую.Корень зла, как мне кажется в той первоначальной постановке, которая была 60 лет назад и которую по большому счету никто всерьез не ревизировал. Та, превоначальная, идея была простая: входящий вектор - черный ящик - выходящий вектор. С точки зрения биологии, это сермяжная, простая как валенок рефлексия. Тыкаем в гидру иголкой - гидра поджимает щупальца. На момент формирования концепция смотрелась вполне революционной.Следующим шагом было придумать, как добиться от черного ящика такого поведения. Взяли упрощенную концепцию нейрона, как сумматора входящих весов и сказали, что правильный выход будем получать подстройкой весов. Принципиальная идея - привести систему в стабильное состояние, при котором на все обучающие входы мы получим правильные выходы. Окей, почему бы нет. Для задачи рефлексии вполне себе подход.Вот эти две концептуальные идеи и не дают возможности развиваться в сторону сильного ИИ. Как мы его в общих чертах понимаем? AGI должен уметь накапливать новую информацию, структурировать ее, обобщать и на ее основании искать решение задач. Что у нас получается с существующими архитектурамиРаспознавание образов. Это, как я выше написал, обратная задача кластеризации. А все методы кластеризации имеют фундаментальное ограничение - они работают только для заданного числа кластеров. Вот и в сетях так. Если вы научили сетку распознавать кошечек и собачек, а потом подсунете ей картинку с попугайчиком, то нового класса она вам создать не может - у нее в выходном слое нейрона для этого нет.Текстовые описания в картинки. Тут можно здорово обмануться. Мы, как бы, даем на вход нормальный осмысленный текст, а на выходе получаем картинку коррелирующую с этим текстом. О чудо! Она понимает смысл написанного?! На самом деле в сетку поступают не слова, а эмбеддинги. А это осредненные на собранной статистике связи между словами. Во-первых они будут зависеть от тех текстов, на которых вы собирали статистику. Во-вторых эмбеддинги статичны. Если вы попробуете их менять в зависимости от входящей информации (мы же хотим новую информацию собирать), у вас система вместо стабилизации пойдет вразнос. Ну и в-третьих, эмбеддинги в общем призваны сделать из слов точки в некотором многомерном пространстве. А выходящие картинки - это точки в другом многомерном пространстве. А сетка - это просто преобразователь. Никакой структурированности и обобщения там не нужно и нету ее там.Трансформеры. Надежда и опора. Они - вроде как марковские сети, а марковские сети могут иметь не только конечное, но и счетное число состояний. Это хорошо, есть потенциал для развития. Но мы опять упираемся в первоначальную концепцию: вход - черный ящик - выход. Здесь вход - поток фактов, а выход - предсказание следующего факта. Предсказания - это вообще очень мутная тема, человечество постоянно пытается решать задачки на предсказания, тратит кучу ресурсов и получает обычно нулевой результат. Конечно, если вы строите систему наведения ракеты, то предсказание вам в помощь. Но вот с точки зрения AGI, один вред. Сейчас попробую объяснить.Вот я читаю ребенку книжку про (условного) Винни-Пуха. "Винни-Пух пришел домой и съел горшок мёду". Спрашиваю ребенка, - что ест Винни-Пух?. Отвечает, - мёд. Предсказание? А вот и нет. Читаю следующую главу: "Винни-Пух пришел домой и съел.... кашу". Опять задаю тот же вопрос, - что ест Винни-Пух? Отвечает - мёд и кашу. Это не предсказание, это множественная связь между объектами.А что будет делать трансформер? С первой главой все в порядке, подстроили веса, вход "Винни-Пух ест" - выход "мёд". Добрались до второй главы, вход как бы тот же, а выход другой. Вот тут внимание. Конечно, скорее всего выбор Винни-Пуха зависел от каких-то внешних и внутренних причин: может мёд кончился, может зубы у него заболели, может Пятачок ему лекцию про перистальтику прочитал. Но Милн (условный) нам об этом не написал. Он не обязан давать нам всю исходную информацию. И вселенная тоже не обязана. Поэтому ребенок просто запоминает, что может быть так, а может эдак, никакого когнитивного диссонанса у него не возникает. Но мы же от трансформера требуем всегда только один вектор на выход, мы ж ему не даем права дать множественный ответ. И он начнет откатываться по тексту назад и искать, на основе чего он может сделать развилку. И зацепится за первое попавшееся слово/факт/явление. Если в первой главе Винни-Пух повстречал Кролика, то вот мы и получим предсказание, если встретил Кролика, то ест мёд, а не встретил - кашу. Ну и в дополнение, трансформеры на тех же эмбеддингах работают. И они тоже должны быть статичны.В общем я бы сформулировал так. Первоначальная концепция нейросетей, используемая до сих пор, принципиально не даст им развиваться в сторону AGI, потому чтоОни работают только в состоянии гомеостаза. Научили, работает - не трогай. Новая информация их расстабилизирует.Они построены так, чтобы всегда давать однозначный ответ на внешнее воздействие. Рефлексия как она есть. Множественные выходы не И еще 5 копеекПро обобщение данных нейросетками. Я вот, честно скажу, не видел ни одного доказательства того, что какое-то обобщение происходит. По-моему, это миф, растущий еще из времен первых персептронов, кто-то из яйцеголовых тогда ляпнул, потому что с его точки зрения, ничего другого там внутри этого черного ящика произойти не может. А все до сих пор тиражируют. Если кто знает доказательство – пожалуйста швырните его мне в лицо, со всей пролетарской датасайнтистской ненавистью.А хотите эксперимент?Постройте сетку, распознающую кошечек и собачек. Или хомячков и попугайчиков. Обучите, проверьте на тестовой выборке, что распознавание устойчивое и приличное, ну там 90-95, сколько там у вас сейчас принято. Только выборка чтобы честная была, не как с волками и хасями (Как избежать «подводных камней» машинного обучения: руководство для академических исследователей / Хабр (habr.com))Ну-с, а теперь возьмите фотографии из тестовой выборки и оставьте только головы собачек/кошечек/попугайчиков. Потому что если уж голова собаки и кошки не является самым характерным обобщенным атрибутом класса, то я уж и не знаю, что является.А теперь прогоните тестовую выборку с головами через свою сетку еще разок. И если распознавание останется на уровне хотя бы 80, я напишу отдельную статью с извинениями. Я предполагаю, что вы получите в лучшем случае 60-65.Слава нейросеткамВ общем, не надо ждать от технологии того, что она дать не может. Нейросетки были слабым ИИ, им они и останутся. Больше всего жалко бизнесменов, которые искренне верят, что забашляв датасатанистам они когда-то, скоро, вот прям через месяц-год-два, получат вожделенный AGI и станут царями горы. Ничем, кроме этой светлой детской надежды, я не могу, например, объяснить вот такие эксперименты в коммерческих банках ruDALL-E: генерируем изображения по текстовому описанию, или Самый большой вычислительный проект в России / Хабр (habr.com) Картинки из этой статьи. Сгенерированы по фразе "Олень у озера".Потому что, проработав в финтехе последние 15 лет, я не могу придумать практического применения такой системы в банке (В банке, Карл!). Видимо это инвестиции в светлое будущее… Понятно… Мои соболезнования…Тем не менее, для слабого ИИ полно задачек, и если правильно понимать ограничения технологии, то можно их вполне успешно решать… Ну наверно, успешно… Если понимать... Злые языки утверждают, что до прода долетает порядка 15% проектов. Простите, ссылку не нашел, статья была давно. А если прикинуть, что 10% из этих 15% приходятся на мэтров жанра, то для остальных получается что-то на уровне статистической погрешности. Буду очень благодарен за статистику, доказывающую обратное.Но есть, на мой взгляд у нейронок, одно достижение, которое реально революционное. Наверно последние лет 500, а кое-где и раньше, проблема решалась через применение математического аппарата. Есть теория, есть проблема, которая каким-то своим боком похожа на эту теорию, отлично! Берем соответствующий матаппарат, проецируем проблему на него – решаем. Мы должны обладать глубокими знаниями и алгоритмами внутри этой теории, чтобы решить проблему. Понимаете, да? Чтобы Вы смогли оптимизировать перемещение товаров между складами вашей Пятерочки, Магнита или где Вы там работаете, кто-то до этого должен был пыхтеть десять лет и разработать теорию графов. А Вы еще должны были знать, что эта теория графов существует, прочитать ее и понять какие алгоритмы для решения Вам нужны.А как это выглядит с нейросетками. Строим архитектуру, учим, даем задачу – решает! Никакой теории не имеем, можем даже не догадываться. Решение делается не математическими, а инженерными методами. Если вдуматься, это просто мозговзрывательная концепция. Понимаете, теоретически можно запилить механическую систему, железяку, которая будет реализовывать нейросетевую архитектуру и решать задачки. Трудоемко наверно получится, но я не удивлюсь, если какой-нибудь энтузиаст напильником персептрончик запилит, просто по фану. Люди на что только не тратят время. Никаких знаний мы в систему при этом не вкладываем, решение делается за счет архитектуры. Ну и обучения конечно.Нейросетка??Так что слава нейросеткам! Они доказали, что решение сложных задач возможно за счет архитектуры решения, без вложения внутрь системы каких-то предначально заданных знаний о внешнем мире. Это правда очень сильно. И внушает надежду.О роли вопроса в поисках ответаДавным-давно, в далекой галактике у сообщества был вопрос, а можно ли вообще создать алгоритм, устойчиво распознающий изображения. Подробностей истории я не знаю, но тут не трудно догадаться, что разные коллективы время от времени публиковали громкие статьи, о том, что вот они-то наконец познали дзен. А противные оппоненты, проверяя опубликованные решения на своих выборках, получали дрянные результаты и все это приводило к срачу в научных масс-медиа. И тогда сделали ImageNet, как эталон замера успешности решения. На тот момент вопрос был простой – может или не может? Поэтому и критерий сделали простой. Если на картинке человек играет с собакой, а сзади дерево, то человек размечающий картинку ставит 3 метки: человек, собака, дерево. Система смогла распознать хотя бы один из объектов – зачет! И вот на такой постановке долго тестили разные подходы, долго получали результаты не очень, долго мытарились, пока в 12 году не пульнули сверточные нейросетки. Поначалу все бросились улучшать результаты, 90%, 95%, 98%, 99.8%. Ребята, остановитесь! Все, ответ уже получили – может. Дальше что?Есть у систем, показывающих результаты на ImageNet практический смысл? Распознать что-нибудь на быстромелькающих картинках? Ну… эта… может в викторинах… Понимаете, да? Где следующий вопрос, на который надо отвечать? Конкурсная задачка, победителю – пряник, сообществу – направление движения.Картинки по текстовым описаниям? Это не вопрос, это игрища. Значение их мне не очень понятно. Нет, я понимаю их с точки зрения оправдания за гранты. Гранты дают бизнесмены, они фишку не рубят, а червяки с рогами производят на них сильное впечатление. Но на какой вопрос пытаются ответить такие системы? Или у них очень мощное коммерческое применение? Заменить всех иллюстраторов на сайтах алгоритмами? А чем так провинились иллюстраторы, что ML-сообщество так остервенело им роет могилу? Я может чего не знаю…Чат-боты? Генерация нейросетями статей о нейросетях? Похоже на попугаев. Ну или на мега-попугаев с огромным словарным запасом. Вопроса тут я тоже не наблюдаю. Я, по правде сказать, и практического смысла не наблюдаю. Видимо скоро нас ожидают гига-попугаи, дейно-попугаи и под конец тирано-попугаи… Тирано-попугай. Словарный запас как у Вильяма нашего.АльтернативаДля тех, кто на Хабре меньше 7 лет – в 2014 Логика мышления. Часть 1. Нейрон / Хабр (habr.com) и 2016 Логика сознания. Часть 1. Волны в клеточном автомате / Хабр (habr.com) годах @AlexeyR опубликовал два цикла статей, о своей концепции того, что в мозгу происходит и зачем это нужно. И это был самый основательный заход в альтернативную реальность.Там очень много текста, и, читая, надо понимать, что автор описывает два направления. Первое – что там в мозгу происходит. Этому уделено много места в статьях, это биохимия мозга, за это на автора были наезды из серии, насколько все это верифицировано профессионалами. И, честно сказать, меня, как ИТшника, это все не очень интересует. Мозг состоит из живых клеток, и понятно, что архитектура решений у него не такая, как у компьютера. А вот второе направление – зачем это мозг делает, и вот тут было несколько весьма сильных заявлений, заставляющих по-новому взглянуть на проблему. Во-первых, было сказано, что информация о явлении/факте, отражается в мозге не как активация нейрона, а как активация группы нейронов, узора на коре. Автор даже несколько раз (если я правильно помню) возвращался к той идее, что единицей хранения информации не является нейрон (нейрон бабушки, у него там это так называлось).Во-вторых, было сказано, что этот узор может перемещаться по всей коре как волна.В-третьих, уделено внимание понятию забывания. Информация хранится недолго, и если не повторяется, то забывается. А вот если повторяется – то закрепляетсяВ-четвертых, множественные центры обработки информации. Автор пишет о кортикальных колонках. В общем, идея в том, что мозг это не одна думалка, а очень много думалок с одинаковой архитектурой хранения и обработки. И они все обмениваются идентификаторами-фактами.В-пятых, для понимания смысла факта/явления важно понятие контекста. Не знаю, насколько бы автор статей согласился со мной, может проклянет еще, но я бы сделал такие выводы:Активация случайной группы нейронов в ограниченной области коры, по факту выглядит как бинарный вектор. То есть, если по-простому, то это уникальный идентификатор. Поскольку кора двумерная и узор двумерный, то все не так просто, конечно, но для отправной точки пойдет. Тогда получается, что любой факт регистрируемый, обрабатываемый, генерируемый мозгом – это идентификатор, IDшник, число. Это сильно. Потому что уж что-что, а генерировать IDшники компьютеры умеют. И это снимает любые ограничения на накопление новой информации внутри системы. И это совершенно не то, что делают нейросетки.Вопросов, правда, очень много. Как мозг гарантирует уникальность идентификаторов? А если не гарантирует – то как выкручивается? Как далеко распространяются волны по коре? По всей коре? А не приводит ли это тогда к дублированию информации? А если приводит, то зачем? Далее, эти IDшники обрабатываются внутри локальных когнитивных полей (не уверен, что они равны кортикальным колонкам). На выход когнитивные поля выдают новые идентификаторы, как результат комбинации входящих сигналов. Можно предположить, что внутри когнитивного поля регистрируются достоверные (часто повторяющиеся?) комбинации входящих фактов, а забывание фильтрует шумы. И тут вопросов выше крыши: с какими входящими фактами одно поле работает? Со всеми подряд? А емкости хватит? А если с подмножеством- то как делить? Триггерные факты? В этой архитектуре (точнее не архитектуре, а концепции архитектуры) есть еще одна интересная фишка. Если мозг занимается агрегацией простых фактов в сложные, то он может это делать двумя путями: без учителя – на основании частотного анализа (а может и не только частотного), и с учителем – за счет явного указания, что вот эта комбинация является важной. То есть результатом всегда будет метка достоверности на комбинации, только эта метка достоверности может быть получена через оба подхода. Мне эта идея очень нравится своей универсальностью. И да, это уже отсебятина.По поводу контекста, я, пожалуй, распространяться не буду, у Алексея там все подробно, я не совсем согласен, но у меня цель статьи другая.И еще один бонус. Многие статьи, которые делали заход на альтернативные технологии для AGI, хромают на одну и ту же ногу. В них авторы предполагают первоначально внедренные в систему знания о входящих данных. И про части речи там было, и про пространственные координаты и т.п. Если мы собираемся строить AGI, то никакой эзотерики быть не должно, чистая архитектура. Вот в этом подходе так и есть. Первоначальные IDшники приезжают от рецепторных полей, а дальше все на агрегациях. И да, это тоже отсебятина.Дела это, как видите, довольно давние, но вот что любопытно. В том же 16 году появилась вот такая статья Совсем не нейронные сети / Хабр (habr.com), а к статьям этого автора @Vasyutka (как и его соратника @ZlodeiBaal) я отношусь с большим вниманием, поскольку оба точно являются профессионалами в этой области. В общем пальнувший калибр был крупным. В статье было описано практическое применение идей Алексея. И результаты в статье были весьма интригующими. А вот дальше – тишина. То ли идея не взлетела. То ли наоборот ого-го как взлетела, и теперь авторы втихаря пилят коммерческую систему, которая поработит галактику. Но по правде сказать, то, что (гораздо позднее) появилась вот такая статья Тихая революция и новый дикий запад в ComputerVision / Хабр (habr.com) принадлежащая перу @ZlodeiBaal (еще один крупный калибр и близкий соратник предыдущего), и статья эта возвращает нас в лоно нейросетевых архитектур, наводит на мысль, что альтернатива заглохла.И вот тут, как бы сказать… Я прекрасно понимаю, что никому не охота писать о провалившихся проектах. Но вот для сообщества, честно говоря, информация была бы очень полезная. Типа, мы туда сходили, там болото, все плохо, вот такие нерешаемые проблемы, в общем тупик, нечего там делать. Это было бы очень круто.ИтогоНейросетки - молодцы, если понимать, что они могут, а что нет. Развитие идет во многих направлениях, хотя, наверно, не все направления являются полезными в народном хозяйстве.Для AGI они не годятся принципиально, по своей архитектуре. В первую очередь из-за того что они работают только в стабильном состоянии,новая информация им противопоказана.Хорошо бы сформулировать вопрос, на который должна ответить новая архитектура. И чтобы этот вопрос позволял формировать измеримый ответ. Тогда глядишь и дело сдвинется с мертвой точки.Ну и было бы здорово услышать рассказы о том, как альтернативу строили-строили, но почему-то не достроили. Это было бы очень поучительно. Потому что, как говаривал однорукий, одноногий и одноглазый викинг из мультика - "Практика - наш главный учитель".      Tags: agiсильный иинейросети  Hubs: Machine learningArtificial Intelligence          


