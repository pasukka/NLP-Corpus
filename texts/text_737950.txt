

Сравнение нейросетей для перевода / Habr


               Сравнение нейросетей для перевода Level of difficulty  
    Medium
   Reading time  
    13 min
   Views  27K Python *Machine learning *Artificial Intelligence Learning languages Natural Language Processing * 
    Review
        За звание лучшего переводчика сегодня поборютсяGoogle Translate - в представлении не нуждается. Я воспользуюсь официальным API, которое стоит $20 за миллион символов.DeepL - конкурент Google Translate. У него тоже есть API, цена использования которого примерно такая же.GPT-3.5. Я буду использовать OpenAI Chat API. Подробнее о работе с ним вы можете почитать в моих предыдущих статьях.GPT-4. У меня есть доступ к GPT-4 API (сейчас его предоставляют по вейтлисту). Вызов GPT-4 не отличается от вызова GPT-3.5; модель умнее, но гораздо дороже.MarianMT - семейство моделей для различных языковых пар, которые зафантюнили специалисты из Helsinki-NLP. Модели можно скачать с Hugging Face и бесплатно запускать на своих ресурсах (однако, придется немного заморочиться с запуском). В зависимости от языковой пары, доступна либо большая модель (~ 500 MB), либо стандартная (~ 300 MB). Есть модели, которые работают с несколькими языками сразу. Я буду использовать большие модели, где это возможно.Код для перевода через GPT-3.5/GPT-4 APIimport openai
import os
def translate(sentence, source_lang, target_lang, model = "gpt_3.5-turbo"):#source_lang, target_lang are names of the languages, like "French"
    openai.api_key = os.environ.get("OPENAI_API_KEY") #or supply your API key in a different way
    completion = openai.ChatCompletion.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": f"Please translate the user message from {source_lang} to {target_lang}. Make the translation sound as natural as possible."
            },
            {
                "role": "user",
                "content": sentence
            }
        ],
        temperature=0
    )
    return completion["choices"][0]["message"]["content"]Поэкспериментировать с промтом и параметрами API можно в плейграунде (не забудьте выставить температуру в 0).Я выбрал 12 популярных языков: испанский, китайский (мандарин), русский, французский, немецкий, японский, португальский, корейский, голландский, хинди, индонезийский и арабский. Для каждого из них я буду тестировать перевод на английский и с английского каждым из кандидатов.Есть пара исключений:DeepL поддерживает только 29 языков, среди которых нет хинди и арабскогоMarianMT модель для перевода с английского на корейский сломана, она генерирует бред даже в демо на Hugging FaceВ качестве метрики качества перевода я буду использовать золотой стандарт - метрику BLEU-4.Сбор данныхЯ собрал собственный набор данных на основе датасета Tatoeba: для каждой языковой пары я взял по 50 или 100 самых длинных параллельных предложений, которые были добавлены позже сентября 2021.Брать необходимо только новые предложения, чтобы бороться с data contamination - известно, что обучающая выборка для GPT-3.5/GPT-4 заканчивается сентябрем 2021.MarianMT модели обучались на датасете OPUS, сами разработчики тестируют их на Tatoeba, так что здесь никаких проблем нет.Я специально взял самые длинные предложения, чтобы усложнить задачу. На коротких предложениях очень часто возникает ситуация, когда все переводы годные, и побеждает тот, который случайно оказался ближе всего к переводу человека.Сравнение качества переводаЯ оптимизировал промт для GPT-3.5/GPT-4 способом, который я описал в предыдущей статье.Получилось, что лучше всего в системное сообщение написатьPlease translate the user message from {src} to {tgt}. Make the translation sound as natural as possible.Второе предложение очень важно - без него сильно ухудшается BLEU.Я также пробовал использовать few-shot примеры. Оказалось, что на этой задаче добавление примеров чаще всего ухудшает метрики. Да, можно перебирать наборы примеров и найти те, которые улучшают, и выбрать среди них оптимальный. Однако, это больше похоже на переобучение модели на стиль Tatoeba-предложений. Поэтому я решил не использовать примеры, промт состоит только из системного сообщения и сообщения для перевода. Такое решение, вдобавок, потребляет гораздо меньше токенов и поэтому дешевле.В итоге у меня получились следующие результаты: https://github.com/einhornus/prompt_gpt/tree/main/data/translation/reports. Каждый файл в этой папке содержит .json-отчет по конкретной языковой паре для одной из моделей. В каждом отчете предложения отсортированы по убыванию BLEU - легко анализировать самые худшие переводы.Я визуализировал распределение BLEU для каждой языковой пары в виде ящиков с усами. Жирная линия посередине ящика означает медиану, границы ящика показывают 25-й и 75-й перцентили. Треугольный вырез в центре называется "notch" и показывает доверительный интервал для медианы.Ссылки под графиками ведут на соответствующие .json-отчеты.DeepLGoogle TranslateGPT-3.5GPT-4MarianMTПеревод с испанского на английский - не очень сложная задача, и все модели справляются очень хорошо. Похожая ситуация наблюдается и с другими романскими языками.DeepLGoogle TranslateGPT-3.5GPT-4MarianMTDeepLGoogle TranslateGPT-3.5GPT-4MarianMTВ самых худших переводах у MarianMT происходит полная потеря смысла, чего не скажешь про остальные модели. DeepLGoogle TranslateGPT-3.5GPT-4MarianMTDeepLGoogle TranslateGPT-3.5GPT-4MarianMTНа русском GPT-3.5 и GPT-4 демонстрируют наихудшие результаты по BLEU относительно других моделей. Вероятно, это объясняется проблемами с токенизацией кириллицы.На этот раз даже в самых худших переводах MarianMT корректно передает смысл. DeepLGoogle TranslateGPT-3.5GPT-4MarianMTMarianMT иногда генерирует нереально кривые предложения на русском:Вот скриншот их страницы магазина за неделю назад, и вот как это выглядит сегодня. У них точно такие же цены, но текущий утверждает, что они все на 50%. Странно, не так ли? (Here's a screenshot of their store page from a week ago, and here's what it looks like today. They have the exact same prices listed, but the current one claims they're all 50% off. Strange, isn't it?)О, парень! Это конечно прекрасное утро здесь! На самом деле, я не могу дождаться, чтобыхух? Что случилось? "Как дела, Линк?" "Моршу, что происходит?" "Ха, просто. Со всеми деньгами, которые я сделал на моем успешном бизнесе и моей успешной карьере битбокса, я разбогател!" "Вау, так что вы устроили нам вечеринку?" "Ха, нет. Безопасность, возьми этих ублюдков." (Oh boy! It sure is a beautiful morning around here! In fact, I can't wait to–huh? What happened? "What's up, Link?" "Morshu, what is going on?" "Hah, simple. With all the money I made from my successful businesses and my successful beatboxing career, I got rich!" "Wow, so you threw us a party?" "Hah, nope. Security, get those motherfuckers out.")Мне очень нравится эта доска, но одна из самых разочаровывающих вещей здесь - это количество плакатов, у которых есть серьезное непонимание любой формы юмора и которые, следовательно, относятся к вещам слишком серьезно. Это настоящее раздражение, но с ним нужно жить. (I like this board a lot, but one of the most frustrating things about it is the amount of posters here who have a serious lack of understanding of any form of humour and who consequently take things too seriously. It is a real annoyance but one has to live with it.)Вот те же самые предложения от GPT-3.5 (смысл передан верно, грамматических ошибок формально нет, но первые два предложения выглядят неестественно)Вот скриншот их страницы магазина на прошлой неделе, а вот как она выглядит сегодня. Они указали точно такие же цены, но на текущей странице написано, что все товары со скидкой 50%. Странно, не так ли?Ого, какое прекрасное утро здесь! На самом деле, я не могу дождаться - что случилось? "Что случилось, Линк?" "Моршу, что происходит?" "Хах, просто. Со всеми деньгами, которые я заработал благодаря своим успешным бизнесам и успешной карьере битбоксера, я разбогател!" "Вау, так ты устроил нам вечеринку?" "Хах, нет. Охрана, выкиньте этих ублюдков."Мне очень нравится этот форум, но одна из самых раздражающих вещей здесь - это количество пользователей, которые не понимают юмора и слишком серьезно относятся к вещам. Это действительно раздражает, но приходится с этим жить.В целом, от переводов GPT-3.5 иногда попахивает машинностью, но прямо совсем треша я в них не вижу; когда как результаты MarianMT местами совсем неприемлемы для использования в проде. Это немного странно, учитывая что медианный BLEU у них близок. Вот те же предложения в переводе Google Translate:Вот скриншот их страницы в магазине, сделанный неделю назад, и вот как она выглядит сегодня. У них указаны одинаковые цены, но текущая утверждает, что все они со скидкой 50%. Странно, не так ли?О, парень! Здесь, конечно, прекрасное утро! На самом деле, я не могу дождаться… а? Что случилось? — Что случилось, Линк? — Моршу, что происходит? «Ха, просто. Со всеми деньгами, которые я заработал на своем успешном бизнесе и успешной карьере битбоксера, я разбогател!» — Вау, так ты устроил нам вечеринку? «Ха, нет. Охрана, вытащите этих ублюдков».Мне очень нравится эта доска, но одна из самых неприятных вещей на ней — это количество постеров, которые серьезно не понимают ни одной формы юмора и, следовательно, слишком серьезно относятся к вещам. Это действительно неприятно, но с этим нужно жить.К первому переводу никаких вопросов, но во втором и третьем есть явные ошибки (Oh boy! 