

Китай вводит регулирование ИИ и генерируемого контента. Как это реализовано и какие страны последуют за КНР / Habr


               Китай вводит регулирование ИИ и генерируемого контента. Как это реализовано и какие страны последуют за КНР  Reading time  
    4 min
   Views  5K Selectel corporate blog Research and forecasts in IT *Legislation in IT Artificial Intelligence       
Я ничего еще не сделал, человек!


О том, что в различных странах планируют ввести регуляторную политику относительно ИИ, пишут уже давно. Так, например, в апреле 2023 года на Хабре публиковалась новость о том, что это собираются сделать в ЕС, США и Китае. Но если в Европе и Штатах «воз и ныне там», то Китай оказался впереди планеты всей. Что именно предпринимают в КНР в отношении искусственного интеллекта — под катом. 

Что это за регуляторная политика? 

Китайские власти вместе с бизнесом разработали 24 новых правила регулирования ИИ. Цель — не препятствовать развитию технологий искусственного интеллекта, поскольку для страны эта отрасль крайне важна. Декларируемая цель нововведений — найти баланс между поддержкой отрасли и возможными последствиями развития ИИ-технологий и соответствующей продукции. 


Если разбить основную цель на задачи, то это «содействие здоровому развитию генеративного ИИ и его стандартных приложений, защите национальной безопасности, общественных интересов, защите прав граждан и юридических лиц». 


Правила введены 15 августа. В соответствии с ними теперь нужно обязательно регистрировать услуг и алгоритмы на базе искусственного интеллекта. Кроме того, сгенерированный алгоритмами контент, включая фото и видео, нужно помечать, причем так, чтобы эта пометка была хорошо заметна. 




Также создатели контента и алгоритмов должны будут проводить проверку безопасности своей продукции до ее вывода на рынок. Каким образом это будут реализовать — пока неясно. Также законодатели посчитали, что для обучения нейросетей нужно использовать законные данные, которые по требованию регулятора понадобится раскрывать. Возможно, контролирующие органы и не будут требовать у всех и каждого подобных действий, но такое требование есть. 


Плюс ко всему, компании, связанные с ИИ-технологиями и генерированным контентом должны иметь прозрачный и действенный механизм рассмотрения жалоб пользователей на услуги и контент. 


Стоит отметить, что регулятор будет не один, а сразу семь. Обязанности по контролю за выполнением новых правил возложены на семь организаций, включая Cyberspace Administration of China (CAC), министерство образования, министерство науки и технологий, национальную комиссию по развитию и реформам National Development and Reform Commission.

Кто разрабатывал правила? 

Как и говорилось выше, представители правительства совместно с бизнесом — крупными участниками отрасли. Правила не ввели сразу, сначала чиновники проводили консультации с различными компаниями. Консультировались как в отношении содержания правил, так и формы. И для бизнеса, и для правительства было важно, чтобы регулирование не подавляло развитие, поскольку в этом случае Китай мог бы быстро отстать от других стран. 


Кстати, изначально планировалось штрафовать злостных нарушителей — вплоть до $14000. Но в финальной редакции правил эти штрафы убрали. Возможно именно потому, что они могли бы здорово навредить отрасли — далеко не все компании из Китая, которые работают над ИИ, это Baidu с Alibaba. Многие относительно небольшие стартапы активно участвуют в работе отрасли и делают большой вклад в общее развитие. А крупные штрафы вполне могли бы привести к банкротству таких бизнесов. Что, конечно, невыгодно государству. 




Более того, оно собирается поощрять инновационные способы применения генеративного ИИ в различных отраслях, а также поддерживать промышленные организации, предприятия, образовательные и исследовательские институты, другие учреждения.

А что в других странах? 

В целом, то, о чем уже известно, позволяет судить о некоторой схожести планируемых нововведений относительно ИИ в Европе и США с Китаем. Так, в других странах также планируют добиться от компаний раскрытия информации о том, кто занимается разработкой и обучением алгоритмов. По словам законодателей, плюсом такого правила является повышение прозрачности работы над технологиями. С другой стороны, подобные нюансы работы могут компаниям и вредить — ведь данные друг друга будут изучать конкуренты. 




В ЕС около 50 представителей ИИ-отрасли, это бизнесмены, сотрудники научно-исследовательских организаций, подписали меморандум, призывающий чиновников ЕС расширить свой Закон об AI. Среди предлагаемых мер есть и идентификация разработчиков. По словам противников такой меры, раскрытие личностей отдельных участников ИИ-индустрии приведет к негативным последствиям. 


Не обязательно для самих разработчиков — их, скорее всего, просто начнут переманивать конкуренты тех компаний, в которых они работают А вот компании будут терять ценных специалистов, что окажет негативное влияние на проводимые работ и исследования. 


Также в ЕС приняли проект закона, это произошло в июне 2023 года, согласно которому необходимо ограничить использование ПО для распознавания лиц, обязательно проводить анализ рисков при разработке разных технологий и обеспечивать контроль конфиденциальности. 


В США разработали пока лишь возможную базу федеральной политики в области искусственного интеллекта. И здесь также предусмотрена идентификация специалистов, обучающих алгоритмы. Если предложения составителей предварительных законопроектов примут, то независимые эксперты получат разрешение проверять и тестировать новые технологии различных компаний перед продакшеном. 


Ни в США, ни в ЕС пока нет закона, который обязывал помечать определенным образом сгенерированный нейросетями контент. Возможно, этот закон примут в ближайшем будущем.


В России также рассматривают возможность помечать контент, созданный при помощи ИИ. Кроме того, в августе 2020 года была утверждена концепция развития регулирования отношений в сфере технологий искусственного интеллекта (ИИ) и робототехники на период до 2024 г. Авторы концепции затрагивают отдельные нюансы работы с ИИ, обращают внимание на важность информационной безопасности и оценку рисков и перспектив использования подобных технологий в разных отраслях науки и техники. 

Возможно, эти тексты тоже вас заинтересуют:

