

Греф заявил о риске создания закрытого клуба крупнейших держав в области ИИ / Habr


               Греф заявил о риске создания закрытого клуба крупнейших держав в области ИИ  Reading time  
    4 min
   Views  20K Machine learning *Cloud services *Artificial Intelligence IT-companies       
Нейросеть «Сбера» Kandinsky 2 так видит запрос «Герман Греф дружит с роботом».

12 апреля 2023 года глава «Сбера» Герман Греф заявил о риске создания закрытого клуба крупнейших мировых держав в области искусственного интеллекта по аналогии с ядерным клубом. 

«Есть опасность создания, наряду с ядерным закрытым клубом мировых держав, создания закрытого клуба мировых держав в области ИИ. А это создание такого рода сложных систем, как нейросети. Я думаю, что нам нужно прикладывать все свои усилия, чтобы быть членами этого клуба, быть донорами, а не реципиентами этих технологий», — пояснил Греф.

Глава «Сбера» подчеркнул, что профильным разработчикам и заинтересованным компаниям необходимо продолжать активно заниматься развитием технологии искусственного интеллекта, которая в перспективе нескольких лет может внести ощутимый положительный вклад в прирост российской экономики.

«При развитии искусственного интеллекта нужно уделять особое внимание безопасности. Тема кибербезопасности должна опережать тему развития искусственного интеллекта», — считает Греф. 

В ходе своей речи глава «Сбера» заявил, что не верит в то, что искусственный интеллект уничтожит человека, но, по его словам, «нанести какой-то вред ИИ, вероятно, может».


С начала апреля проект ChaosGPT (на базе ИИ-решения с открытым исходным кодом Auto-GPT с поддержкой GPT-4 и API OpenAI) получил доступ в интернет (возможность поиска в Google и личный аккаунт в Twitter для прямого общения с людьми) и задачу понять, как можно «уничтожить человечество», «установить глобальное господство» и «достичь бессмертия». ChaosGPT уже начал создавать планы для достижения поставленных его создателем целей. ИИ разбивает их на более мелкие задачи и использует интернет и доступные ИИ-сервисы для поиска нужной информации.

Ограничения в развитии чат-ботов с ИИ

 14 марта OpenAI представила новую модель ИИ интерпретации изображений и текста GPT-4, которую компания назвала «последней вехой в своих усилиях по расширению масштабов глубокого обучения». GPT-4 создала за несколько десятков секунд по короткому ТЗ рабочую версию Pong, Asteroids, Breakout и Pac-Man, а также написала простую игру на JavaScript, в которой можно «играть лесными эльфами, охраной дворца и злодеями» и «грабить корованы» и даже помогла «превратить» $100 в $25 тыс.
 В конце марта некоммерческая организация Future of Life опубликовала письмо, в котором глава SpaceX Илон Маск, соучредитель Apple Стив Возняк, филантроп Эндрю Янг и ещё около тысячи исследователей искусственного интеллекта призвали «немедленно приостановить» обучение систем ИИ «более мощных, чем GPT-4».
 Организация проблем этики в IT Center for Artificial Intelligence and Digital Policy направила жалобу против OpenAI в Федеральную торговую комиссию США. Она потребовала запретить компании развёртывать новые модели GPT, а также попросила регулятора начать расследование в отношении OpenAI из-за выпуска GPT-4, чтобы выяснить, не нарушает ли он законы США и других стран.
 В начале апреля группа специалистов по этике AI выступила с ответом на письмо Future of Life. Они скептически отнеслись к призыву взять шестимесячную «паузу» в развитии AI и обучении систем, «более мощных, чем GPT-4», раскритиковали текст письма за акцент на гипотетических будущих угрозах, связанных с развитием искусственного интеллекта. По их мнению, реальный вред может принести использование AI-технологий уже сегодня.
 Билл Гейтс считает, что призыв приостановить работу над нейросетями мощнее GPT-4 на полгода не решит проблемы. По его мнению, вместо ввода моратория необходимо определить проблемные области и заняться ими.


Ограничения в работе с OpenAI и ChatGPT в разных странах

 25 марта OpenAI признала, что сбой с публикацией историй запросов пользователей чат-бота ChatGPT произошёл из-за некорректного использования и ошибки в клиенте Redis открытой библиотеки redis-py. Разработчики выяснили, что из-за бага также произошло непреднамеренное отображение третьим лицам платёжной информации и персональных данных 1,2% подписчиков сервиса ChatGPT Plus.
 31 марта разработчики из OpenAI временно отключили доступ к сервису ChatGPT для пользователей в Италии. Компания сделала блокировку по геолокации по требованию итальянского агентства по защите персональных данных. Регулятор выявил в работе ChatGPT нарушения при сборе данных пользователей и заявил, что у OpenAI нет правовой основы, оправдывающей массовый сбор и хранение персональных данных. Ограничение по геоблокировке в Италии затрагивает веб-версию ChatGPT, но не влияет на доступ к чат-боту поисковой системы Microsoft Bing, который также основан на GPT-4 от OpenAI.
 В начале апреля регулятор по защите персональных данных Германии сообщил, что ведомство не исключает блокировки ChatGPT в стране по аналогии с прецедентом в Италии из-за нарушений OpenAI законодательства ЕС в сфере обработки и защиты персональных данных GDPR (General Data Protection Regulation). Комиссар Германии по защите данных Ульрих Кельбер заявил СМИ, что ведомство изучает ситуацию с ChatGPT по соображениям безопасности данных граждан страны.
 5 апреля регулятор Канады начал расследование нарушений в деятельности американской компании OpenAI в рамках обработки данных пользователей ChatGPT. Комиссариат по защите частной жизни Канады сообщил, что ведомство оперативно запустило расследование против OpenAI после получения от граждан жалоб о сборе, использовании и раскрытии личной информации сервисом ChatGPT без согласия пользователей. 
      Tags: chatgptчат-ботперсональные данныеутечкаИИ  Hubs: Machine learningCloud servicesArtificial IntelligenceIT-companies          


