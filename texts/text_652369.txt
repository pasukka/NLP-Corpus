

gamio. Русскоязычное текстовое приключение с GPT2 / Habr


              18  February   at 16:50  gamio. Русскоязычное текстовое приключение с GPT2 Python *Programming *Machine learning *Artificial Intelligence Natural Language Processing *      Моя попытка создать аналог aidungeon, novelai, holo AI для русского языка. Хоть я и пытался сделать всё с абсолютного нуля, получилось не плохо.В данном посте я затрону технические проблемы и расскажу про самые ранние попытки создать gamio.ruПервые попытки осуществить цельВсё началось в середине 2021 года. Тогда я познакомился с AI21 Labs (это своеобразный аналог, тогда закрытого GPT-3. Они предоставляли бесплатный, ограниченный доступ к своей языковой модели J1)Я запросил у них кастомную модель J1, имеющая 7 миллиардов параметров. Не буду вдаваться в подробности обучения, но в конечном итоге я получил 2 версии нейросети. Полученные модели работали исключительно на английском языке, поэтому криво-косо, но я вставил api переводчика и запустил сайт. (Правда, проект я закрыл. Доступ был бесплатным, а за услуги Ai21 Labs нужно было кому-то платить.)Что получилосьРасстроившись, на этом я не стал останавливаться. Забросив Ai21 labs с их J1, я стал искать дешёвые способы для создания своей, кастомной модели.Обучение ruGPT3Вновь загоревшись идеей, я решил обучить аж 3 модели ruGPT3 сразу! К тому моменту у меня уже появился сервер, поэтому размещать модели я мог на нём.Собрав и переведя множество данных с chooseyourstory.com, я начал обучение ruGPT3-Large/Medium/Small на этих данных. Обучение в общей сложности заняло чуть больше недели. Я был недоволен результатом.Так и не вышла в свет версия gamio.ru с обученными моделями GPT. Они одиноко пылятся на hugging face...Простое решениеМои мучения были не долгие, взяв оригинальную модель GPT2-XL с репозитория AiDungeon2 и подключив ко всему этому переводчик "opus-mt" я получил ядерную смесь. (Переводчик мало влиял на скорость всей генерации. Зато он умнее всяких Яндексов и Гуглов.)Нейросеть весила аж 6 гб! Загрузив через костыли GPT на сервер, я был вновь разочарован! Да, такая комбинация была умнее чем 2 предыдущие попытки, но работала она жуть как медленно. Поэтому я решил сконвертировать модель в лёгкий и удобный формат.Переведя нейронную сеть из Tensorflow-формата в PyTorch и назвав её "gameGPT", я не только сэкономил 3 гб места на диске и оперативную память сервера, но ещё и ускорил всё это дело.Что получилосьGitHub с gameGPT - https://github.com/0x7o/gameGPTЧуть-чуть проблемНейросеть в PyTorch формате отличалась от Tensorflow версии. Просто подобрав параметры для gameGPT, я сделал новую версию ещё лучше.generate(text, max_length=num_tokens(text) + 55, repetition_penalty=5.0, temperature=0.9, num_beams=2, top_k=50, top_p=0.95)Связь gameGPT с gamio.ruЧто такое gamio? Это сайт построенный на django с добавлением JS. Всё, что вам необходимо знать.Gamio создаёт своеобразную очередь из запросов к gameGPT (это была необходимость. При параллельных вычислениях сервер входит в шок.). gameGPT последовательно обрабатывает каждый запрос к нему.На вход к модели подаётся история мира + последние 10 действия игрока. На выходе генерируется 55 токенов. Что в итоге?Мне удалось создать то, что я хотел. Получился отличный сервис gamio.ru. На нём уже поиграли свыше 1000 человек (для меня это рекорд :)) и все вполне довольны.Далее будут только улучшения и обновления. Следите за новостями :)Мой github Мой PatreonТелеграм-канал Gamio      Tags: gpt-2cyoaтекстnlpтрансформеры Hubs: PythonProgrammingMachine learningArtificial IntelligenceNatural Language Processing          


